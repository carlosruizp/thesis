% Chapter 6

\chapter{Experiments} % Write in your own chapter title
\label{Chapter6}
\lhead{Chapter \ref{Chapter6}. \emph{Experiments}} 

% {\bf \small{
% small  }}

%\section{Introduction}
In the previous chapter, we have given the theoretical framework of our proposals for \acrfull{mtl}. In Chapter~\ref{Chapter4} we have presented the convex \acrshort{mtl} formulation that uses a convex combination of common and task-specific parts, which is convenient for interpretability and hyperparameter selection.
We developed the convex formulation for kernel methods, such as L1, L2 and LS-\acrfull{svms}, and for \acrfull{nns}. We also show how we can optimally select the convex combination of pre-trained models.
%
In this chapter we will present several experiments to better understand this convex formulation, and also to test its performance on \acrshort{mtl} problems.
%
Moreover, in Chapter~\ref{Chapter5} we presented the \acrfull{gl} formulation for \acrshort{mtl}, which we have combined also with the convex approach to define the convex \acrshort{gl} formulation.
We developed it for linear models and then for kernel methods, such as the L1, L2 and LS-\acrshort{svms}. This approach, however, involves the selection of an adjacency matrix that reflects the relations between the tasks. We proposed also the Adaptive \acrshort{gl} approach, which uses a data-driven procedure to automatically learn this adjacency matrix.
%
We will present in this chapter multiple experiments to test a fixed convex \acrshort{gl} model, as well as its adaptive version.
%

More specifically, in Section~\ref{sec:convexmtlsvm_exp} we present experiments that show the performance of the convex formulation with kernel methods. In Section~\ref{sec:convexmlt_renewable} we present the application of the convex formulation to the problem of predicting the production of solar and wind energy.
In Section~\ref{sec:convexmtl_nn_experiments} we give experiments that consider \acrfull{mt} image datasets and, thus, \acrshort{nns} are the models better suited for this kind of problems, in particular we test our proposed convex \acrshort{mtl} \acrshort{nn}. 
%
Then, in Section~\ref{sec:convexgl_experiments} we give experiments with models that implement \acrshort{gl}-based \acrshort{mtl}. And, finally, in Section~\ref{sec:adapconvexgl_experiments} we illustrate our adaptive algorithm for \acrshort{gl}-based \acrshort{mtl} in several experiments with real and synthetic data.






\section{Convex Multi-Task Learning with Kernel Methods}\label{sec:convexmtlsvm_exp}
In this section we present the experiments used to test the convex \acrshort{mtl} formulation with kernel models, which we have proposed in~\citet{RuizAD19} and~\citet{RuizAD21} and have been explained in Section~\ref{sec:convexmlt_kernel}. 
%
First, following our work in~\citet{RuizAD19}, experiments comparing convex and additive \acrshort{mtl} formulations in the L1-\acrshort{svm} are described. 
%
Next, we present experiments where multiple convex \acrshort{mtl} models, using L1, L2 and LS-\acrshort{svms}, as well as optimal convex combinations of pre-trained models, are compared over multiple real problems.
%

Before diving into the results, some technical details have to be explained. The convex \acrshort{mtl} formulation, as presented in Equation~\eqref{eq:svmmtl_primal_convex}, uses task-specific hyperparameters $\lambda_r$, as well as common and task-specific kernels, with their corresponding hyperparameters; however, the selection of many hyperparameters is always a challenge because of the curse of dimensionality. 
%
In general, to select the hyperparameters $p_1, \ldots, p_L$ of a learning algorithm using \acrshort{cv}, the following problem is solved:
\begin{equation}
    \label{eq:hp-selection_general}
    p_1^*, \ldots, p_L^* = \argmin_{p_i \in \mathcal{S}_{p_i}, i=1, \ldots, L} \sum_{j=1}^{F} \rho(\mathcal{A}(p_1, \ldots, p_L; (X^j_\text{train}, y^j_\text{train})); (X^j_\text{val}, y^j_\text{val})) ,
\end{equation}
where $\rho$ is some score measure, $\mathcal{A}$ is our choice of learning algorithm, $p_1, \ldots, p_L$ are the parameters on which $\mathcal{A}$ depends and $\mathcal{S}_{p_i}$ a feasible space for the parameter $p_i$, and $(X^j_\text{train}, y^j_\text{train}), (X^j_\text{val}, y^j_\text{val})$ are the training and validation sets, respectively. We are using $F$ folds, that is, for $j=1, \ldots, F$, we select different training and validation sets and we train our algorithm $\mathcal{A}$ on the training set $(X^j_\text{train}, y^j_\text{train})$; then we use $\rho$ to measure the performance of our model on $(X^j_\text{val}, y^j_\text{val})$. 
%
Observe that our search space is the product space $\mathcal{S}_{p_1} \times \ldots \times \mathcal{S}_{p_L}$, so the difficulty of selecting an optimal combination of hyperparameters scales exponentially with the number of such parameters.

%
In a standard Gaussian kernel \acrshort{svm}, the definition of the classification problem depends on two hyperparameters: $C$ and $\gamma$.
For regression problems we also add a third parameter: $\epsilon$. 
That is, the optimal hyperparameters of a standard \acrshort{svm} for a single task problem are
\begin{equation}
    \nonumber
    C^*, \gamma^* (, \epsilon^*) = \argmin_{\substack{C \in \mathcal{S}_C ; \\ \substack{\gamma \in \mathcal{S}_\gamma} ; \\ \left(\substack{\epsilon \in \mathcal{S}_\epsilon} \right); }}
     \sum_{j=1}^{F} \rho(\mathcal{A}(C, \gamma (, \epsilon); (X^j_\text{train}, y^j_\text{train})); (X^j_\text{val}, y^j_\text{val})) ,
\end{equation}
which is typically feasible by using a grid search method in the space $\mathcal{S}_{C} \times \mathcal{S}_{\gamma} (\times \mathcal{S}_{\epsilon}) .$
%
However, using the convex \acrshort{mtl} formulation, 
%as shown in the \acrshort{mtl} kernel expression~\eqref{eq:conv_mtl_kernel_fun}, there are a common width $\gamma$ and task-specific widths $\gamma_1, \ldots, \gamma_\ntasks$.
we have the following hyperparameters: 
\begin{itemize}
    \item the regularization parameter $C$;
    \item the common kernel width $\gamma$ and task-specific ones $\gamma_1, \ldots, \gamma_\ntasks$;
    \item the convex combination parameters $\lambda_1, \ldots, \lambda_\ntasks$; and
    \item possibly the $\epsilon$ parameter.
\end{itemize}
That is, there are at least $2\ntasks + 2$ hyperparameters that have to be selected. Even with $\ntasks=2$, a search space of dimension $6$ can be computationally unfeasible to cover with a grid search. Although there exist other methods to select thy hyperparameters, such as random search or Bayesian optimization, we will only consider \acrshort{cv} in this work.
% \begin{equation}
%     \nonumber
%     C^*, \gamma^*, \gamma_1^*, \ldots, \gamma_\ntasks^*, \lambda_1^*, \ldots, \lambda_\ntasks^*   (, \epsilon^*) = \argmin_{\substack{C \in \mathcal{S}_C ; \\ \substack{\gamma \in \mathcal{S}_\gamma} ; \\ \left(\substack{\epsilon \in \mathcal{S}_\epsilon} \right); }}
%      \sum_{j=1}^{F} \rho(\mathcal{A}(C, \gamma (, \epsilon); (X^j_\text{train}, y^j_\text{train})); (X^j_\text{val}, y^j_\text{val})) ,
% \end{equation}

To face this issue and select the optimal parameters for the convex \acrshort{mtl} formulation we use the following strategy strategy.
%
For the kernel widths, we first hyperparametrize the corresponding \acrshort{ctl} and \acrshort{itl} kernel models, which have a common and task-specific kernel widths, respectively. 
This step would give also optimal $C$ and $\epsilon$ values, but we discard them.
Observe that in the \acrshort{ctl} approach, where a single task is solved, and in the \acrshort{itl} approach, where we solve the tasks independently, we have either $2$ or $3$ hyperparameters. We solve the corresponding problems, which are represented in Equation~\eqref{eq:hp-selection_general}, and using grid search, we obtain the optimal common $C^*, \gamma^*$ and the task-specific ones $C_r^*, \gamma^*_r$ for $r=1, \ldots, \ntasks$, and also the respective $\epsilon^*$ values in the regression setting.
Then, we reutilize the optimal widths for these models, and fix them in the \acrshort{mtl} one. 
%
Moreover, for the convex combination parameters we use a single $\lambda$ for all tasks, that is, $\lambda_1 = \ldots = \lambda_\ntasks = \lambda$.
%
With these considerations, the problem to select the remaining hyperparameters is 
\begin{equation}
    \nonumber
    C^*, \lambda^* (, \epsilon^*) = \argmin_{\substack{C \in \mathcal{S}_C ; \\ \substack{\lambda \in \mathcal{S}_\lambda} ; \\ \left(\substack{\epsilon \in \mathcal{S}_\epsilon} \right); }}
     \sum_{j=1}^{F} \rho(\mathcal{A}(C, \lambda, \gamma^*, \gamma_1^*, \ldots, \gamma_\ntasks^* (, \epsilon); (X^j_\text{train}, y^j_\text{train})); (X^j_\text{val}, y^j_\text{val})) ,
\end{equation}
where we have a maximum of $3$ hyperparameters.

%
Therefore, there are two adjustments that we make to carry out the experiments shown in this subsection.
The first adjustment concerning kernel widths does not change the model definition, but it assumes that kernel widths that are good for \acrshort{ctl} or \acrshort{itl} models are good for the \acrshort{mtl} one. 
In particular, consider the Gaussian kernel
\begin{equation}
    \nonumber
    k(x, y) = \exp{\left(-\gamma \norm{x - y}^2 \right)},
\end{equation}
where $\gamma$ is the kernel width that regulates ``how wide is the influence of each point'';
then, kernel widths are not that descriptive of the model but of the data used, which makes the reutilization of kernel widths seems to be a sensible decision.
The combined data from all tasks, which is used in the \acrshort{ctl} approach, is well ``characterized'' by the width $\gamma^*$ so we expect that this width is also useful for the common part of the \acrshort{mtl} model. The same reasoning applies to task-specific data and the \acrshort{itl} approach.
%
The second adjustment does change the models' definition, because we use a single $\lambda$ that determines the specifity of all models. However, we expect that the possible difference in specifity among tasks can be alleviated in the training process.

\subsection{Comparison of Convex and Additive Formulations}
% Figure Synthetic Problem HAIS2019
% \begin{figure}
%     \centering
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/HAIS2019/synthetic_example-crop.pdf}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/HAIS2019/synthetic_comparison-crop.pdf}
%     \end{subfigure}
%     \caption{Left: Synthetic example dataset, where the data of each task (corresponding to a different function $f_i$) are represented with a different color.
%         Right: Comparison of the weights obtained by the {convex} and {additive} approaches.}
%     \label{fig:lines_slopes}
% \end{figure}

\begin{figure}[t!]
    \centering
    \subfloat[][Synthetic problem, where the data of each task (corresponding to a different function $f_i$) are represented with a different color.]{%    
    \includegraphics[width=0.45\textwidth]{Chapter6/HAIS2019/synthetic_example-crop.pdf}
    \label{fig:synthetic_example}}\quad%
    \subfloat[][Comparison of the weights obtained by the {convex} and {additive} approaches.]{%
    \includegraphics[width=0.45\textwidth]{Chapter6/HAIS2019/synthetic_comparison-crop.pdf}
    \label{fig:synthetic_comparison}}\\
    \caption{Synthetic problem and comparison of convex and additive formulations weights.}
    \label{fig:lines_slopes}
\end{figure}

% Figure Convex vs Additive HAIS2019
% \begin{figure}
%     \centering
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/HAIS2019/synthetic_specWeights_add-crop.pdf}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/HAIS2019/synthetic_specWeights_conv-crop.pdf}
%     \end{subfigure}
%     \caption{{Convex} (right) and {additive} (left) MTL slope estimates weights as a function of $\lambda$. We represent the common part of the models, $w$ for the {additive} and $\lambda u$ for the {convex}, as well as each task specific part $v_t$ and $(1 - \lambda) u_t$.}
%     \label{fig:synthetic_specWeights}
% \end{figure}

\begin{figure}[t!]
    \centering
    \subfloat[][{Additive} MTL slope estimates weights as a function of $\mu$. We represent the common part of the models as $w$, and the task-specific parts as $v_r$.]{%    
    \includegraphics[width=0.45\textwidth]{Chapter6/HAIS2019/synthetic_specWeights_add-crop.pdf}
    \label{fig:additive_weights}}\quad%
    \subfloat[][{Convex} MTL slope estimates weights as a function of $\lambda$. We represent the common part of the models as $\lambda u$, and the task-specific parts as $(1 - \lambda) u_r$.]{%
    \includegraphics[width=0.45\textwidth]{Chapter6/HAIS2019/synthetic_specWeights_conv-crop.pdf}
    \label{fig:convex_weights}}\\
    \caption{Additive and Convex \acrshort{mtl}\acrshort{svr} slope estimates.}
    \label{fig:synthetic_specWeights}
\end{figure}



%The work shown in~\cite{RuizAD19} focuses on 

In~\citet{RuizAD19} we illustrate the results of the equivalence between the additive and convex formulations in an empirical way. To do this we generate a synthetic problem, shown in Figure~\ref{fig:synthetic_example}, as a four tasks linear regression problem. 
%
We use four different functions, $f_0, f_1, f_2, f_3$, by considering a base function $f(x) = 2x - 1$ with slope $m=2$ and bias $n=1$; then we sample $z_m^r, z_n^r \sim \normal{0, 1}$ for each task $r=0, \ldots, 3$, and create the $r$-th slope and bias by adding these Gaussian samples, i.e., $m_r = m + z_m^r$ and $n_r = n + z_n^r$. Also, we sample the noise level $\sigma_r$ for each task uniformly in $(0, 5)$. 
%
Then, the $r$-th task consists in estimating $m_r$ and $n_r$ from the data. To do this, for each task we uniformly sample $30$ points $x_i^r \in [1, 50)$, and the target values are defined as $y_i^r = f_r(x_i^r) + \epsilon^i_r$, where $\epsilon^i_r \sim \normal{0, \sigma_r}$ and $f_r(x) = m_r x + n_r$.
%

Combining all tasks, there are $120$ data points, $30$ for each task, that we split randomly in a task-stratified way: two thirds, i.e. $80$ points, are used for training, and the rest are used for testing purposes. In this division, the task size proportions are kept constant, that is $1/4$ for each task, in both the train and test sets. 
%
With this synthetic problem, we train four convex \acrshort{mtl} models corresponding to values of $\lambda \in \set{0.2, 0.4, 0.6, 0.8}$; and we also train the corresponding equivalent additive \acrshort{mtl} models, in which we set $\mu = (1 - \lambda)/\lambda^2$ and $C_\text{add} = (1 - \lambda)^2 C_\text{conv}$, as shown in Proposition~\ref{prop:add_conv_equiv}.
%

Our first goal is to compare the influence of $\mu$ with that of $\lambda$ in the final models that are obtained. To do that, we need $C$ to be small enough so that the regularization and, therefore, $\mu$ are relevant; the value $C_{\text{conv}} = 10^{-2}$ is found to be useful. We also consider linear kernels, so we can obtain the primal coefficients, that is, the slopes, and compare those obtained using the additive and convex formulations. In Figure~\ref{fig:synthetic_comparison}, we show the estimated slopes for each of the $\lambda$ values considered with a different color. In the $x$ axis we represent the slopes estimated using the convex approach and in the $y$ axis those estimated with the additive one. There are four dots of each color, corresponding to each of the tasks considered in our synthetic problem. We can observe that all dots lie in the diagonal line corresponding to the identity function, as we expected from the equivalence result from Proposition~\ref{prop:add_conv_equiv}.

%
To further compare the two formulations, we visualize how the change on the hyperparameters imposes a change on the final models. Using the already described synthetic problem of Figure~\ref{fig:synthetic_example}, we select values of $\lambda$ ranging from $0$ to $1$, and their corresponding values $\mu = (1-\lambda)^2 / \lambda^2$, and fit convex and additive \acrshort{mtl} linear \acrshort{svm}s using these values. In Subfigures~\ref{fig:additive_weights} and~\ref{fig:convex_weights} we show the coefficients obtained for the common and task-specific parts with the additive and convex formulations, respectively.
%
We can observe how both graphics show a similar behaviour, with the common model starting in $0$ when $\mu$ is large or $\lambda=0$, and, as $\mu$ decreases and $\lambda$ grows, the task-specific parts go to zero and the common model reaches the optimal value for \acrshort{ctl}.
%

However, two facts are noticeable. The first one is the range of the hyperparameters needed for each formulation: while the convex formulation always uses $[0, 1]$, with the additive formulation it seems that $(10^{-3}, 10^3)$ is useful in this problem, but we cannot extrapolate to other problems. The second one is the smoother transition of the convex formulation, where the changes are steadily made, while with the additive one the changes look more abrupt.



\subsection{Performance of Convex \acrshort{mtl} and Optimal Convex Combination}

To test the performance of the convex \acrshort{mtl} formulation, in~\citet{RuizAD19} we also conduct experiments with real problems, which we later extend in~\citet{RuizAD21}. 
To test our proposal we apply it to three \acrshort{svm} variants: L1, L2 and LS-\acrshort{svm}. For each variant, we compare the \acrshort{ctl} and \acrshort{itl} approaches with our convex \acrshort{mtl} formulation. To do this, we use fourteen different problems, six regression ones and eight classification ones.

% Models
%\subsubsection*{Models}
Using {LX} such that it can stand for {L1}, {L2} or {LS}, we consider the following models to test our proposal:
\begin{itemize}
    \item {Common Task Learning LX-\acrshort{svm} (\fmod{CTL-LX})}: A single LX-\acrshort{svm} fitted using data from all the tasks, which does not use task information.
    \item {Independent Task Learning LX-\acrshort{svm} (\fmod{ITL-LX})}: Multiple task-specific LX-\acrshort{svm}s, each of which is fitted with the data from its own task.
    \item {Direct Convex Combination of LX-\acrshort{svm}s (\fmod{CMB-LX})}: A combination of the best \fmod{CTL-LX} and \fmod{ITL-LX} as described in Section~\ref{sec:optimal_comb}.
    \item {Convex Multi-Task Learning LX-\acrshort{svm} (\fmod{MTL-LX})}: The Convex \acrshort{mtl} formulations shown in Section~\ref{sec:convexmlt_kernel}.
\end{itemize}

% Problems
%\subsubsection*{Problems}
We describe next the regression and classification problems.
We use a total of six regression problems:
\begin{itemize}
    \item \fdata{majorca} and \fdata{tenerife}: The goal is to predict the photovoltaic energy production in Majorca and Tenerife, respectively. The tasks are defined as the energy prediction at each of the $14$ hours with sunlight (we remove the night hours).
    \item \fdata{boston}\footnote{\url{https://www.kaggle.com/datasets/schirmerchad/bostonhoustingmlnd}}: This is the Boston housing problem, where the goal is to predict house prices, and the tasks are defined as the predictions in different areas of the city. In this problem we define two tasks: the houses that are next to the river and those that are not. 
    \item \fdata{california}\footnote{\url{https://www.kaggle.com/datasets/camnugent/california-housing-prices}}: This is the housing problem in California, where the goal is also to predict house prices. Here the tasks correspond to four different areas of California, according to their distance to the sea.
    \item \fdata{abalone}\footnote{\url{https://archive.ics.uci.edu/ml/datasets/abalone}}: The goal is to predict the number of rings of a species of marine molluscs. The tasks are male, female or infant specimens.
    \item \fdata{crime}\footnote{\url{https://archive.ics.uci.edu/ml/datasets/communities+and+crime}}: The goal is to predict the number of crimes per \num{100000} habitants in the U.S. The tasks are the prediction of the crime rate in nine different states.
\end{itemize}
For the classification setting, we consider eight problems, six of which are generated by applying different task definitions to two different problems.
\begin{itemize}
    \item \fdata{landmine}\footnote{\url{https://andreric.github.io/files/datasets/LandmineData\_19.mat}}: This is a binary classification problem in which the goal is to decide whether a landmine is present in a given image. Detection of different types of landmines define different tasks. 
    \item \fdata{binding}\footnote{\url{https://github.com/pcpLiu/DeepSeqPan/tree/master/dataset}}: This is a binary classification problem where the goal is to determine if a given molecule will bind with peptides. Different molecules define different tasks and the patterns are the characteristics of the peptides.
    \item \fdata{adult}\footnote{\url{https://archive.ics.uci.edu/ml/datasets/adult}}: The goal is to predict whether the yearly salary of a particular person is greater than \num{50}K based on sociocultural data. We can define different tasks dividing the population by either gender or race, so we have the problems:
    \begin{itemize}
        \item \fdata{ad\_(G)}: dividing by gender. We consider $2$ tasks.
        \item \fdata{ad\_(R)}: dividing by race. We consider $5$ tasks.
        \item \fdata{ad\_(G, R)}: dividing by both gender and race, so we define a total of $10$ tasks.
    \end{itemize}
    \item \fdata{compas}\footnote{\url{https://www.kaggle.com/datasets/danofer/compass}}: The goal is to predict whether the COMPAS algorithm will assign ``low'' or ``high'' scores of recidivism to a particular subject. We can also divide the sample by either race or gender, so we obtain:
    \begin{itemize}
        \item \fdata{comp\_(G)}: dividing by gender. We consider $2$ tasks.
        \item \fdata{comp\_(R)}: dividing by race. We consider $4$ tasks
        \item \fdata{comp\_(G, R)}: dividing by both gender and race, so we define a total of $8$ tasks.
    \end{itemize}
\end{itemize}
% The characteristics of some of the problems considered are present in Table~\ref{tab:mtl_problems} but, considering the different task definitions for \fdata{compas} and \fdata{adult} 
We give in Table~\ref{tab:problems_hais19} a description of the characteristics of the datasets.

% Table Problems HAIS19
\begin{table*}[t!]
    \caption{Sample sizes, dimensions and number of tasks of the datasets used.}
    \label{tab:problems_hais19}
    \centering
    \scalebox{.65}{
    \begin{tabular}{l*{7}{S[table-format=5]}}
    \toprule
    \fhead{Dataset} & \fhead{Size} & \fhead{No. feat.} & \fhead{No. tasks} & \fhead{Avg. task size} & \fhead{Min. task size} & \fhead{Max. task size}\\
    \midrule
    \fdata{majorca} & 15330 & 765 & 14 & 1095 & 1095 & 1095 \\ 
    \fdata{tenerife} & 15330 & 765 & 14 & 1095 & 1095 & 1095 \\
    \fdata{california} & 19269 & 9 & 5 & 3853 & 5 & 8468\\
    \fdata{boston} & 506 & 12 & 2 & 253 & 35 & 471 \\
    \fdata{abalone} & 4177 & 8 & 3 & 1392 & 1307 & 1527 \\
    \fdata{crime} & 1195 & 127 & 9 & 132 & 60  & 278 \\
    \fdata{binding} & 32302 & 184 & 47 & 687 & 59 & 3089 \\ 
    \fdata{landmine} & 14820 & 10 & 28 & 511 & 445 & 690 \\
    \fdata{adult\_(G)} & 48842 & 106 & 2 & 24421 & 16192 & 32650 \\
    \fdata{adult\_(R)} & 48842 & 103 & 5 & 9768 & 406 & 41762 \\
    \fdata{adult\_(G, R)} & 48842 & 101 & 10 & 4884 & 155 & 28735 \\
    \fdata{compas\_(G)} & 3987 & 11 & 2 & 1993 & 840 & 3147 \\
    \fdata{compas\_(R)} & 3987 & 9 & 4 & 997 & 255 & 1918 \\
    \fdata{compas\_(G, R)} & 3987 & 7 & 8 & 498 & 50 & 1525 \\
    \bottomrule
   \end{tabular}}
\end{table*}

% Experimental Procedure

% Table Hyperparameters HAIS19
\begin{table}[t!]
    \caption{Hyperparameters, grids used to select them (when appropriate) and hyperparameter selection method for each model.}
    \label{tab:hyperpars_grid}
    \centering
    \scalebox{.65}{
     \begin{tabular}{*{9}{c}}
     \toprule
     \fhead{} & \fhead{Grid} & \fhead{\fmod{CTL-L1,2}} & \fhead{\fmod{ITL-L1,2}} & \fhead{\fmod{MTL-L1,2}}  & \fhead{\fmod{CTL-LS}} & \fhead{\fmod{ITL-L,S}} & \fhead{\fmod{MTL-LS}}   \\
     \midrule
      $C$ &  \scalebox{1}{$\set{4^k: -2 \leq k \leq 6}$} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv}  \\ 
      $\epsilon$ & \scalebox{1}{$\set{\frac{\sigma}{4^k}: 1 \leq k \leq 6}$} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & - & - & - \\
      $\gamma_c$ & \scalebox{1}{$\set{\frac{4^k}{d}: -2 \leq k \leq 3}$} & \acrshort{cv} & - & \fmod{CTL-L1,2} & \acrshort{cv} & - & \fmod{CTL-LS} \\
      $\gamma_s^r$ & \scalebox{1}{$\set{\frac{4^k}{d}: -2 \leq k \leq 3}$} & - & \acrshort{cv} & \fmod{ITL-L1,2} & - & \acrshort{cv} & \fmod{ITL-LS}\\
      $\lambda$ & \scalebox{1}{$\set{0.1 k : 0 \leq k \leq 10}$} & - & - & \acrshort{cv} & - & - & \acrshort{cv} \\
      \bottomrule
     \end{tabular}
     }
  \end{table}

%\subsubsection*{Experimental Procedure}
To obtain the experimental results, we have to select the optimal hyperparameters for each model in a training-validation set and measure their performance on a test set. To do this, we follow the adjustments and experimental procedure described at the beginning of this Section~\ref{sec:convexmtlsvm_exp}, reusing the kernel widths from the \acrshort{ctl} and \acrshort{itl} approaches and limiting the convex \acrshort{mtl} formulation to a single convex combination hyperparameter $\lambda$.
%
In all models considered we use Gaussian kernels, so all features have been normalized to have zero mean and a standard deviation of $1$.
As previously explained, the hyperparameters for the \acrshort{ctl} and \acrshort{itl} approaches in the classification setting are $\set{C, \gamma}$ for all variants (L1, L2 and LS-\acrshort{svm}).
In the regression setting we have $\set{C, \gamma, \epsilon}$ for the L1 and L2 variants, and $\set{C, \gamma}$ for the LS-\acrshort{svm}.
%
%After selecting the optimal kernel widths in the \acrshort{ctl} approach $\gamma^*$, and the task-specific widths $\gamma_r^*$ in the \acrshort{itl} approach, we use these values to fix them in the convex \acrshort{mtl} formulation.
%Therefore, the hyperparameters that we are considering for \acrshort{cv} search in the convex \acrshort{mtl} approaches in the classification settings are $\set{C, \lambda}$ for all variants, while in the regression problems they are $\set{C, \lambda, \epsilon}$ for the L1 and L2 variants and $\set{C, \lambda}$ for the LS-\acrshort{svm}.
%
The optimal combination approaches do not have specific hyperparameters, since $\lambda$ is computed by minimizing the training error.
%

In all problems, the hyperparameters considered are selected with a grid search using a task-stratified $3$-fold \acrshort{cv}. That is, given a training-validation set, we divide it in three different folds where the task proportions are kept constant, and we use two of these folds for training the model and evaluate its performance in the remaining one.
%
In the regression problems, we present the test results of models that have been selected with two different validation metrics, the \acrshort{mae} and \acrshort{mse}.
%In Table~\ref{tab:error_models_reg_mae_mae} we present the test results of models selected using the \acrshort{mae} as validation metric, while in Table~\ref{tab:error_models_reg_mse_mae} the models have been selected using the \acrshort{mse}.
%
Observe that the objective function of L1-\acrshort{svm} based models is more aligned with minimizing the \acrshort{mae}, while those of L2 and LS-\acrshort{svm} based models are more related to minimizing the \acrshort{mse}. Therefore, we consider both scores as validation metrics to compare the results more fairly.
%
In the classification problems we will consider the F1 score to deal with the class-imbalance ratio that we find, for example, in the \fdata{landmine} dataset (where we have 200 negative examples for each 13 positive ones).
%
% (see Table~\ref{tab:error_models_reg_mae_mae})
% (see Table~\ref{tab:error_models_reg_mse_mae})
In Table~\ref{tab:hyperpars_grid} we show for each hyperparameter of the considered approaches whether they are selected using a \acrshort{cv} procedure or reusing them from another approach, as well as the grids used for the \acrshort{cv} search.

We have explained how we select the hyperparameters given a training-validation set, but it is necessary also to describe how we get the final test results.
In every problem, except for \fdata{majorca} and \fdata{tenerife}, we will consider three external folds, each with the internal three folds for \acrshort{cv}. That is, the entire dataset of each problem is first divided in three task-stratified external folds: $F_1, F_2, F_3$. Then, two folds will form the training-validation set and the third one will be used as the test set. All folds have the same task proportions. There are three different combinations to do this division: $\set{F_1, F_2; F_3}, \set{F_1, F_3; F_2}$ and $\set{F_2, F_3; F_1}$, where the first two folds form the train-validation set and the other one is the test set.
%
In each train-validation set we follow the procedure described above to select the optimal hyperparameters, and the performance of the model with the optimal hyperparameters will be tested in the remaining fold, i.e., the test set.
%
The problems of \fdata{majorca} and \fdata{tenerife} have a temporal dependency, so it is not sensible to use training data from a time that is ahead of that of the test or validation data. Therefore, we use data from years 2013, 2014 and 2015, each corresponding to train, validation and test sets, respectively.
%

We consider different metrics to measure the test performance. Therefore, in every problem, except \fdata{majorca} and \fdata{tenerife}, for each metric we obtain three different scores, each corresponding to a different test set, so we will show the mean and standard deviation of such scores. In \fdata{majorca} and \fdata{tenerife} we obtain a single test score corresponding to data from the year 2015.
% 
For the regression problems, in Tables~\ref{tab:error_models_reg_mae_mae} and~\ref{tab:error_models_reg_mse_mae}, we show both the MAE and R2 score, closely related to MSE, obtained in the test set. 
Recall that the results in Table~\ref{tab:error_models_reg_mae_mae} have been obtained with models selected using the \acrshort{mae} as the \acrshort{cv} metric, while those of Table~\ref{tab:error_models_reg_mse_mae} have been selected with the \acrshort{mse} as the metric.
%
For classification, in Table~\ref{tab:error_models_class_f1} we show the F1 and the accuracy scores.
%




% Results


  \begin{table*}[t!]
    %\captionsetup{font=scriptsize}
    \caption{Test \acrshort{mae} (top) and R2 score (bottom) and Wilcoxon-based ranking. Here, the optimal hyperparameters have been selected using the \acrshort{mae}. The best models are shown in bold.}
    \label{tab:error_models_reg_mae_mae}
    \centering
    \scalebox{.65}{
    \begin{tabular}{l*{2}{c@{ }l}*{4}{r@{$\pm$}l@{ }l } }
    \toprule
    & \fheadmulti{2}{\fdata{maj.}} & \fheadmulti{2}{\fdata{ten.}} & \fheadmulti{3}{\fdata{boston}} & \fheadmulti{3}{\fdata{california}} &  \fheadmulti{3}{\fdata{abalone}} & \fheadmulti{3}{\fdata{crime}}\\
    \midrule
    & \fheadmulti{16}{MAE} \\
    \midrule
    \fmod{ITL-L1}            &  {5.087} &   (6) &  {5.743} &   (3) &  {2.341} & {0.229} &   \fmaxn{(1)} &  {36883.582} & {418.435} &   (2) &  {1.481} & {0.051} &   (3) &  {0.078} & {0.001} &   (2) \\
    \fmod{CTL-L1}            &  {5.175} &   (7) &  {5.891} &   (5) &  \fmaxn{2.192} & \fmaxn{0.244} &   \fmaxn{(1)} &  {41754.337} & {270.908} &   (6) &  {1.482} & {0.050} &   (3) &  {0.078} & {0.001} &   (2) \\
    \fmod{CMB-L1} &  \fmaxn{5.047} &   (5) &  \fmaxn{5.340} &  \fmaxn{(1)} &  {2.239} & {0.255} &   \fmaxn{(1)} &  {36880.238} & {420.417} &   \fmaxn{(1)} &  {1.470} & {0.052} &   (2) &  {0.077} & {0.002} &   (2) \\
    \fmod{MTL-L1}     &  {5.050} &   (5) &  {5.535} &   (2) &  {2.206} & {0.292} &   \fmaxn{(1)} &  \fmaxn{36711.383} & \fmaxn{343.333} &  \fmaxn{(1)} &  \fmaxn{1.454} & \fmaxn{0.048} &  \fmaxn{(1)} &  \fmaxn{0.074} & \fmaxn{0.002} &  \fmaxn{(1)} \\
    \midrule
    \fmod{ITL-L2}            &  {4.952} &   (3) &  \fmaxn{5.629} &   (3) &  {2.356} & {0.300} &   \fmaxn{(1)} &  {37374.618} & {433.511} &   (5) &  {1.498} & {0.054} &   (4) &  {0.079} & {0.002} &   (2) \\
    \fmod{CTL-L2}            &  {5.193} &   (7) &  {6.107} &   (8) &  \fmaxn{2.083} & \fmaxn{0.136} &   \fmaxn{(1)} &  {42335.612} & {163.773} &   (8) &  {1.503} & {0.047} &   (5) &  {0.080} & {0.002} &   (2) \\
    \fmod{CMB-L2} &  {4.869} &   (3) &  {5.963} &   (6) &  {2.089} & {0.128} &   \fmaxn{(1)} &  {37374.618} & {433.511} &   (4) &  {1.494} & {0.050} &   (4) &  {0.077} & {0.003} &   (2) \\
    \fmod{MTL-L2}     &  \fmaxn{4.854} &   (2) &  {5.784} &   (4) &  {2.089} & {0.134} &   \fmaxn{(1)} &  \fmaxn{37202.603} & \fmaxn{419.166} &   (3) &  \fmaxn{1.482} & \fmaxn{0.049} &   (3) &  \fmaxn{0.077} & \fmaxn{0.002} &   (2) \\
    \midrule
    \fmod{ITL-LS}            &  {4.937} &   (3) &  {5.649} &   (3) &  {2.204} & {0.116} &   \fmaxn{(1)} &  {37348.347} & {441.240} &   (4) &  {1.496} & {0.051} &   (4) &  {0.079} & {0.002} &   (2) \\
    \fmod{CTL-LS}            &  {5.193} &   (7) &  {6.005} &   (7) &  \fmaxn{2.072} & \fmaxn{0.143} &  \fmaxn{(1)} &  {42259.492} & {146.825} &   (7) &  {1.502} & {0.052} &   (5) &  {0.079} & {0.002} &   (2) \\
    \fmod{CMB-LS} &  {4.977} &   (4) &  \fmaxn{5.593} &   (3) &  {2.081} & {0.146} &   \fmaxn{(1)} &  {37339.179} & {430.288} &   (4) &  {1.486} & {0.049} &   (4) &  {0.079} & {0.002} &   (2) \\
    \fmod{MTL-LS}     &  \fmaxn{4.824} &  \fmaxn{(1)} &  {5.754} &   (4) &  {2.077} & {0.152} &   \fmaxn{(1)} &  \fmaxn{37231.043} & \fmaxn{420.992} &   (4) &  \fmaxn{1.478} & \fmaxn{0.050} &   (3) &  \fmaxn{0.076} & \fmaxn{0.002} &   (2) \\
    \midrule
    & \fheadmulti{16}{R2} \\
    \midrule
    \fmod{ITL-L1}            &  {0.845} &   (6) &  {0.901} &   (7) &  {0.821} & {0.041} &   (2) &  {0.699} & {0.009} &   (7) &  {0.543} & {0.022} &   (8) &  {0.732} & {0.021} &   (3) \\
    \fmod{CTL-L1}            &  {0.837} &   (9) &  {0.901} &   (6) &  {0.854} & {0.036} &   \fmaxn{(1)} &  {0.639} & {0.006} &  (10) &  {0.559} & {0.014} &   (6) &  {0.740} & {0.027} &   (3) \\
    \fmod{CMB-L1} &  {0.844} &   (6) &  {0.905} &   (4) &  {0.845} & {0.053} &   \fmaxn{(1)} &  {0.699} & {0.009} &   (6) &  {0.555} & {0.018} &   (7) &  {0.741} & {0.029} &   (3) \\
    \fmod{MTL-L1}     &  \fmaxn{0.846} &   (4) &  \fmaxn{0.908} &   (2) &  \fmaxn{0.858} & \fmaxn{0.057} &   \fmaxn{(1)} &  \fmaxn{0.703} & \fmaxn{0.007} &   (6) &  \fmaxn{0.568} & \fmaxn{0.012} &   (5) &  \fmaxn{0.760} & \fmaxn{0.024} &   (2) \\
    \midrule
    \fmod{ITL-L2}            &  {0.846} &   (5) &  {0.906} &   (3) &  {0.836} & {0.045} &   (2) &  {0.707} & {0.009} &   (5) &  {0.565} & {0.025} &   (6) &  {0.743} & {0.017} &   (3) \\
    \fmod{CTL-L2}            &  {0.840} &   (8) &  {0.901} &   (8) &  \fmaxn{0.889} & \fmaxn{0.017} &   \fmaxn{(1)} &  {0.645} & {0.005} &   (9) &  {0.574} & {0.013} &   (4) &  {0.744} & {0.028} &   (3) \\
    \fmod{CMB-L2} &  {0.850} &   (3) &  {0.900} &   (9) &  {0.885} & {0.013} &   \fmaxn{(1)} &  {0.707} & {0.009} &   (4) &  {0.571} & {0.018} &   (4) &  {0.755} & {0.024} &   (3) \\
    \fmod{MTL-L2}     &  \fmaxn{0.863} &   (2) &  \fmaxn{0.908} &   \fmaxn{(1)} &  {0.888} & {0.015} &   \fmaxn{(1)} &  \fmaxn{0.709} & \fmaxn{0.008} &  \fmaxn{(1)} &  \fmaxn{0.580} & \fmaxn{0.014} &   (3) &  \fmaxn{0.762} & \fmaxn{0.028} &   \fmaxn{(1)} \\
    \midrule
    \fmod{ITL-LS}            &  {0.849} &   (3) &  {0.907} &   (3) &  {0.856} & {0.008} &   \fmaxn{(1)} &  {0.707} & {0.009} &   (3) &  {0.573} & {0.015} &   (4) &  {0.743} & {0.022} &   (3) \\
    \fmod{CTL-LS}            &  {0.838} &   (9) &  {0.904} &   (5) &  \fmaxn{0.894} & \fmaxn{0.015} &  \fmaxn{(1)} &  {0.646} & {0.005} &   (8) &  {0.576} & {0.016} &   (4) &  {0.746} & {0.032} &   (3) \\
    \fmod{CMB-LS} &  {0.843} &   (7) &  {0.907} &   (2) &  {0.886} & {0.024} &   \fmaxn{(1)} &  {0.707} & {0.009} &   (2) &  {0.581} & {0.012} &   (2) &  {0.746} & {0.021} &   (3) \\
    \fmod{MTL-LS}     &  \fmaxn{0.863} &  \fmaxn{(1)} &  \fmaxn{0.910} &  \fmaxn{(1)} &  {0.890} & {0.016} &   \fmaxn{(1)} &  \fmaxn{0.709} & \fmaxn{0.008} &   (2) &  \fmaxn{0.581} & \fmaxn{0.015} &  \fmaxn{(1)} &  \fmaxn{0.763} & \fmaxn{0.028} &  \fmaxn{(1)} \\
    \bottomrule
    \end{tabular}}
  \end{table*}





  \begin{table*}[t!]
    %\captionsetup{font=scriptsize}
    \caption{Test \acrshort{mae} (top) and R2 score (bottom) and Wilcoxon-based ranking. Here, the optimal hyperparameters have been selected using the \acrshort{mse}. The best models are shown in bold.}
      \label{tab:error_models_reg_mse_mae}
      \centering
      \scalebox{.65}{
          \begin{tabular}{l*{2}{c@{ }l}*{4}{r@{$\pm$}l@{ }l } }
              \toprule
              & \fheadmulti{2}{\fdata{maj.}} & \fheadmulti{2}{\fdata{ten.}} & \fheadmulti{3}{\fdata{boston}} & \fheadmulti{3}{\fdata{california}} &  \fheadmulti{3}{\fdata{abalone}} & \fheadmulti{3}{\fdata{crime}}\\
      \midrule
      & \fheadmulti{16}{MAE} \\
      \midrule
      \fmod{ITL-L1}            &  {5.087} &   (7) &  {5.743} &   (3) &  {2.437} & {0.281} &   (3) &  {36941.516} & {450.767} &   (1) &  {1.480} & {0.058} &   (3) &  {0.079} & {0.002} &   (3) \\
      \fmod{CTL-L1}            &  {5.175} &   (8) &  {5.891} &   (7) &  {2.315} & {0.192} &   (2) &  {41857.602} & {235.021} &   (6) &  {1.479} & {0.047} &   (3) &  {0.078} & {0.000} &   (2) \\
      \fmod{CMB-L1} &  \fmaxn{4.920} &   (4) &  {5.743} &   (4) &  {2.315} & {0.192} &   (3) &  \fmaxn{36941.476} & \fmaxn{450.711} &  \fmaxn{(1)} &  {1.471} & {0.057} &   (2) &  {0.079} & {0.002} &   (2) \\
      \fmod{MTL-L1}     &  {5.050} &   (6) &  \fmaxn{5.535} &  \fmaxn{(1)} &  \fmaxn{2.244} & \fmaxn{0.150} &   (1) &  {36999.003} & {360.445} &   (2) &  \fmaxn{1.455} & \fmaxn{0.046} &  \fmaxn{(1)} &  \fmaxn{0.074} & \fmaxn{0.001} &  \fmaxn{(1)} \\
      \midrule
      \fmod{ITL-L2}            &  {4.924} &   (5) &  {5.752} &   (5) &  {2.437} & {0.324} &   (3) &  {37407.929} & {461.878} &   (5) &  {1.497} & {0.050} &   (5) &  {0.079} & {0.002} &   (2) \\
      \fmod{CTL-L2}            &  {5.193} &   (8) &  {6.107} &   (9) &  {2.096} & {0.112} &   (1) &  {42335.612} & {163.773} &   (7) &  {1.504} & {0.048} &   (6) &  {0.079} & {0.002} &   (2) \\
      \fmod{CMB-L2} &  \fmaxn{4.813} &  \fmaxn{(1)} &  \fmaxn{5.623} &   (3) &  {2.116} & {0.131} &   (1) &  {37398.940} & {449.498} &   (5) &  {1.495} & {0.051} &   (5) &  {0.078} & {0.003} &   (2) \\
      \fmod{MTL-L2}     &  {4.854} &   (4) &  {5.784} &   (6) &  \fmaxn{2.082} & \fmaxn{0.130} &   (1) &  \fmaxn{37356.599} & \fmaxn{390.629} &   (4) &  \fmaxn{1.481} & \fmaxn{0.041} &   (4) &  \fmaxn{0.076} & \fmaxn{0.000} &   (2) \\
      \midrule
      \fmod{ITL-LS}            &  {4.937} &   (5) &  {5.649} &   (3) &  {2.326} & {0.231} &   (3) &  {37385.244} & {403.331} &   (4) &  {1.495} & {0.045} &   (5) &  {0.079} & {0.002} &   (2) \\
      \fmod{CTL-LS}            &  {5.193} &   (8) &  {6.005} &   (8) &  \fmaxn{2.072} & \fmaxn{0.143} &  \fmaxn{(1)} &  {42339.063} & {156.624} &   (7) &  {1.504} & {0.043} &   (6) &  {0.078} & {0.002} &   (2) \\
      \fmod{CMB-LS} &  \fmaxn{4.820} &   (2) &  {5.578} &   (2) &  {2.136} & {0.106} &   (1) &  {37377.005} & {391.694} &   (4) &  {1.491} & {0.048} &   (5) &  {0.078} & {0.002} &   (2) \\
      \fmod{MTL-LS}     &  {4.824} &   (3) &  \fmaxn{5.754} &   (6) &  {2.090} & {0.090} &   (1) &  \fmaxn{37232.918} & \fmaxn{397.866} &   (3) &  \fmaxn{1.478} & \fmaxn{0.042} &   (3) &  \fmaxn{0.076} & \fmaxn{0.000} &   (2) \\
      \midrule
      & \fheadmulti{16}{R2} \\
      \midrule
      \fmod{ITL-L1}            &  {0.845} &   (6) &  {0.901} &   (9) &  {0.800} & {0.050} &   (3) &  {0.703} & {0.009} &   (8) &  {0.534} & {0.053} &  (10) &  {0.732} & {0.017} &   (4) \\
      \fmod{CTL-L1}            &  {0.837} &   (7) &  {0.901} &   (8) &  {0.860} & {0.026} &   (2) &  {0.642} & {0.006} &  (10) &  {0.564} & {0.011} &   (8) &  {0.748} & {0.017} &   (3) \\
      \fmod{CMB-L1} &  \fmaxn{0.852} &   (4) &  {0.901} &  (10) &  {0.860} & {0.026} &   (3) &  {0.703} & {0.009} &   (7) &  {0.550} & {0.036} &   (9) &  {0.733} & {0.018} &   (3) \\
      \fmod{MTL-L1}     &  {0.846} &   (5) &  \fmaxn{0.908} &   (5) &  \fmaxn{0.871} & \fmaxn{0.019} &   (1) &  \fmaxn{0.705} & \fmaxn{0.008} &   (6) &  \fmaxn{0.573} & \fmaxn{0.011} &   (7) &  \fmaxn{0.764} & \fmaxn{0.019} &   (1) \\
      \midrule
      \fmod{ITL-L2}            &  {0.850} &   (4) &  {0.906} &   (6) &  {0.819} & {0.053} &   (3) &  {0.707} & {0.009} &   (4) &  {0.573} & {0.020} &   (6) &  {0.744} & {0.018} &   (3) \\
      \fmod{CTL-L2}            &  {0.840} &   (6) &  {0.901} &  (11) &  {0.886} & {0.014} &   (1) &  {0.645} & {0.005} &   (9) &  {0.574} & {0.013} &   (6) &  {0.747} & {0.025} &   (3) \\
      \fmod{CMB-L2} &  {0.857} &   (3) &  \fmaxn{0.910} &  \fmaxn{(1)} &  {0.883} & {0.016} &   (1) &  {0.707} & {0.009} &   (2) &  {0.574} & {0.021} &   (5) &  {0.751} & {0.029} &   (3) \\
      \fmod{MTL-L2}     &  \fmaxn{0.863} &   (2) &  {0.908} &   (4) &  \fmaxn{0.887} & \fmaxn{0.015} &   (1) &  \fmaxn{0.708} & \fmaxn{0.007} &   (2) &  \fmaxn{0.581} & \fmaxn{0.011} &   (2) &  \fmaxn{0.768} & \fmaxn{0.020} &  \fmaxn{(1)} \\
      \midrule
      \fmod{ITL-LS}            &  {0.849} &   (4) &  {0.907} &   (5) &  {0.841} & {0.028} &   (3) &  {0.707} & {0.009} &   (5) &  {0.577} & {0.012} &   (4) &  {0.743} & {0.021} &   (3) \\
      \fmod{CTL-LS}            &  {0.838} &   (7) &  {0.904} &   (7) &  \fmaxn{0.894} & \fmaxn{0.015} &  \fmaxn{(1)} &  {0.645} & {0.005} &   (9) &  {0.575} & {0.012} &   (4) &  {0.754} & {0.022} &   (3) \\
      \fmod{CMB-LS} &  {0.856} &   (3) &  {0.909} &   (3) &  {0.877} & {0.009} &   (1) &  {0.707} & {0.009} &   (3) &  {0.580} & {0.013} &   (3) &  {0.750} & {0.024} &   (3) \\
      \fmod{MTL-LS}     &  \fmaxn{0.863} &  \fmaxn{(1)} &  \fmaxn{0.910} &   (2) &  {0.890} & {0.014} &   (1) &  \fmaxn{0.710} & \fmaxn{0.008} &  \fmaxn{(1)} &  \fmaxn{0.582} & \fmaxn{0.011} &  \fmaxn{(1)} &  \fmaxn{0.763} & \fmaxn{0.019} &   (2) \\
      \bottomrule
      \end{tabular}}
    \end{table*}
  






%\subsubsection*{Results}
Regarding the numerical results, the tables presenting them have three blocks, one for each variant (L1, L2 or LS-\acrshort{svm}s), and, in each block, for each problem we show in bold the model with best test results.
%
We also provide a statistical significance ranking based on the Wilcoxon test. This is a pairwise test that checks whether the difference of two samples has 0 median. Instead of showing every Wilcoxon test result between all pairs of models, which would result in a $12 \times 12$ matrix difficult to interpret, we take the following approach. We first sort the models, according to some criterion, and test the significance between one model and the next one in the sorting order. Then we create a new significance ranking; the ranking increases only if this difference is significant. For example, if there are no significant differences between the first and second model, according to the sorting order, they both obtain a ranking of $1$.

%Regression
%
We compute a single Wilcoxon-based ranking for each regression dataset with the $12$ models considered, that is, the four approaches for each of the three blocks. We sort the models according to their mean score. Then, we test whether the difference between each model and the next one in the ranking is significant. To do this, we take the list of errors committed by each model in the test set, that is, $e_1 = \abs{y - \hat{y_1}}$ and $e_2 = \abs{y - \hat{y_2}}$. Then, we use the Wilcoxon test to check whether $e_1 - e_2$ is centered around 0.
If the null hypothesis is rejected at a $5\%$ level, then we say that the difference is significant, and we take as better the model with smaller error.
%
% For instance, according to MAE, in Table~\ref{tab:error_models_reg_mae_mae}, for the \fdata{majorca} dataset, the best model is the convex \fmod{MTL-LS} proposal and the second best is the \fmod{MTL-L2} model, while the \fmod{MTL-L1} ties for fifth place with \fmod{CMB-L1}.
%

The results for regression problems are shown in Table~\ref{tab:error_models_reg_mae_mae}, where the best parameters are selected according to the \acrshort{mae} validation score, and in Table~\ref{tab:error_models_reg_mse_mae}, where the \acrshort{mse} is used as the validation metric.
%
Although we cannot pick a single overall winner, we can still draw some conclusions from the tables. Notice that the convex \acrshort{mtl} approaches usually perform better, obtaining the best result in 11 out of 18 MAE blocks and 16 out of the 18 R2 blocks of Table~\ref{tab:error_models_reg_mae_mae}; in Table~\ref{tab:error_models_reg_mse_mae} it obtains 12 out of 18 MAE blocks and 15 out of 18 R2 blocks.
Also, a convex \acrshort{mtl} approach yields the single best overall model in four problems, while ties for the first place in \fdata{boston}, and only in \fdata{tenerife} ends up as second after the \fmod{CMB-L1} model.


\begin{table*}[t!]
    %\captionsetup{font=scriptsize}
    \caption{Test F1 (top) and accuracy (bottom) scores, global ranking and block-wise Wilcoxon-based rankings for classification problems. The best models in each block are shown in bold.}
    \label{tab:error_models_class_f1}
    \centering
    \scalebox{.65}{
      \begin{tabular}{ l*{8}{c} c c c}
        \toprule
        & \fhead{\fdata{comp\_(G)}} & \fhead{\fdata{comp\_(R)}} & \fhead{\fdata{comp\_(G,R)}} & \fhead{\fdata{ad\_(G)}} & \fhead{\fdata{ad\_(R)}} & \fhead{\fdata{ad\_(G,R)}} & \fhead{\fdata{landmine}} & \fhead{\fdata{binding}} & \fhead{mean} & \fhead{rank} & \fhead{Wil.}\\
        \midrule
        & \fheadmulti{8}{F1}  \\
        \midrule
        \fmod{ITL-L1}    &          0.625 &           \fmaxn{0.639} &                  0.630 &         \fmaxn{0.659} &          0.653 &                 0.657 &    0.231 &   0.867 & 0.620 &     10 & 1 \\
        \fmod{CTL-L1}    &          0.623 &           0.638 &                  0.638 &         0.657 &          0.650 &                 0.653 &    0.255 &   0.901 & 0.627 &      7 & 1 \\
        \fmod{CMB-L1} &          0.616 &           0.638 &                  0.638 &         0.658 &          0.650 &                 0.653 &    \fmaxn{0.270} &   0.901 & \fmaxn{0.628} &      6 & 1 \\
        \fmod{MTL-L1}    &          \fmaxn{0.627} &           0.636 &                  \fmaxn{0.640} &         \fmaxn{0.659} &          \fmaxn{0.655} &                 \fmaxn{0.659} &    0.242 &   \fmaxn{0.907} & \fmaxn{0.628} &      5 & 1 \\
        \midrule
        \fmod{ITL-L2}    &          0.636 &           0.623 &                  0.607 &         \fmaxn{0.668} &          \fmaxn{0.666} &                 \fmaxn{0.668} &    0.256 &   0.867 & 0.624 &      8 & 3 \\
        \fmod{CTL-L2}    &          \fmaxn{0.640} &           0.647 &                  \fmaxn{0.651} &         0.665 &          0.661 &                 0.659 &    \fmaxn{0.270} &   0.903 & 0.637 &      2 & 2 \\
        \fmod{CMB-L2} &          0.629 &           0.640 &                  0.645 &         0.666 &          0.662 &                 0.661 &    \fmaxn{0.270} &   0.903 & 0.634 &      3 & 2 \\
        \fmod{MTL-L2}    &          0.634 &           \fmaxn{0.651} &                  0.650 &         \fmaxn{0.668} &          \fmaxn{0.666} &                 \fmaxn{0.668} &    0.263 &   \fmaxn{0.909} & \fmaxn{0.639} &      1 & 1 \\
        \midrule
        \fmod{ITL-LS}    &          \fmaxn{0.631} &           0.622 &                  0.608 &         \fmaxn{0.659} &          \fmaxn{0.659} &                 \fmaxn{0.660} &    0.243 &   0.867 & 0.619 &     12 & 2 \\
        \fmod{CTL-LS}    &          0.628 &           \fmaxn{0.644} &                  \fmaxn{0.649} &         0.650 &          0.653 &                 0.647 &    0.230 &   0.853 & 0.619 &     11 & 2 \\
        \fmod{CMB-LS} &          0.630 &           0.635 &                  0.642 &         0.657 &          0.658 &                 0.654 &    0.238 &   0.873 & 0.623 &      9 & 2 \\
        \fmod{MTL-LS}    &          0.630 &           0.641 &                  0.648 &         \fmaxn{0.659} &          \fmaxn{0.659} &                 0.659 &    \fmaxn{0.257} &   \fmaxn{0.906} & \fmaxn{0.632} &      4 & 1 \\
        \midrule
        & \fheadmulti{8}{Accuracy}  \\
        \midrule
        \fmod{ITL-L1}    &          0.750 &           0.749 &                  0.746 &         0.852 &          0.851 &                 \fmaxn{0.853} &    \fmaxn{0.941} &   0.790 & 0.817 &     11 & 3 \\
        \fmod{CTL-L1}    &          \fmaxn{0.757} &           0.759 &                  \fmaxn{0.763} &         0.852 &          0.847 &                 0.849 &    0.938 &   0.850 & 0.827 &      6 & 2 \\
        \fmod{CMB-L1} &          0.754 &           0.759 &                  \fmaxn{0.763} &         0.852 &          0.847 &                 0.849 &    0.935 &   0.850 & 0.826 &      7 & 2 \\
        \fmod{MTL-L1}    &          0.753 &           \fmaxn{0.760} &                  \fmaxn{0.763} &         \fmaxn{0.853} &          \fmaxn{0.852} &                 \fmaxn{0.853} &    0.933 &   \fmaxn{0.861} & \fmaxn{0.829} &      5 & 1 \\
        \midrule
        \fmod{ITL-L2}    &          0.754 &           0.762 &                  0.751 &         \fmaxn{0.856} &          \fmaxn{0.855} &                 \fmaxn{0.856} &    \fmaxn{0.942} &   0.791 & 0.821 &      8 & 2 \\
        \fmod{CTL-L2}    &          \fmaxn{0.762} &           0.765 &                  \fmaxn{0.767} &         0.854 &          0.853 &                 0.851 &    0.933 &   0.853 & 0.830 &      3 & 1 \\
        \fmod{CMB-L2} &          0.757 &           0.764 &                  0.766 &         0.854 &          0.853 &                 0.853 &    0.934 &   0.853 & 0.829 &      4 & 1 \\
        \fmod{MTL-L2}    &          0.753 &           \fmaxn{0.766} &                  0.766 &         \fmaxn{0.856} &          \fmaxn{0.855} &                 \fmaxn{0.856} &    0.933 &   \fmaxn{0.864} & \fmaxn{0.831} &      1 & 1 \\
        \midrule
        \fmod{ITL-LS}    &          0.754 &           0.761 &                  0.750 &         \fmaxn{0.851} &          \fmaxn{0.850} &                 \fmaxn{0.851} &    0.943 &   0.791 & 0.819 &      9 & 2 \\
        \fmod{CTL-LS}    &          \fmaxn{0.757} &           \fmaxn{0.764} &                  0.766 &         0.845 &          0.847 &                 0.842 &    0.914 &   0.750 & 0.811 &     12 & 3 \\
        \fmod{CMB-LS} &          0.754 &           \fmaxn{0.764} &                  0.765 &         0.849 &          \fmaxn{0.850} &                 0.848 &    0.925 &   0.793 & 0.818 &     10 & 3 \\
        \fmod{MTL-LS}    &          \fmaxn{0.757} &           \fmaxn{0.764} &                  \fmaxn{0.767} &         \fmaxn{0.851} &          \fmaxn{0.850} &                 \fmaxn{0.851} &    \fmaxn{0.944} &   \fmaxn{0.858} & \fmaxn{0.830} &      2 & 1 \\
        \bottomrule
      \end{tabular}}
  \end{table*}

%Classification
The classification results in Table~\ref{tab:error_models_class_f1} show a similar behavior. In this table, the ranking is not computed for each problem, but in general, computing the mean of scores across all problems. This mean score is used to rank the models, which is the second left-most column, and, using the Wilcoxon-based procedure we produce a statistical significance ranking shown in the last column. In this case, the Wilcoxon tests are done with samples of size eight, the number of classification problems, so it is more difficult to find significant differences. In any case, the Wilcoxon test here uses a very small sample size and is given only for illustration purposes.
The convex \acrshort{mtl} approaches get the best 18 F1 scores out of 24 and the 22 best accuracy scores out of 24. The best overall model is the \fmod{MTL-L2}, while the other convex \acrshort{mtl} models are tied with it in the significance ranking.
%%%%%%%%%%%%%%%%%

















































































































\section{Application to Renewable Energy Prediction}\label{sec:convexmlt_renewable}

A transition towards renewable energies is taking place, with particular interest for solar and wind generation, which implies a demand for accurate energy production forecasts to be made for the transmission system operators, wind and solar farm managers and market agents. These forecasts can be made at different time horizons: very short (up to one hour), short (up to a few hours), or medium-long (one or more days ahead).
In~\citet{ruiz2020_energies} we presented an application of our convex \acrshort{mtl} techniques to renewable energies forecast, in particular we focus on the hourly, day-ahead prediction, that is, the prediction of tomorrow, of each hour, is given today.

Machine Learning (\acrshort{ml}), like in other forecasting scenarios, has an increasing presence in energy prediction approaches. 
The use of ML models requires choosing the predictive features, which depend on the time horizon of interest. 
For short-term forecast, past values of energy production and real time meteorological data can be used; however, for longer horizons the most common features are those from \acrfull{nwps}, that can be provided by entities such as the \acrfull{ecmwf}, which is the one used in this work.
For the hourly day-ahead predictions of interest here, we use the \acrshort{ecmwf} forecasts of the ECMWF run at \utc{00} in a given day to predict the hourly energy productions the day after. That is, using the \acrshort{ecmwf} generated at \utc{00}, the energy predictions are given for each hour from {24}h to {47}h.

After the selection of predictive features, the ML method better suited for the problem at hand has to be selected. Also, each method has a set of hyperparameters that influence its behaviour and have to be adjusted in each occasion.
%In the case of interest here, there are two possibilities: using local models for single installations or global models for multiple installations within a geographic area.

% Many ML approaches have been proposed for energy forecasting. 
% In the case of wind energy, prediction see, for example, the reviews of wind energy predictions of~\citep{giebel_soa,pinson2013,colak} or the application of concrete models to specific time-horizons~\citet{heinermann,zhu_genton}.
% For solar energy, we can see the surveys of~\citep{Antonanzas2016,Inman2013,Wan2015}, and a good reference for many aspects of photovoltaic energy can be found in~\cite{SEK}.

Anyway, any ML approach has to deal with the changing behaviour of a wind or solar farm, which can be altered substantially according to different conditions or time.
In the \acrfull{pv} energy production this is obvious, since different times of the day, from sunrise to sunset, have very different behaviours, but there are also seasonal effects that affect the energy generation in the solar farms.
For wind energy, it is more difficult to define the variables that determine different scenarios. 
The wind velocity forecast is the most relevant variable for energy generation, but it is important to take into account the power curve of wind turbines, which has three different response zones: one for low speed and near zero production, an intermediate one with power growing with wind velocity and one with~maximum constant power up to the cut-off speed.
The angle in which this wind incides is also important, since the turbines of a farm are set for a specific direction. 
Finally, the assymetric wind velocities between the day and night period can also affect the energy production.

One way to deal with these different behaviour scenarios is to apply an \acrshort{mtl} model, where the models built are specialized in each scenario but all scenarios are used in the learning process.
In this section a convex \acrshort{mtl} kernel-based approach will be used for wind and solar energy forecasting. To do this, it is necessary to define the tasks of interest on each case, which are described next.
In the first subsection the experimental methodology is described, showing how the models are chosen and the hyperparameters are selected. Then, the next two subsections present the approach and the detailed task definitions used for solar and wind energy, respectively, as well as the results to measure the performance.

\subsection{Experimental~Methodology}

%
\begin{table}[t!]
    \caption{Hyperparameters, grids used to find them (when appropriate), and hyperparameter selection method for each model. Here, $d$ is the number of {dimensions} % Please chang the font in the Table.
     of the data and $\sigma$ is the standard deviation of the~target.}
    \label{tab:hyperpars_grid_energies}
    \centering
    \scalebox{.65}{
     \begin{tabular}{*{5}{c}}
     \toprule
     \fhead{Par.} & \fhead{Grid} & \fhead{\fmod{CTL}} & \fhead{\fmod{ITL}} & \fhead{\fmod{MTL}} \\
     \midrule
      $C$ &  $\set{10^k: -1 \leq k \leq 6}$ & \acrshort{cv} & \acrshort{cv} & \acrshort{cv}  \\
      $\epsilon$ & $\set{\frac{\sigma}{2^k}: 1 \leq k \leq 6}$ & \acrshort{cv} & \acrshort{cv} & \acrshort{cv}  \\
      $\gamma$ & $\set{\frac{4^k}{d}: -2 \leq k \leq 3}$ & \acrshort{cv} & - & CTL \\
      $\gamma_r$ & $\set{\frac{4^k}{d}: -2 \leq k \leq 3}$ & - & \acrshort{cv} & ITL\\
      $\lambda$ & $\set{10^{-1}k: 0 \leq k \leq 10}$ & - & - & \acrshort{cv} \\
      \bottomrule
     \end{tabular}
    }
\end{table}

Here we describe the methodology that we have followed to conduct the experiments of renewable energy prediction.
%
For both solar and wind energy, we use the same procedure. In each problem, we have train, validation and test sets, each corresponding to one year of data. In the solar energy problems we have data from photovoltaic parks in Majorca and Tenerife, we consider 2013, 2014 and 2015 as train, validation and test sets, respectively, while for wind energy problems, where we have data from the Sotavento park, in Spain, we have the years 2016, 2017 and 2018.
%
For both solar and wind problems we apply different definition of tasks. We use only the training samples for establishing rules to partition the data in different tasks; then, with these tasks' definition, we apply them to get the tasks of the validation and test instances.
%
For example, if we consider the wind velocity to define three tasks, we study the velocities of the training samples to set the boundaries that define each task: low, medium and high velocity; then, we use these definitions on the validation and test sets.
%
We will represent the task definition applied with the nomenclature \fmodt{taskDef}{modelName}, where \fmod{taskDef} is a name for the task definition and \fmod{modelName} is the name of the model.

%
We consider three different models based on the standard Gaussian kernel SVR:
\begin{itemize}
    \item \fmod{CTL}: a \acrshort{ctl} model, that is, a single SVR for all tasks. Its set of hyperparameters is $\set{C, \gamma, \epsilon}$, where $C$ is the regularization trade-off parameter, $\gamma$ is the kernel width, and $\epsilon$ the width of the error insensitive area.
    \item \fmod{ITL}: an \acrshort{itl} model, that is, an independent SVR for each task, each with its hyperparameters: $\set{C_r, \gamma_r, \epsilon_r}$ for $r=1, \ldots, \ntasks$.
    \item \fmod{MTL}: a convex \acrshort{mtl} model, as shown in Section~\ref{sec:convexmlt_kernel}, whose corresponding set of hyperparameters is in principle $\set{C, \epsilon, \gamma, \gamma_1, \ldots, \gamma_\ntasks, \lambda_1, \ldots, \lambda_\ntasks}$, where $\gamma$ is the kernel width of the common part and $\gamma_r$ the one of the $r$-th specific part; also, $\lambda_r$ is the convex combination parameter corresponding to the $r$-th task.
\end{itemize}
%
Although the \acrshort{ctl} approach does not use the tasks information, the \acrshort{itl} and \acrshort{mtl} models depend on the task definition that we use. For instance, prediction at different hours can define different tasks, where one possible value is (\fmod{hour}=14) or (\fmod{hour}=12). The models using this task definition will be named \fmodt{hour}{ITL} and \fmodt{hour}{MTL}. 
%
Since each task definition partitions the data, we can also use multiple task definitions, combining them and creating finer partitions. 
We will name \fmod{(taskDef1,...,taskDefM)} the combination of task definitions \fmod{taskDef1},...,\fmod{taskDefM}. For example, consider the \fmod{(hour)} definition for solar energy, in which we take $14$ different hours, hence, $14$ tasks, and consider the \fmod{season} definition, which defines the prediction in each season as a different task, hence, four tasks. The combined definition \fmod{(hour, season)} generates $14 \times 4$ possible tasks, whose values can be, for example, \fmod{(hour = 12, season = summer)}.
The models using this combination will be named \fmodt{hour, season}{ITL} and \fmodt{hour, season}{MTL}.

%
As explained in Section~\ref{sec:convexmtlsvm_exp}, the cost of selecting the optimal hyperparameters scales exponentially with their number, so it is not feasible to use a \acrshort{cv} grid search, for example, if we have more than $3$ hyperparameters.
%
In the \fmod{CTL} and \fmod{ITL} it is not a problem, since we have $3$ hyperparameters per model: the single common \acrshort{svr}, and each one of the task-independent \acrshort{svr}s, respectively. We apply then a \acrshort{cv} grid search, with the train and validation sets described above.
However, to find the hyperparameters of \fmod{MTL} we have to make some adjustments, as discussed in Section~\ref{sec:convexmtlsvm_exp}. 
%
First, we apply a convex \acrshort{mtl} formulation with a single $\lambda$ parameter, common to all tasks.
%
Second, we use the optimal kernel widths selected in validation for the \acrshort{ctl} and \acrshort{itl} approaches as the widths in the \acrshort{mtl} approach. That is, we get the optimal common $\gamma^*$ and task-specific $\gamma^*_1, \ldots, \gamma^*_\ntasks$, and fix them in the \fmod{MTL} model, not including them in the grid search procedure.
Then, we apply a \acrshort{cv} grid search to find the optimal values of the remaining hyperparameters, that is, $\set{C, \epsilon, \lambda}$.
%
In Table~\ref{tab:hyperpars_grid_energies} we show the method to obtain each hyperparameter, as well as the grids considered in the \acrshort{cv} grid search procedures.
We use the \acrshort{mae} as the validation metric, because it is the most natural for the $\epsilon$-insensitive loss that is used in the SVRs, and the most common in energy forecasting.

%
The complete procedure to get the final scores is:
\begin{enumerate}
    \item \textbf{Scale the target and normalize the features.} We scale the target values to $[0, 1]$ and we normalize each feature, so it has $0$ mean and a standard deviation of $1$. This is done using the training data only. 
    For the target scale, we select the target minimum and maximum values, that is, $y_\text{min} = 0$, when no energy is produced, and $y_\text{max}$ is the maximum capacity of the park.    
    %Then, the target in train, validation and test sets is normalized as     $y_\text{scaled} = (y - y^\text{tr}_\text{min}) / (y^\text{tr}_\text{max} - y^\text{tr}_\text{min} )$.
    %For example, for feature normalization, we compute the training mean $\mu_d^\text{tr}$ and standard deviation $\sigma_d^\text{tr}$ of feature $d$, then we normalize the corresponding feature in the whole dataset using $\hat{X}_d = (\hat{X}_d - \mu_d^\text{tr}) /  \sigma_d^\text{tr}$.
    \item \textbf{Use a \acrshort{cv} grid search to select the optimal hyperparameters.} This is done with the train and validation sets, with the grids and adjustements already explained. We use the MAE as our validation metric.
    \item \textbf{Predict on the test set and rescale to the original scale.} That is, we use the corresponding model $f(\cdot)$ to compute the prediction of the normalized $i$-th test example from task $r$, $\tilde{x}_i^r$, as $f(\tilde{x}_i^r)$. Then, we rescale it back to obtain the final prediction $\hat{y}_i^r = f(x_i^r)  (y_\text{max} - y_\text{min} ) + y_\text{min}$.
    \item \textbf{Compute the test score.} Using the target values $y_i^r$ and their corresponding predictions, $\hat{y}_i^r$, we measure the performance of our model using both MAE and MSE.
\end{enumerate}
The entire process is carried out using a \fcode{Pipeline} object, where we make use of the class \fcode{StandardScaler} to normalize the data, and the \fcode{TransformedTargetRegressor} class to scale the targets. All these classes are part of the \emph{scikit-learn} library~\citep{scikit-learn}.

%
To put our results in perspective, we also show the errors of simple persistence models and of multilayer perceptrons. For the perceptron we use the \fcode{MLPRegressor} class of \emph{scikit-learn}. The architecture for both problems consists on fully connected networks with two hidden layers, with $100$ and $50$ neurons. We train these networks using the L-BFGS solver with a maximum of $800$ iterations and a tolerance of $10^{-10}$. The regularization hyperparameter is selected using a \acrshort{cv} grid search, as those described above, where the grid is $\set{4^k: -2 \leq j \leq 3}$.






\subsection{Solar Energy}

\begin{figure}[t!]
    \centering%
    \subfloat[][Hourly photovoltaic energy mean in \fdata{majorca}.]{%    
    \includegraphics[width=.35 \textwidth]{Chapter6/energies/majorca_groupby_hour_train.pdf}
    \label{fig:maj_groupby_hour}}\quad%
    \subfloat[][Hourly photovoltaic energy mean in \fdata{tenerife}.]{%
    \includegraphics[width=.35 \textwidth]{Chapter6/energies/tenerife_groupby_hour_train.pdf}
    \label{fig:ten_groupby_hour}}\\
    \subfloat[][Monthly photovoltaic energy mean in \fdata{majorca}.]{%
    \includegraphics[width=.35 \textwidth]{Chapter6/energies/hist_season_majorca_train_byMonth.pdf}
    \label{fig:maj_groupby_season}}\quad%
    \subfloat[][Monthly photovoltaic energy mean in \fdata{tenerife}.]{%
    \includegraphics[width=.35 \textwidth]{Chapter6/energies/hist_season_tenerife_train_byMonth.pdf}
    \label{fig:ten_groupby_season}}
 \caption{\label{fig:solar_task_def}Hourly photovoltaic energy mean {in} \fcode{majorca} {and} \fcode{tenerife} measured in \mwhu{}. Photovoltaic energy monthly averages for \fcode{majorca} and \fcode{tenerife}, colored with the tasks defined using the season and measured in \mwhu{}. All the histograms have been computed using data from year~2016.}
 \end{figure}

The goal is to predict the hourly energy production in the islands of Majorca and Tenerife, and the corresponding problems are named \fdata{majorca} and \fdata{tenerife}, respectively. 
%
In this subsection the experiments with these solar problems are presented, using the experimental procedure already described. First a description of the problems and the data used is given; then the results are presented and analyzed.

%\subsubsection*{Data and~Tasks}
For both problems, \fdata{majorca} and \fdata{tenerife}, the same variables, extracted from the \acrshort{ecmwf}, are used:
%These variables, extracted from \acrshort{ecmwf} predictions made by the European Center for Medium Weather Forecasts 
%(ECMWF;~\cite{ECMWF}), are:
\begin{itemize}
    \item Surface net solar {radiation} (\ftt{SSR}).
    \item Surface solar radiation {downwards} (\ftt{SSRD}).
    \item {Total Cloud Cover} %Please change it not to be captitalized if unnecessary.
     (\ftt{TCC}).
    \item Temperature at 2 {meters} above surface (\ftt{T2M}).
    \item Module of the speed of wind at {10 meters} above surface (\ftt{v10}).
\end{itemize}
The radiation variables \ftt{SSR}, solar radiation, and \ftt{SSRD}, the diffuse radiation scattered by the atmosphere plus solar radiation, as well as the \ftt{TCC}, have all a direct impact on \acrshort{pv} production.
%
The \ftt{T2M} and \ftt{v10} features are also considered because they influence the conversion of photon energy into electrical one, and also the overall performance of \acrshort{pv} stations.
%

To collect these features, geographical grids with a $\ang{0.125}$ spatial resolution are considered. For \fdata{majorca}, the grid has its northeast coordinates at $(\ang{2}, \ang{40})$, and its southwest coordinates at $(\ang{4}, \ang{39})$. For \fdata{tenerife}, the coordinates are $(\ang{-17.5}, \ang{28.75})$ for the northwest corner, and $(\ang{-15.5}, \ang{27.75})$ for the southeast one.
%
That is, both grids have a longitude width of 2 degrees and a latitude height of 1 degree. With the spatial resolution considered, this results in a total number of $17 \times 9 = 153$ grid points; since we use five variables at every point, the total dimension of our data is thus $5 \times 153 = 765$. 


%
Observe that we obtain large dimensional patterns, where the features might be highly correlated. That is, a feature, \ftt{SSR} for example, measured in one point of the grid and another close point might be very correlated, since the entire grids are squares with sides of about $\km{12}$.
This correlation will affect those models based on matrix-vector computations, such as linear models, but, also, to some extent, to neural networks.
Although ridge (or Tikhonov) regularization can alleviate this issue for these models, kernel-methods, such as the kernel \acrshort{svm}s, seems better suited for this kind of problems.
When we apply kernels, like the Gaussian kernel $$\exp({-\gamma \norm{x-y}^2}),$$ the algorithm learns using the distances among patterns $\norm{x - y}$, instead of its features.
%
%These distances scale linearly with the dimension of data $\dimx$; 
Consider the features scaled to $[0, 1]$, then a rough estimate of the distance between two patterns would scale linearly with $d$. In the extreme case where all features are equal, i.e. $x_j = x_1$ for all $j=1, \ldots, \dimx$, then $\norm{x - x'} = d \abs{x_1 - {x'}_1} $.
However, this influence of the dimension can be easily controlled by $\gamma$, and, if selected properly, should not affect the performance of a Gaussian SVR.

%
Recall that we use data from years 2013, 2014 and 2015 as train, validation and test sets, respectively.
%
We show the errors in both total \mwhu{} and as percentages, in the range $[0, 100]$ of the total install \acrshort{pv} power in each island, {\mw{72.46}} in \fdata{majorca} and \mw{107.68} in \fdata{tenerife}.
%
We remove night data for obvious reasons and make predictions between \utc{06} and \utc{19} {for} \fcode{majorca} and between \utc{07} and \utc{20} for \fcode{tenerife}.
%
The hour of the day has a direct influence on the solar radiation, and, therefore, on energy production. Also, the season of the year has a similar impact on the production. This leads to two obvious task definitions:
\begin{itemize}
    \item	\fcode{hour}: The prediction at each hour is defined as a different task; there are thus 14 tasks in \fcode{majorca} (from 06 to \utc{19}) and \fcode{tenerife} (from 07 to \utc{20}).
    %We observe in Figures~\ref{fig:maj_groupby_hour} and~\ref{fig:ten_groupby_hour} that the distribution of the target, i.e.,~the photovoltaic energy, is very dependent on the hour chosen.
    \item	\fcode{season}: The prediction at each season is defined as a different task.  With~a slight abuse of language, the following definitions for each season are used: Spring, from~16 February to 15 May; Summer, from~16 May to 15 August; Autumn, from~16~August to 15 November; and~Winter, from~16 November to 15 February.
    %We can observe in Figures~\ref{fig:maj_groupby_season} and~\ref{fig:ten_groupby_season} that different seasons have different means of the target.
\end{itemize}
%
In Subfigures~\ref{fig:maj_groupby_hour} and~\ref{fig:ten_groupby_hour} the hourly averages of the \acrshort{pv} energy in \mwhu{} are shown for \fdata{majorca} and \fdata{tenerife}.
Also, in Subfigures~\ref{fig:maj_groupby_season} and~\ref{fig:ten_groupby_season} we show the monthly averages, colored by season, where we take the season in first half of each month to select the color.

 




%\subsubsection*{Experimental~Results}

\begin{table}[t!]
    \caption{Test \acrshort{mae} (left), test \acrshort{mse} (center), with the corresponding rankings and associated Wilcoxon-based rankings, and optimal mixing $\lambda^*$ (right) of the solar energy models considered {in} \fcode{majorca}. {Base units} are \mwhu{} or percentages (\%) for the \acrshort{mae}, and \mwhusq{} or permyriad ({\textpertenthousand}) for \acrshort{mse}, whose root values are percentages of the \acrshort{rmse}.  The~best model errors are shown in~bold.}
    \centering
    \label{table:solar_scores_m}
    \scalebox{.65}{
    \begin{tabular}{lccccccccc}
        \toprule
        & \fheadmulti{4}{MAE} & \fheadmulti{4}{MSE} & \fhead{$\lambda^*$}\\
        & {{\mwhu}}	& {{\%}} & {rank} & {Wil.} & {{\mwhusq}}	& {{\textpertenthousand}} & {rank} &  {Wil.}\\
        \midrule
        \fmod{CTL}    &  5.265 &  7.265  & (6) & (4) &  59.322 &  112.985  & (6) & (4) &  - \\
        \fmod{(season)\_ITL}   &  5.305 &  7.384  & (7) & (5) &  59.591 &  113.498  & (7) & (4) &  - \\
        \fmod{(season)\_MTL}   &  \fmaxn{4.884} &  \fmaxn{6.740}  & \fmaxn{(1)} & \fmaxn{(1)} &  53.222 &  101.366  & (2) & (3) &  0.4 \\
        \fmod{(hour)\_ITL}   &  5.083 &  7.015  & (4) & (2) &  54.540 &  103.877  & (3) & (3) &  - \\
        \fmod{(hour)\_MTL}   &  4.957 &  6.840  & (2) & (1) &  \fmaxn{52.614} &  \fmaxn{100.208}  & \fmaxn{(1)} & \fmaxn{(1)} &  0.3 \\
        \fmod{(hour, season)\_ITL}   &  5.250 &  7.251  & (5) & (3) &  57.927 &  110.328  & (5) & (4) &  - \\
        \fmod{(hour, season)\_MTL}   &  5.038 &  6.952  & (3) & (2) &  54.601 &  103.992  & (4) & (3) &  0.3 \\
        \bottomrule
    \end{tabular}
    }
 \end{table}
\unskip


 \begin{table}[t!]
    \caption{Test \acrshort{mae} (left), test \acrshort{mse} (center), with the corresponding rankings and associated Wilcoxon-based rankings, and optimal mixing $\lambda^*$ (right) of the solar energy models considered {in} \fcode{tenerife}. {Base units} are \mwhu{} or percentages (\%) for the \acrshort{mae}, and \mwhusq{} or permyriad ({\textpertenthousand}) for \acrshort{mse}, whose root values are percentages of the \acrshort{rmse}. The~best model errors are shown in~bold. 
    %The positions in bold correspond to the model ranked first in terms of MAE or MSE, as indicated by its column.
    }
    \centering
    \label{table:solar_scores_t}
    \scalebox{.65}{
    \begin{tabular}{lccccccccc}
        \toprule
        & \fheadmulti{4}{MAE} & \fheadmulti{4}{MSE} & \fhead{$\lambda^*$}\\
        & {{\mwhu}}	& {{\%}} & {rank} & {Wil.} & {{\mwhusq}}	& {{\textpertenthousand}} & {rank} &  {Wil.}\\
        \midrule
        \fmod{CTL}    &  5.786 &  5.373  & (5) & (5) &   88.323 &  76.174  & (5) & (5) &  - \\
        \fmod{(season)\_ITL}   &  5.930 &  5.545  & (6) & (5) &   97.454 &  84.611  & (6) & (6) &  - \\
        \fmod{(season)\_MTL}   &  5.579 &  5.181  & (4) & (2) &   86.227 &  74.366  & (3) & (3) &  0.8 \\
        \fmod{(hour)\_ITL}   &  5.403 &  5.018  & (2) & (2) &   86.686 &  74.762  & (4) & (4) &  - \\
        \fmod{(hour)\_MTL}   &  \fmaxn{5.376} &  \fmaxn{4.993}  & \fmaxn{(1)} & (1) &   \fmaxn{84.207} &  \fmaxn{72.624}  & \fmaxn{(1)} & (1) &  0.7 \\
        \fmod{(hour, season)\_ITL}   &  6.025 &  5.554  & (7) & (6) &  104.536 &  90.297  & (7) & (7) &  - \\
        \fmod{(hour, season)\_MTL}   &  5.494 &  5.102  & (3) & (3) &   85.440 &  73.687  & (2) & (2) &  0.7 \\
        \bottomrule
    \end{tabular}
    }
 \end{table}
\unskip


% \begin{table}[t!]
%    \caption{Wilcoxon $p$-values for absolute (left) and quadratic (right) errors.}
%    \centering
%    \label{table:solar_wilcoxon}
%    %% \tablesize{} %% You can specify the fontsize here, e.g.,~\tablesize{\footnotesize}. If commented out \small will be used. Is the bold necessary. Same as others in the table.
%    \scalebox{.65}{
%    \begin{tabular}{lcccc}
%       \toprule
%       & \fheadmulti{2}{MAE} &  \fheadmulti{2}{MSE}\\
%       & {\fcode{majorca}}	& {\fcode{tenerife}} & {\fcode{majorca}}	& {\fcode{tenerife}}\\
%       \midrule
%     \fmod{CTL}                           &    0.014 (4) &    0.000 (5) &    0.081 (4) &    0.000 (5) \\
%     \fmod{(season)\_ITL}                &    0.008 (5) &    0.636 (5) &    0.215 (4) &    0.354 (5) \\
%     \fmod{(season)\_MTL}         &   {(1)} &    0.000 (4) &    0.036 (2) &    0.000 (3) \\
%     \fmod{(hour)\_ITL}                  &    0.693 (2) &    0.006 (2) &    0.000 (3) &    0.000 (4) \\
%     \fmod{(hour)\_MTL}           &    0.067 (1) &   ------ {(1)} &   ------ {(1)} &   ------ {(1)} \\
%     \fmod{(hour, season)\_ITL}        &    0.000 (3) &    0.000 (6) &    0.000 (4) &    0.098 (5) \\
%     \fmod{(hour, season)\_MTL} &    0.000 (2) &    0.000 (3) &    0.745 (3) &    0.000 (2) \\
%     \bottomrule
%     \end{tabular}
%    }
% \end{table}

We show the numerical results for \fdata{majorca} and \fdata{tenerife} in Tables~\ref{table:solar_scores_m} and~\ref{table:solar_scores_t}, respectively. We give the test MAE, which is the most natural metric for SVRs, as well as the MSE. 
In the case of percentages, for MAE, we give the percentage corresponding to the total installed power, and for the MSE, the permyriad, that is, per \num{10000}, of the installed power. Concretely, since the \acrshort{mse} gives information of the squared errors, we compute these permyriad values as 
$$ 100^2 (\text{MSE}/\text{PV}_\text{max}^2) ,$$
where $\text{PV}_\text{max}^2$ is the maximum installed power; thus, the root of these values are the percentages of the \acrfull{rmse}:
$$ 100 (\text{RMSE}/\text{PV}_\text{max}) .$$
%
We also show the rankings in terms of MAE or MSE, and the optimal hyperparameter $\lambda^*$ selected by the \acrshort{cv} for the \acrshort{mtl} models.
%

The Wilcoxon test is used to assess statistical significance, but instead of testing every pair of models, the rankings of Tables~\ref{table:solar_scores_m} and~\ref{table:solar_scores_t} are given. As explained before, we first sort the models and then the Wilcoxon test is applied between each model and the next in the ranking, at the $0.05$ level, to determine whether the difference is significant.
The test is applied over the list of errors commited by each model in the patterns of the test set; we consider absolute errors for the \acrshort{mae} ranking and squared errors for the \acrshort{mse} one. 
%
When the null hypothesis of the Wilcoxon test is rejected, we can assume that the distribution of the difference between the errors does not have its median at $0$.
%In Table~\ref{table:solar_wilcoxon}, we show the $p$-values of the pairwise tests. If the $p$-value is smaller than the considered level of 0.05, then the different between models is considered significant.
%
With this procedure, a new significance ranking is generated: starting from the best model, we compare each model with the next best one, and we increase the ranking only if the difference is significant. 
%In Tables~\ref{table:solar_scores_m} and~\ref{table:solar_scores_t} we present these significance rankings for both the \acrshort{mae} and \acrshort{mse} corresponding rankings.
%
For example, in Table~\ref{table:solar_scores_m}, in terms of MAE, the first model, \fmod{(season)\_MTL}, is tested against the second one, \fmod{(hour)\_MTL}. 
However, if we apply the Wilcoxon test to their corresponding list of errors, the null hypothesis is not rejected, so we give to both models the same significance ranking.
%In Table~\ref{table:solar_wilcoxon}, we show the $p$-value corresponding to that test, which is $0.067$, and since it is larger than the level $0.05$, the ranking is not increased and we give to both models the same significance ranking. 

%
Looking at the tables, it is easy to see that the \acrshort{mtl} approaches obtain the best results in both problems, while \fmod{CTL} has the worst performance in \fcode{tenerife} and second worst in \fcode{majorca}.
\acrshort{itl} models are more difficult to interpret: although they are always behind their corresponding \acrshort{mtl} approaches, they can obtain good results, see the \fmodt{hour}{ITL} in \fdata{majorca} which is second; but they can also have bad performances, as the \fmodt{season}{ITL} in \fdata{tenerife}.

%
The $\lambda^*$ values can help to understand this behaviour. In both problems, the selected values lie far from the extremes $0$ (\acrshort{itl}-equivalent) or $1$ (\acrshort{ctl}-equivalent). Therefore, the validation scores of the \acrshort{ctl} or \acrshort{itl}-equivalent models are worse than those of a pure \acrshort{mtl} approach. This is reflected also in the test set, as shown in the tables.
Moreover, it is noticeable that the optimal values for \fdata{majorca} are all smaller than $0.5$, which can be intepreted as models with a stronger common part, while in \fdata{tenerife} the optimal values are larger than $0.5$, which reflects stronger independent parts.
%
Although the \acrshort{mtl} approaches get the best results with any task definition, the \fmod{(hour)} definition seems to work best than the \fmod{(season)} one. The \fmodt{hour}{MTL} gets a second best result, which is not significantly worse than the best one in \fdata{majorca}, and is the single best result in \fdata{tenerife}.

%
For completeness, the scores of persistence models and a neural network are given here.
The persistence forecasts are obtained by predicting at each hour the production value 24 hours prior. By doing this, the MAE scores for \fdata{majorca} and \fdata{tenerife} are \mwh{5.776} and \mwh{7.766}, which scaled to $[0, 100]$ correspond to 7.97\% and 7.21\%; which are an 18\% and 44\% error increase of the best \acrshort{mtl} models.
The neural network errors are \mwh{5.140} and \mwh{5.763}, that is, 7.09\% and 5.35\% of the total \acrshort{pv} installed. While this results are still competitive, this performance is worse than those of the convex \acrshort{mtl} models proposed.


\begin{figure}[t!]
    \centering%
    \subfloat[\acrshort{ctl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_ctl_majorca.pdf}
    \label{fig:best_ctl_majorca}}\quad%
    \subfloat[\acrshort{itl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_itl_majorca.pdf}
    \label{fig:best_itl_majorca}}\quad%
    \subfloat[\acrshort{mtl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_mtl_majorca.pdf}
    \label{fig:best_mtl_majorca}}\\
 \caption{\label{fig:majorca_best_plots} Real energy production against the prediction made by the best  models {in} \fcode{majorca}; the perfect prediction line is shown in orange. The~units of the axis are \mwhu{}.}
\end{figure}

\begin{figure}[t!]
    \centering%
    \subfloat[\acrshort{ctl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_ctl_tenerife.pdf}
    \label{fig:best_ctl_tenerife}}\quad%
    \subfloat[\acrshort{itl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_itl_tenerife.pdf}
    \label{fig:best_itl_tenerife}}\quad%
    \subfloat[\acrshort{mtl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_mtl_tenerife.pdf}
    \label{fig:best_mtl_tenerife}}\\
 \caption{\label{fig:tenerife_best_plots} Real energy production against prediction made by the best models {in} \fcode{tenerife}; the perfect prediction  line is shown in orange. The~units of the axis are \mwhu{}.}
\end{figure}


%
To get a better understanding of the results, we plot the predictions against the target values of the \acrshort{ctl} model and of the best \acrshort{itl} and \acrshort{mtl} ones.
%
In the case of \fdata{majorca}, we plot the predictions \fmod{CTL}, \fmodt{hour}{ITL} and \fmodt{season}{MTL} in Figure~\ref{fig:majorca_best_plots}.
From these scatter plots it seems that the \acrshort{ctl} approach has a larger deviation in its predictions, while the \acrshort{itl} one has a bias, that is, it systematically underestimates the prediction corresponding to larger values of energy production.
The \acrshort{mtl} approach seems to correct, to a certain degree, this bias of the \acrshort{itl} model, while preserving a smaller variance than the \acrshort{ctl} one.
%
For \fdata{tenerife} we plot the predictions of \fmod{CTL}, \fmodt{hour}{ITL} and \fmodt{hour}{MTL}, which are shown in Figure~\ref{fig:tenerife_best_plots}.
It is more difficult to interpret the plots in this case, although it is possible to highlight that the \acrshort{mtl} approach seems less prone to overestimate the production at lower values than either the \acrshort{ctl} or \acrshort{itl} models.







\subsection{Wind Energy}
We want to predict the wind energy production at the Sotavento wind park located in Galicia, Spain.
Wind energy forecasting is more challenging than the photovoltaic one, due to the unstable nature of the wind, whose behavior is more chaotic than that of solar radiation. Detecting scenarios where the wind energy production behaves differently but is stable inside each one seems crucial, but it is a difficult task. Looking at different characteristics of wind energy production we establish some task definitions and use them to test our proposal. 

%\subsubsection*{Data and~Tasks}

\begin{figure}[t!]
    \centering%
    \subfloat[Histogram of wind angles colored by task definition \fmod{angle}.]{%
    \includegraphics[width=.38 \textwidth]{Chapter6/energies/polarhist_tasks_angle_stv_train.pdf}
    \label{fig:stv_task_angle}}\quad%
    \subfloat[Histogram of wind velocity (\si{\metre/\second}) in Sotavento colored by {task} definition \fmod{velocity}.]{%
    \includegraphics[width=.38 \textwidth]{Chapter6/energies/hist_tasks_velocity_stv_train.pdf}
    \label{fig:stv_task_velocity}}\\
 \caption{\label{fig:wind_task_def} Histograms of wind derived from \acrshort{ecmwf} data for the year 2016 in Sotavento.}
\end{figure}




The variables from the \acrshort{ecmwf} that we consider as predictors are:
\begin{itemize}
    \item	Eastward component of the wind at \si{10\metre} %Please remove the font. Same as below
     (\ftt{U10}).
    \item	Northward  component of the wind at \si{10\metre} (\ftt{V10}).
    \item   Module of velocity of the wind at \si{10\metre} (\ftt{vel10}).
    \item	Eastward  component of the wind at \si{100\metre} (\ftt{U100}).
    \item	Northward component of the wind at \si{100\metre} (\ftt{V100}).
    \item   Module of velocity of the wind at \si{100\metre} (\ftt{vel100}).
    \item   Surface {pressure} (\ftt{sp}).
    \item	2 meter {temperature} (\ftt{2t}).
\end{itemize}
These variables are collected in a grid, which is approximately centered at the farm, with northwest and southeast coordinates at $(\ang{-9.5}, \ang{44})$ and $(\ang{-6}, \ang{42.25})$, respectively, and a spatial resolution of $\ang{0.125}$.
This results in a grid with $435$ points, that, with the $8$ variables considered at each point, gives a total number of {3480} predictive features.
We scale the energy productions values to $[0, 100]$ using the maximum power installed (\mw{17.56}), which corresponds to the value $100$.
%
Recall that we have three years of data, 2016, 2017 and 2018, which are used as train, validation and test sets.
%
Although there are no obvious task definitions, we consider three different criteria:
\begin{itemize}
    \item \fmod{angle}: Here the wind angle at a height of \si{100\metre} is considered, which is obtained from the \ftt{U100} and \ftt{V100} variables. 
    First, the most frequent angle is estimated, which is $\ang{56}$, and then, we use it as the center of the first quadrant. That is, the patterns that correspond to the first task as those whose wind angle lies between ${11}$ and $\ang{101}$  The other three quadrants, corresponding to a different task each, are defined by the remaining sectors of $\ang{90}$.
    The histogram of wind angles, and the defined quadrants in different colors, are shown in Figure~\ref{fig:stv_task_angle}.
    \item \fmod{velocity}: Here the wind velocity at a height of \si{100\metre} is considered, which is again obtained from the \ftt{U100} and \ftt{V100} variables. The speed boundaries selected to define three tasks are $4$ and $10$m/s, which, for an ideal generator, are approximately the starting point of wind energy generation and its maximum power plateau, before cut-off speed.   
    In Figure~\ref{fig:stv_task_velocity} the histrogram of velocities is shown with the task regions colored. 
    \item \fmod{timeOfDay}: Here the 24 hours of a day are divided in two 12 hours periods: a day period between 08 and \utc{19}, and~a night one between 20 to \utc{07}.
\end{itemize}

\begin{figure}[t!]
    \centering
    \subfloat[{Hourly mean} of generated energy (\si{\kilo{\watt\hour}}) colored by {task} definition \fmod{timeOfDay}.]{%
    \includegraphics[width=.45 \textwidth]{Chapter6/energies/hist_timeOfDay_stv_train_byHour.pdf}
    \label{fig:hist_timeOfDay_stv_target}}%
    \quad%
 \subfloat[Hourly mean of velocity (\si{\metre/\second}) at \SI{100}{\metre} colored by {task} definition \fmod{timeOfDay}.]{%
     \includegraphics[width=.45 \textwidth]{Chapter6/energies/hist_timeOfDay_stv_vel100_byHour.pdf}
     \label{fig:hist_timeOfDay_stv_vel100}}
 % \hspace{\fill}
 \caption{\label{fig:wind_task_def} Histograms of generated energy and wind velocities derived from \acrshort{ecmwf} data for the year 2016 in Sotavento.}
 \end{figure}

 
\begin{figure}[t!]
    \centering
    \includegraphics[width=.5\textwidth]{Chapter6/energies/hist_timeOfDay_stv_vel100_normal.pdf}
  \caption{\label{fig:stv_vel100} Histograms of the velocity of wind at 100m derived from \acrshort{ecmwf} data for the year 2016 and measured in m/s during the day and night in Sotavento.
 %  \comm{decir para qu ao. Hay una cosa que no entiendo: a ojo parece que hay ms datos de night que de day, lo que no debera ser. Pero mirando la fig anterior hay 11 horas night-azul- y 13 day naranja. Claramente est mal, pero as las cosas los colores de abajo estn al revs}
 }
 \end{figure}

%
In Figures~\ref{fig:hist_timeOfDay_stv_target} and~\ref{fig:hist_timeOfDay_stv_vel100} the hourly average energy production and wind speed are shown, with the hours colored according to the two tasks defined. In Figure~\ref{fig:stv_vel100} the histograms of wind velocity in the night and day periods are shown.
%
For these task definitions, it is necessary to perform an analysis of the data, which is done only using the train set, corresponding to 2016.
The tasks in this case are not as clear-cut as those defined for the solar energy. For the \fmod{angle} and \fmod{velocity} definitions some differences across tasks in the histograms can be found, but not remarkable ones.
For the \fmod{timeOfDay} definition, the two histograms of Figure~\ref{fig:stv_vel100} look very similar.
Moreover, the boundaries of the tasks are set in a way that is partially arbitrary, and a bad selection of tasks could lead to poor results.


%\subsubsection*{Experimental~Results}


\begin{table}[t!]
    \caption{Test \acrshort{mae} (left), {\acrshort{mse}} (center), with the corresponding rankings and associated Wilcoxon-based rankings, and optimal mixing $\lambda^*$ (right) of the Sotavento wind energy models considered. The~best model errors are shown in~bold.}
    \centering
    \label{table:wind_scores}
    %% \tablesize{} %% You can specify the fontsize here, e.g.,~\tablesize{\footnotesize}. If commented out \small will be used.
    \scalebox{.65}{
    \begin{tabular}{lccccccc}
    \toprule
    & \fheadmulti{3}{MAE} &  \fheadmulti{3}{MSE} &  \fhead{$\lambda^*$}\\
%    & \fhead{\fcode{stv}}	& \fhead{\fcode{stv}} & \fhead{\fcode{stv}} \\
& {{\mwhu}} & {rank} & {Wil.} & {{\mwhusq}} & {rank} &  {Wil.}\\
    \midrule
    \fmod{CTL}                                           &   \fmaxn{6.132} & \fmaxn{(1)} & \fmaxn{(1)} &    90.228 & (2) & (2) & - \\
    \fmod{(velocity)\_ITL}                              &  6.211 & (7) & (3) &   93.363 & (7) & (3) & - \\
    \fmod{(velocity)\_MTL}                       &   6.208 & (6) & (3) &    93.199 & (6) & (3) & 0 \\
    \fmod{(timeOfDay)\_ITL}                             &  6.283 & (9) & (4) &   93.594 & (9) & (4) & - \\
    \fmod{(timeOfDay)\_MTL}                      &   \fmaxn{6.132} & \fmaxn{(1)} & \fmaxn{(1)} &    90.228 & (2) & (2) & 1 \\
    \fmod{(timeOfDay, velocity)\_ITL}                 &  6.341 & (11) & (4) &   97.250 & (11) & (5) & - \\
    \fmod{(timeOfDay, velocity)\_MTL}          &  6.312 & (10) & (4) &   94.774 & (10) & (4) & 0.4 \\
    \fmod{(timeOfDay, angle)\_ITL}                    &  6.266 & (8) & (4) &   93.517 & (8) & (4) & - \\
    \fmod{(timeOfDay, angle)\_MTL}             &   \fmaxn{6.132} & \fmaxn{(1)} & \fmaxn{(1)} &    90.228 & (2) & (2) & 1 \\
    \fmod{(timeOfDay, angle, velocity)\_ITL}        &  6.410 & (12) & (4) &  102.031 & (12) & (6) & - \\
    \fmod{(timeOfDay, angle, velocity)\_MTL} &   \fmaxn{6.132} & \fmaxn{(1)} & \fmaxn{(1)} &    90.228 & (2) & (2) & 1 \\
    \fmod{(angle)\_ITL}                                 &   6.170 & (4) & (3) &    91.586 & (4) & (3) & - \\
    \fmod{(angle)\_MTL}                          &   6.135 & (2) & (2) &    \fmaxn{90.026} & \fmaxn{(1)} & \fmaxn{(1)} & 0.9 \\
    \fmod{(angle, velocity)\_ITL}                     &   6.173 & (5) & (3) &    92.529 & (5) & (3) & - \\
    \fmod{(angle, velocity)\_MTL}              &   6.168 & (3) & (3) &    90.990 & (3) & (3) & 0.7 \\
    \bottomrule
    \end{tabular}
    }
\end{table}



% \begin{table}[t!]
%     \caption{\comm{TODO: alinear rankings }Wilcoxon $p$-values and {corresponding} %Please add explanations of ``''. In addition, please remove bold if appropritate.
%      rankings for absolute (right) and square (left) wind energy errors in~Sotavento. The positions in bold correspond to the model ranked first in terms of MAE or MSE, as indicated by its column.}
%     \centering
%     \label{table:wind_wilcoxon}
%     %% \tablesize{} %% You can specify the fontsize here, e.g.,~\tablesize{\footnotesize}. If commented out \small will be used.
%     \scalebox{.65}{
%     \begin{tabular}{lcc}
%     \toprule
%     & \fhead{MAE} &  \fhead{MSE}\\
% %    & \fhead{\fcode{stv}}	& \fhead{\fcode{stv}} \\
%     \midrule
% \fmod{CTL}                                           &     ------  {(1)} &    ------   (2)  \\
% \fmod{(velocity)\_ITL}                              &    0.570  (3) &    0.150  (3)  \\
% \fmod{(velocity)\_MTL}                       &    0.356  (3) &    0.466 (3)  \\
% \fmod{(timeOfDay)\_ITL}                             &    0.195  (4) &    0.258  (4)  \\
% \fmod{(timeOfDay)\_MTL}                      &      ------   {(1)} &      ------   (2)  \\
% \fmod{(timeOfDay, velocity)\_ITL}                 &    0.941  (4) &    0.021  (5)  \\
% \fmod{(timeOfDay, velocity)\_MTL}          &    0.428  (4) &    0.650 (4)  \\
% \fmod{(timeOfDay, angle)\_ITL}                    &    0.000  (4) &    0.015  (4)  \\
% \fmod{(timeOfDay, angle)\_MTL}             &      ------   {(1)} &      ------   (2)  \\
% \fmod{(timeOfDay, angle, velocity)\_ITL}        &    0.090  (4) &    0.024  (6)  \\
% \fmod{(timeOfDay, angle, velocity)\_MTL} &   ------  {(1)} &    ------   (2)  \\
% \fmod{(angle)\_ITL}                                 &    0.855  (3) &    0.644  (3)  \\
% \fmod{(angle)\_MTL}                          &    0.035  (2) &   ------  {(1)} \\
% \fmod{(angle, velocity)\_ITL}                     &    0.253  (3) &    0.465  (3)  \\
% \fmod{(angle, velocity)\_MTL}              &    0.018  (3) &    0.001 (3)   \\
% \bottomrule
%     \end{tabular}
%     }
% \end{table}

Regarding the experimental results for wind energy prediction, in Table~\ref{table:wind_scores} the MAE and MSE scores are shown, and also the ranking is given in parentheses. 
Unlike the solar energy case, here the \acrshort{ctl} approach seems better suited than using an \acrshort{itl} one. This is also reflected in the selection of $\lambda^*$ values in the models that get best results, which are close to $1$, the \acrshort{ctl} equivalent case. That is, \acrshort{mtl} models such as \fmodt{timeOfDay}{MTL}, \fmodt{timeOfDay, angle}{MTL} and \fmodt{timeOfDay, angle, velocity}{MTL}, where $\lambda^*=1$, obtain the best results and are equivalent to \fmod{CTL}. Also note the cases of \fmodt{angle}{MTL} and \fmodt{angle, velocity}{MTL}, that are second and third best, and where the selected values are $\lambda^*=0.9$ and $\lambda^*=0.7$.
Those models that put the emphasis on the independent parts, like \fmodt{timeOfDay, velocity}{MTL}, and, of course, the \acrshort{itl} approaches, get worse results.
%
%
As with the solar energy problems, the statistical significance of the results is tested using the Wilcoxon test. As before, using the ranking of Table~\ref{table:wind_scores}, the significance of the difference between one model and its immediate succesor is tested. 
%
%In Table~\ref{table:wind_wilcoxon} the $p$-values of these Wilcoxon tests are given, and the statistical significance ranking is shown. Recall that two models have different significance ranking only if the Wilcoxon test hypothesis is rejected.
%
The \acrshort{ctl} approach obtains the best results, being the best model in terms of MAE and second best in terms of MSE. Nevertheless, the equivalent \acrshort{mtl} approaches that use $\lambda^*=1$ trivially tie at first place; these are \fmodt{timeOfDay}{MTL}, \fmodt{timeOfDay, angle}{MTL} and \fmodt{timeOfDay, angle, velocity}{MTL}, while the \fmodt{angle}{MTL} gets the second best MAE score.
When the MSE scores are analyzed, the roles are reversed, the \fmodt{angle}{MTL} gets the best result, and the \fmod{CTL} and the equivalents \acrshort{mtl} approaches are second.

%
This advantage of the \acrshort{ctl} approach can find its roots on poorly defined tasks, which do not have a strong relation with the energy production. Also, the definition of the tasks is made using the train set, data from year 2016, which may behave differently to the validation or test years.
Nevertheless, the \acrshort{mtl} approaches, having the possibility of blending to either \acrshort{ctl} or \acrshort{itl} approaches, get the best results too.

%
In this wind energy problem, the persistence forecasts, which again predict the energy production the previous day at the same hour, obtain an error of $15.64\%$, which is quite large and represent a $150\%$ increase on the lowest error using SVRs. This is not unusual, since the wind velocity or angle between two different days are not necessarily correlated.
%
With the neural network regressor, the error is a $6.66\%$, which is also greater than any of the other models considered.

\begin{figure}[t!]
    \centering%
    \subfloat[Best \acrshort{ctl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_ctl_stv.pdf}
    \label{fig:best_ctl_stv}}\quad%
    \subfloat[Best \acrshort{itl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_itl_stv.pdf}
    \label{fig:best_itl_stv}}\quad%
    \subfloat[Best \acrshort{mtl} prediction.]{%
    \includegraphics[width=.3 \textwidth, height=.3 \textwidth]{Chapter6/energies/best_mtl_stv.pdf}
    \label{fig:best_mtl_stv}}\\
 \caption{\label{fig:stv_best_plots} Real energy production against prediction made by the best models for \fdata{sotavento}; the perfect prediction line is shown in orange. The~units of the axis are percentage points of the total wind energy~installed.}
 \end{figure}

%
Again, we plot the predictions against the target values of the \acrshort{ctl} model and best \acrshort{itl},~\fmodt{angle}{ITL}, and pure \acrshort{mtl}, \fmodt{angle}{MTL}, approaches.
The presence of points with zero production is noticeable, but this is relatively frequent in wind energy. It can be caused either by energy curtailments or by maintenance periods of the wind farm.
Also, it is noticeable the frequency of small production values, below \SI{20}{\percent}, which is due to the approximate Weibull distribution of wind speeds, where small speed values have higher frequencies. 
% With these considerations, it is difficult to compare the plots and find significant differences in model performance.







% \subsection{Conclusions}

% \subsubsection*{old\%

% We finally observe that while the wind \acrshort{mae} in percentage are similar to those in \acrshort{pv}, when compared with the energy produced, the~performance of wind models is actually worse.
% In fact, in~Table~\ref{table:comparison} we compare the percentage MAE against the average generated energy as a percentage of installed power.
% As~it can be seen, the~ratio between the percentage MAE and the percentage average energy is about $34.78\%$ for Sotavento, much higher than the $22.50\%$ of Majorca and the $14.92\%$ of~Tenerife.

% \begin{table}[t!]
%     \caption{{Comparison}        %Please remove font in the Table
%      of the percentage \acrshort{mae} with the average energy produced as a percentage of installed~power.}
%     \centering
%     \label{table:comparison}
%     %% \tablesize{} %% You can specify the fontsize here, e.g.,~\tablesize{\footnotesize}. If commented out \small will be used.
%     \begin{tabular}{lccc}
%     \toprule
%  & \fhead{MAE (\%)} & \fhead{Avg. Target (\%)} & \fhead{Ratio} \\
% 	\midrule
% \fdata{majorca} & 6.740 & 29.954 & 22.50 \\
% \fdata{tenerife} & 4.993 & 33.462 & 14.92 \\
% \fdata{sotavento} & 6.186	& 17.784 & 34.78 \\
% \bottomrule
%     \end{tabular}
% \end{table}













































\section{Convex Multi-Task Learning with Neural Networks}\label{sec:convexmtl_nn_experiments}
%
In the experiments presented in the previous sections, we have focused on the convex \acrshort{mtl} formulation for kernel methods; however, as described in Section~\ref{sec:convexmlt_network}, we can also use this formulation with \acrshort{nns}. The idea is then to use as the model for each task a convex combination of a common and task-specific \acrshort{nns}.

%
\acrshort{nns} have experimented a great success in many areas such as a Computer Vision and Natural Language Processing; however, these results have been achieved using large networks, with possibly millions of parameters, that need a great amount of data in the training process. For relatively small datasets, say below \num{25000} patterns, \acrshort{svms} usually achieve a better performance, because of the better generalization properties that characterize them.
%
Anyway, nowadays, in the era of big data, many problems are composed of tens of thousands, even millions of patterns. Kernel methods, such as \acrshort{svms}, due to their computational cost, cannot deal with such problems. With these methods, training time grows faster than quadratically with the number of training patterns, which makes them unfeasible on large datasets.
%

Moreover, data is not always tabular, where the features have no apparent connection among them, but there might exist a spatial structure, as in images, or temporal dependencies, as in time series or natural language. Incoporating the knowledge of such structures with kernel methods is not an easy task, since the feature space where the problem is actually solved is possibly infinite-dimensional, and very difficult to interpret. Neural networks, on the other hand, are very flexible to incorporate such knowledge, and they are easily adaptable to a wide range of architectures without significant modifications of their training procedure.
%
In this section, we want to show the effectiveness of the convex \acrshort{mtl} formulation when applied to \acrshort{nns}. To do this, we consider four different image datasets, so convolutional neural networks will be the base of our \acrshort{mtl} models. Each of these problems has \num{70000} images, so using \acrshort{svm}-based models with the entire dataset is quite time consuming. Instead, we will use two different approaches to \acrshort{mtl} with \acrshort{nns}, a feature-based one, the hard sharing of hidden weights, and our proposal, the convex \acrshort{mtl} approach.


\begin{figure}[t!]
    \includegraphics[width=\linewidth]{Chapter6/HAIS2022/hais22_datasets.pdf}
    \caption{Images of the four classification problems used. Each image has a title indicating the corresponding task. The rows correspond to \fdata{var-MNIST}, \fdata{rot-MNIST}, \fdata{var-FMNIST} and \fdata{rot-FMNIST} (from top to bottom).}
    \label{fig:problems_hais2022}
\end{figure}

%\subsubsection*{Problems' Description}
To test the convex \acrshort{mtl} neural networks we consider four \acrshort{mt} image datasets:
\fdata{var-MNIST} and \fdata{rot-MNIST}, based on MNIST~\citep{LeCunBBH98}, and \fdata{var-FMNIST} and \fdata{rot-FMNIST}, based on fashion-MNIST~\citep{xiao2017}.
%
The MNIST and fashion-MNIST datasets are both composed of \num{70000} examples of $28\times 28$ grey-scale images. The MNIST dataset contains images of handwritten numbers, while the fashion-MNIST has images of clothes and fashion-related objects.
Both are used as classification problems, where the images have to be classified in one of $10$ possible classes, that is, $10$ different digits or $10$ different types of clothes. These classes are balanced in both datasets.
%
To generate our \acrshort{mt} image datasets, we take the images from MNIST or fashion-MNIST and apply either the \emph{variations} procedure or the \emph{rotation} one.
%
In particular, for the \fdata{var-MNIST} and \fdata{var-FMNIST} we use the \emph{variations} procedure where, inspired by the work of~\cite{BergstraB12}, we consider three transformations:
\begin{itemize}
    \item \textit{random}: adding random noise to the original image.
    \item \textit{image}: adding a random patch of another image to the original image.
    \item \textit{standard}: no transformations are applied to the original image.
\end{itemize}
Then, we use a random split to divide the original datasets in three groups. To each group we apply one of the transformations defined, so we get three tasks: two with \num{23333} examples and the third one with \num{23334}.

%
For the \fdata{rot-MNIST} and \fdata{rot-FMNIST} we apply the \emph{rotations} procedure. With the definitions of~\cite{GhifaryKZB15}, we consider six transformations:
\begin{itemize}
    \item \textit{0}: rotating $0^{\circ}$ the original image.
    \item \textit{15}: rotating $15^{\circ}$ the original image.
    \item \textit{30}: rotating $30^{\circ}$ the original image.
    \item \textit{45}: rotating $45^{\circ}$ the original image.
    \item \textit{60}: rotating $60^{\circ}$ the original image.
    \item \textit{75}: rotating $75^{\circ}$ the original image.
\end{itemize}
Again, we consider a random split to divide the original datasets in six groups and each group is applied one of the transformations defined above, so we get six tasks: four with \num{11667} examples and two with \num{11666}.
%
In Figure~\ref{fig:problems_hais2022} we show examples of the four \acrshort{mtl} image problems that we generate, with the corresponding task annotation for each one.



%\subsubsection*{Experimental Procedure}
% Models Considered
For testing the performance of our proposal we consider the following models:
\begin{itemize}
    \item \fmod{ctlNN}: a \acrshort{ctl}-based neural network, that is, a single network for all tasks.
    \item \fmod{itlNN}: an \acrshort{itl}-based neural network, that is, an independent network for each task.
    \item \fmod{hsNN}: an \acrshort{mtl}-based neural network using the hard sharing strategy. That is, a single neural network is defined for all tasks, where the first layers are shared among tasks, but a task-specific output layer is used for each task.
    \item \fmod{mtlNN}: an \acrshort{mtl}-based neural network using the convex formulation we propose.
\end{itemize}
% convNet
All of these models are based on a convolutional network, which we will name \fmod{convNet}, whose architecture is taken from the Spatial Transformer Network~\citep{Jaderberg_2015} implementation given in Pytorch\footnote{\href{www.pytorch.org/tutorials/intermediate/spatial\_transformer\_tutorial.html}{www.pytorch.org/tutorials/intermediate/spatial\_transformer\_tutorial.html}}.
The architecture of \fmod{convNet} consists, in this order, of two convolutional layers of kernel size $5$, with $10$ and $20$ output channels each; then a dropout layer, followed by a max pooling layer, and two fully connected hidden layers with $320$ and $50$ neurons. After this, the output layers follow.

%
Since we apply one-hot encoding for the multiple classes, the architecture of the \fmod{ctlNN} consists on a single network with the \fmod{convNet} architecture with $10$ output neurons, one for each class.
%
In the \fmod{itlNN}, an independent network, with the \fmod{convNet} architecture and $10$ output neurons, is considered for each task.
%
For the \fmod{hsNN}, a single network with the \fmod{convNet} architecture is considered, but we have a group of $10$ output neurons for each task in the problem. For example, if we are using the \emph{rotation}-based problems, we would have $60$ output neurons, but only the group of $10$ corresponding to each task is used with each example.
%
In the \fmod{mtlNN} we define a network with the \fmod{convNet} architecture and $10$ output neurons to model the common network and each of the task-specific networks. That is, given an example from task $r$, the $10$ common output neurons and the $10$ $r$-th task-specific ones are combined to obtain the final output. 

% Optimizer and Hyperparameters
We use the AdamW algorithm~\citep{LoshchilovH19} to train all the models considered, and the weight decay parameter $\alpha$ for each model is selected using a \acrshort{cv}-based search over the values $\set{10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 10^{0}}$. The rest of the parameters, which are part of the architecture, are fixed and set to the default values: the dropout rate is $0.5$ and we apply a $2\times 2$ max pooling layer with a stride of $2$.
%
The \fmod{mtlNN} model also has $\lambda$ as a hyperparameter, and it is selected, alongside $\alpha$, using a \acrshort{cv} grid search, where the grid for $\lambda$ is $\set{0, 0.2, 0.4, 0.6, 0.8, 1}$.

%
The train and test sets are generated using a task-stratified split of $70\%$ and $30\%$, respectively.
The \acrshort{cv} grid searches are carried out using the training set, where we use a $5$-fold \acrshort{cv} scheme. These folds are task-stratified, that is, all of them have the same task proportions. Also, since the problems are class-balanced and the sample size is reasonably large, the folds are expected to be class-balanced as well.

%\subsubsection*{Results}

\begin{table}[t!]
    \centering
        \caption{Test accuracy with majority voting.}
        \label{tab:test_accuracy_majority}
        \scalebox{.65}{
    \begin{tabular}{l*{4}{c}}
        \hline
                           &   \fdata{var-MNIST} &   \fdata{rot-MNIST} &   \fdata{var-FMNIST} &   \fdata{rot-FMNIST} \\
        \hline
         \fmod{ctlNN} &              0.964 &           0.973 &                     0.784 &                  0.834 \\
         \fmod{itlNN} &              0.968 &           0.981 &                     0.795 &                  0.873 \\
         \fmod{hsNN}  &              0.971 &           0.980  &                    0.770  &                 0.852 \\
         \multirow{2}*{\fmod{mtlNN}} &              \fmaxn{0.974} &           \fmaxn{0.984} &                     \fmaxn{0.812} &                  \fmaxn{0.880} \\
         & ($\lambda^* = {0.6}$)  & ($\lambda^* = {0.8}$) & ($\lambda^* = {0.6}$)  & ($\lambda^* = {0.6}$) \\
         \hline
        \end{tabular}
        }
\end{table}

\begin{table}[t!]
    \centering
        \caption{Test categorical cross entropy of the averaged logits.}
        \label{tab:test_crossentropy_mean}
        \scalebox{.65}{    
    \begin{tabular}{l*{4}{c}}
        \hline
                           & \fdata{var-MNIST}   & \fdata{rot-MNIST}     & \fdata{var-FMNIST}   & \fdata{rot-FMNIST}   \\
        \hline
         \fmod{ctlNN} & 1.274 $\pm$ 0.143  & 1.145 $\pm$ 0.039 & 2.369 $\pm$ 0.183         & 1.757 $\pm$ 0.075      \\
         \fmod{itlNN} & 1.072 $\pm$ 0.029  & 0.873 $\pm$ 0.058 & 2.356 $\pm$ 0.130         & 1.598 $\pm$ 0.042      \\
         \fmod{hsNN}  & 1.087 $\pm$ 0.253  & 0.898 $\pm$ 0.073 & 3.067 $\pm$ 0.888         & 1.888 $\pm$ 0.075      \\
         \multirow{2}*{\fmod{mtlNN}} & \fmaxn{0.924} $\pm$ \fmaxn{0.024}  & \fmaxn{0.831} $\pm$ \fmaxn{0.029} & \fmaxn{2.147} $\pm$ \fmaxn{0.090}         & \fmaxn{1.482} $\pm$ \fmaxn{0.063}      \\
         & ($\lambda^* = {0.6}$)  & ($\lambda^* = {0.8}$) & ($\lambda^* = {0.6}$)  & ($\lambda^* = {0.6}$)      \\
         \hline
        \end{tabular}
        }
\end{table}

% Refitting models
To get more accurate results, less sensitive to randomness, we train each model $5$ different times. To do this, once the optimal hyperparameters have been selected using the \acrshort{cv} in the training set, we refit the model with these hyperparameters using the entire training set. That is, \acrshort{cv} is done only once for each model in each problem, but then we repeat $5$ times the procedure of training the network over the entire training set.

% Accuracy vs Categorical CE
Although maximizing the accuracy is ultimately the goal in classification problems, it is not a differentiable measure, so we use the categorical cross entropy instead as the loss function to train the networks. Both measures are broadly correlated, but they do not represent exactly the same behavior. We will show the results using both for completeness.

% Tables
Since we have $5$ instances of each model, a typical strategy to combine their predictions is majority voting. We perform this majority voting using the logits, in the output neurons, of each instance and averaging them, so we have $10$ values, one for each class.
In Table~\ref{tab:test_accuracy_majority} we show the test accuracy, using the logits average already described, for each of the approaches considered.
%
Other way to visualize these results is to compute the categorical cross entropy directly on the averaged logits, which we show in Table~\ref{tab:test_crossentropy_mean}.
%
In both tables we also show the optimal values for $\lambda$ selected in the \acrshort{cv}.

% Analysis
Our proposal, the \fmod{mtlNN} model, obtains the best results in all the problems, either in terms of accuracy or cross entropy.
The \acrshort{itl} approach comes second in all problems, except for the accuracy score in \fdata{var-MNIST}, where the \fdata{hsNN} is second and \fdata{itlNN} goes third.
The \fdata{hsNN} model goes third in the rest of problems, while the \fdata{ctlNN} gets the worst results consistently in all problems, sometimes by a large margin.
%
By looking at the tables, it seems that a \acrshort{ctl} approach is not able to capture the different properties of each task simultaneously. On the other hand, the \fmod{ITL} approach obtains good results, because it is specialized in each task.
Looking at the optimal values for $\lambda$, there is, however, common information shared among the tasks. These values fall far from the $0, 1$ margins, so neither the \acrshort{ctl} nor the \acrshort{itl} are optimal approaches. This is reflected in Tables~\ref{tab:test_accuracy_majority} and~\ref{tab:test_crossentropy_mean}, where the \fmod{mtlNN} outperforms consistently \fmod{ctlNN} and \fmod{itlNN}. We can assume, then, that the information learned by the common network and the task-specific ones is complementary, because their combination leads to better results.
%
The hard sharing approach, although better than a \acrshort{ctl} one, seems to be too rigid to effectively capture the differences among different tasks, so it is frequently surpassed by the \acrshort{itl} network.




% Complementing common and task-specific











\section{Convex Graph Laplacian for Multi-Task Learning}\label{sec:convexgl_experiments}
%
The convex \acrshort{mtl} that we have seen in the previous experiments assumes that the information that can be shared is common for all tasks. However, there might be problems where there is not an information that is common to all tasks, but there are some elements of knowledge that are shared by each pair of tasks. 
%
To take into account these kind of dependences, we have proposed the convex \acrshort{gl} \acrshort{mtl} formulation in~\cite{RuizAD20}, which we have described in Section~\ref{sec:convexgl} for the L1, L2 and LS-\acrshort{svm}.
%
In this section we present the experiments that we gave in~\cite{RuizAD20}, which test our proposal and compare it to the baseline models using \num{6} regression problems and \num{2} classification ones.

%\subsection{Problems}
%\subsubsection*{Problems}

We use eight different problems: \fdata{majorca}, \fdata{tenerife}, \fdata{california}, \fdata{boston}, \fdata{abalone} and \fdata{crime} for regression and \fdata{landmine} and \fdata{binding} for classification.
Although we have already defined these datasets in Section~\ref{sec:convexmtlsvm_exp}, for convenience we summarize here the description of each one again. We point out that the \fdata{adult} and \fdata{compas} datasets, which are present in Section~\ref{sec:convexmtlsvm_exp}, were not considered for these experiments.
In \fdata{majorca} and \fdata{tenerife} each task goal is to predict the photovoltaic production at different hours.
The \fdata{california} and \fdata{boston} datasets, which are obtained from the Kaggle repository, are problems in which the target is the median price of houses and the different tasks are defined using the location of these houses.
The rest of the regression datasets are available in the UCI repository.
The \fdata{abalone} dataset contains data about sea molluscs and we define as different tasks the prediction of the number of rings in the male, female and infant specimens.
The target in the \fdata{crime} problem is to predict the number of crimes per population in different cities, and the prediction in each state is considered a different task. 
In the classification problems we consider the MHC-I molecule binding problem, which we call \fdata{binding}. In this problem the goal is to predict whether a molecule and a peptide will form a bond. We take the prediction for each MHC molecule as a different task.
The \fdata{landmine}
%~\cite{jebara2011multitask} 
problem goal is the detection of landmines, and each type of landmine defines a task.
% In \fdata{majorca} and \fdata{tenerife} each task goal is to predict the photovoltaic production in these islands at different hours.
% In \fdata{california} and \fdata{boston} datasets
% %, which are obtained from the Kaggle repository,
% the target is the price of houses and the tasks are defined using different location categories of these houses.
% %The rest of the regression datasets are available in the UCI repository.
% In \fdata{abalone} we define three tasks: the prediction for male, female and infant specimens.
% The target in \fdata{crime} is to predict the number of crimes per \num{100000} people in different cities of the U.S.; the prediction in each state is considered a task.
% For classification, in \fdata{binding}, the goal is to predict whether peptides will bind to a certain MHC molecule and each molecule represents a different task .
% In \fdata{landmine}
% % %~\cite{jebara2011multitask} 
% the goal is the detection of landmines; each type of landmine defines a task.
Although the characteristics of these datasets have been presented in Table~\ref{tab:problems_hais19}, to make the reading easier we give them also in Table~\ref{table:size_dim_tasks}.
%In Table we give the characteristics of the different datasets.
%\comm{si queda sitio comentara brevement cules son las tareas} \resp{OK, pienso lo mismo.}
%\comm{intenta meter un prrafo no muy verboso a ver cmo queda y cmo se puede ajustar?}
%
\begin{table*}
    \caption{Sample sizes, dimensions and number of tasks of the datasets used.}
    \label{table:size_dim_tasks}
    \centering
    \scalebox{.65}{
    \begin{tabular}{lS[table-format=5]S[table-format=3]S[table-format=2]S[table-format=4]S[table-format=4]S[table-format=4]}
    \toprule
    \fhead{Dataset} & \fhead{Size} & \fhead{No. features} & \fhead{No. tasks} & \fhead{Avg. task size} & \fhead{Min. task size} & \fhead{Max. task size}\\
    \midrule
    \fdata{majorca} & 15330 & 765 & 14 & 1095 & 1095 & 1095 \\ 
    \fdata{tenerife} & 15330 & 765 & 14 & 1095 & 1095 & 1095 \\
    \fdata{binding} & 32302 & 184 & 47 & 687 & 59 & 3089 \\ 
    \fdata{landmine} & 14820 & 10 & 28 & 511 & 445 & 690 \\
    \fdata{california} & 19269 & 9 & 5 & 3853 & 5 & 8468\\
    \fdata{boston} & 506 & 12 & 2 & 253 & 35 & 471 \\
    \fdata{abalone} & 4177 & 8 & 3 & 1392 & 1307 & 1527 \\
    \fdata{crime} & 1195 & 127 & 9 & 132 & 60  & 278 \\
    \bottomrule
    \end{tabular} }
\end{table*}


%

%

%\subsubsection*{Experimental Procedure}

To test our proposal we compare it with four alternative models, all based on the Gaussian L1-\acrshort{svm}, which are described next.
%
\begin{itemize}
    \item \textbf{Common Task Learning \acrshort{svm} (\fmod{CTL})}, which considers a single \acrshort{svm} model for all tasks, without making use of the task information.
    \item \textbf{Independent Task learning \acrshort{svm} (\fmod{ITL})}, which fits an independent \acrshort{svm} for each task.
    \item \textbf{Convex Multi-Task learning \acrshort{svm} (\fmod{MTL})}, which considers the convex \acrshort{mtl} approach, described in Section~\ref{sec:convexmlt_kernel}.
    \item \textbf{Graph Laplacian MTL-\acrshort{svm} (\fmod{GLMTL})}, where only the \acrshort{gl} regularization is used to enforce the coupling between the tasks, as presented in Section~\ref{sec:graphlap}; no common part is incorporated.
    \item \textbf{Convex Graph Laplacian MTL-\acrshort{svm} (\fmod{cvxGLMTL})}, where we use a common and task-specific parts, and those specific parts are coupled through a \acrshort{gl} regularization, as presented in Section~\ref{sec:convexgl}.
\end{itemize}



Each of the considered models has a different set of hyperparameters, which are typically selected from a grid of possible combinations, that is, using a grid search procedure. The cost of this search, however, as explained in Section~\ref{sec:convexmtlsvm_exp}, scales exponentially with the number of hyperparameters.
%
We will consider a grid search \acrshort{cv} procedure, but, when the number of hyperparameters is greater than three, we will use some simplifications that we detail next.
%
For the \fmod{CTL} approach, where we have \num{3} hyperparameters, $\set{C, \epsilon, \gamma}$, with $\gamma$ being the kernel width of this common model, we choose all of them via \acrshort{cv}. 
It is the same for the parameters $\set{C_r, \epsilon_r, \gamma_r}$ of the task-specific models in the \fmod{ITL} approach.
%
In the \fmod{MTL} we have the following set of hyperparameters: $\set{C, \epsilon, \lambda, \gamma, \gamma_1, \ldots, \gamma_\ntasks}$, which include the kernel width for the common part $\gamma$ and the task-specific widths $\gamma_r$, $r=1, \ldots, \ntasks$, that is a total of $T + 4$ hyperparameters. We proceed as follows: we take the common and task-specific kernel widths as the optimal ones from the \fmod{CTL} and \fmod{ITL} approaches, then we perform a standard \acrshort{cv} search for $\set{C, \epsilon, \lambda}$.
%
For the \fmod{GLMTL} approach we use a similar procedure. We use the kernel width selected for \fmod{CTL} and do a grid search \acrshort{cv} for $\set{C, \epsilon, \mu}$.
%
Finally, for \fmod{cvxGLMTL} we use the optimal kernel width for \fmod{CTL} in both kernels of the model definition and select for $\mu$ the optimal value for the \fmod{GLMTL} approach. Then, we perform the \acrshort{cv} search for $\set{C, \epsilon, \lambda}$.
%
As with the other experiments, in Table~\ref{table:hyperpars_grid} we give the grids used and illustrate how each hyperparameter is selected in the different models.

\begin{table}[t!]
    \caption{Hyper-parameters, grids used to select them (when appropriate) and hyperparameter selection method for each model.}
    \label{table:hyperpars_grid}
    \centering
    \scalebox{.65}{
    \begin{tabular}{*{7}{c}}
    \toprule
    \fhead{} & \fhead{Grid} & \fhead{\fmod{CTL}} & \fhead{\fmod{ITL}} & \fhead{\fmod{MTL}} & \fhead{\fmod{GLMTL}} & \fhead{\fmod{cvxGLMTL}} \\
    \midrule
    $C$ &  \scalebox{1}{$\set{4^k: -2 \leq k \leq 2}$} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv}  \\ 
    $\epsilon$ & \scalebox{1}{$\set{\frac{\sigma}{4^k}: 1 \leq k \leq 6}$} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv} & \acrshort{cv}  \\
    $\gamma$ & \scalebox{1}{$\set{\frac{4^k}{d}: -2 \leq k \leq 3}$} & \acrshort{cv} & - & \fmod{CTL} & - & \fmod{CTL} \\
    $\gamma_s$ & \scalebox{1}{$\set{\frac{4^k}{d}: -2 \leq k \leq 3}$} & - & \acrshort{cv} & \fmod{ITL} & \fmod{CTL} & \fmod{CTL}\\
    $\lambda$ & \scalebox{1}{$\set{0.2 k : 0 \leq k \leq 5}$} & - & - & \acrshort{cv} & - & \acrshort{cv}\\
    $\mu$ & \scalebox{1}{$\set{4^k : -1 \leq k \leq 3}$} & - & - & - & \acrshort{cv} & \fmod{GLMTL}\\
    \bottomrule
    \end{tabular}
    }
\end{table}

Recall that the \acrshort{cv} consists in dividing the dataset in multiple folds; then, for each combination of hyperparameters we train with all the folds but one and test its performance on the remaining fold, the validation set. We divide our datasets in folds differently depending on the nature of the problem.
In \fdata{majorca} and \fdata{tenerife}, which are time series, and, thus, we need to take into account the time dependencies, we use the data from the years 2013, 2014 and 2015 as train, validation and test sets.
%
As in the previous experiments, for the rest of the problems we consider a nested \acrshort{cv}, where now we have three outer folds, and we use two outer of them to select the optimal hyperparameters and the remaining one to measure the fitness of our models. To select the optimal hyperparameters we combine the data from the two outer folds and perform a \acrshort{cv} with three inner folds, where we use two for training and one for validation.
The folds are selected randomly and stratified by task, so the task proportions are similar in all folds.
As validation metrics to select the best hyperparameters we use the \acrshort{mae} in the regression problems and the F1 score in the classification ones.
In the training and validation process, we also normalize the data feature-wise using the mean and deviation from the training set, and in the regression problems we scale the targets into the $[0, 1]$ interval with the minimum and maximum from the training set.
%This is done using the \fcode{TransformedTargetRegressor} class of \textit{Scikit-learn}; the mean and standard deviation is computed with the training data and then it is used in the testing dataset.

In the approaches incorporating a \acrshort{gl} we need to select an adjacency matrix. The weights that compose this matrix define the degree of relationship that we expect between tasks, and we introduce this information through the \acrshort{gl} regularization.
%
Selecting an adequate graph is not trivial, and an expert knowledge of each specific problem would be necessary. In our experiments, since we do not have any prior knowledge about the tasks and their relations, we use an ``agnostic'' graph in which every task (node) is connected to all the others; that is, our adjacency matrix is the constant matrix $A = \frac{1}{\ntasks} \fv{1} \fv{1}^\intercal$.

%\subsubsection*{Results}

% \begin{table*}[t]
%     \caption{Test MAE  (top), and test R2 scores (bottom) in the regression problems.}
%     \label{tab:error_models}
%     \centering
%     \scalebox{.65}{
%     \begin{tabular}{l*{2}{S[table-format=1.3]S[table-format=1.3]}S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]}
%     \toprule
%     & \fheadmulti{2}{\fdata{maj.}} & \fheadmulti{2}{\fdata{ten.}} & \fheadmulti{3}{\fdata{boston}} & \fheadmulti{3}{\fdata{california}} &  \fheadmulti{3}{\fdata{abalone}} & \fheadmulti{3}{\fdata{crime}} \\
%     \midrule
%     &\fheadmulti{10}{MAE} \\
%     \midrule
%     {\fmod{CTL}} & 5.265 & 1 &  5.786 & 2.254 & 0.035 & {41870.820} & {76.723} & 1.483 & 0.039 & 0.078 & 0.001 & 1 & 1 & 1& 1 & 1\\
%     {\fmod{ITL}} & 5.119 & 5.341 & 2.779 & 0.134 & {37043.664} & {371.549} & 1.488 & 0.038 & 0.082 & 0.006 \\
%     {\fmod{MTL}} & 5.077 & 5.351 &  \fmax{2.228} & \fmax{0.006} & {36848.971} & {242.052} & \fmax{1.466} & \fmax{0.028} & \fmax{0.074} & \fmax{0.003} \\
%     {\fmod{GLMTL}} & 5.291 & 5.840 & 3.070 & 0.391 & {37123.515} & {404.205} & 1.690 & 0.017 & 0.094 & 0.006  \\
%     {\fmod{cvxGLMTL}} & \fmax{4.917} & \fmax{5.335} &  2.230 & 0.038 & \fmax{36720.854} & \fmax{225.335} & 1.467 & 0.026 & \fmax{0.074} & \fmax{0.003}  \\
%     \midrule        
%         &\fheadmulti{10}{R2} \\
%         \midrule
%         {\fmod{CTL}} & 0.831 &  0.902 & 0.843 & 0.044 & {0.638} & {0.005} & 0.560 & 0.017 & 0.743 & 0.022   \\
%         {\fmod{ITL}} & 0.843 & 0.904 & 0.776 & 0.017 & {0.696} & {0.005} & 0.550 & 0.024 & 0.711 & 0.006 \\
%         {\fmod{MTL}} & 0.845 & \fmax{0.907} & 0.850 & 0.045 & {0.700} & {0.003} & \fmax{0.566} & \fmax{0.013} & \fmax{0.755} & \fmax{0.016} \\
%         {\fmod{GLMTL}} & 0.832 & 0.894 &  0.490 & 0.264 & {0.695} & {0.007} & 0.366 & 0.027 & 0.596 & 0.033 \\
%         {\fmod{cvxGLMTL}} & \fmax{0.849} & 0.905 & \fmax{0.852} & \fmax{0.046} & \fmax{0.702} & \fmax{0.003} & \fmax{0.566} & \fmax{0.013} & 0.752 & 0.016 \\
%         \bottomrule
%         \end{tabular}}
% \end{table*}

% \begin{table*}[t]
%     \caption{Test MAE  (top), and test R2 scores (bottom) in the regression problems.}
%     \label{tab:error_models}
%     \centering
%     \scalebox{.65}{
%     \begin{tabular}{l*{2}{S[table-format=1.3]}S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]}
%     \toprule
%     & \fhead{\fdata{maj.}} & \fhead{\fdata{ten.}} & \fheadmulti{2}{\fdata{boston}} & \fheadmulti{2}{\fdata{california}} &  \fheadmulti{2}{\fdata{abalone}} & \fheadmulti{2}{\fdata{crime}} \\
%     \midrule
%     &\fheadmulti{10}{MAE} \\
%     \midrule
%     {\fmod{CTL}} & 5.265 &  5.786 & 2.254 & 0.035 & {41870.820} & {76.723} & 1.483 & 0.039 & 0.078 & 0.001 \\
%     {\fmod{ITL}} & 5.119 & 5.341 & 2.779 & 0.134 & {37043.664} & {371.549} & 1.488 & 0.038 & 0.082 & 0.006 \\
%     {\fmod{MTL}} & 5.077 & 5.351 &  \fmax{2.228} & \fmax{0.006} & {36848.971} & {242.052} & \fmax{1.466} & \fmax{0.028} & \fmax{0.074} & \fmax{0.003} \\
%     {\fmod{GLMTL}} & 5.291 & 5.840 & 3.070 & 0.391 & {37123.515} & {404.205} & 1.690 & 0.017 & 0.094 & 0.006  \\
%     {\fmod{cvxGLMTL}} & \fmax{4.917} & \fmax{5.335} &  2.230 & 0.038 & \fmax{36720.854} & \fmax{225.335} & 1.467 & 0.026 & \fmax{0.074} & \fmax{0.003}  \\
%     \midrule        
%         &\fheadmulti{10}{R2} \\
%         \midrule
%         {\fmod{CTL}} & 0.831 &  0.902 & 0.843 & 0.044 & {0.638} & {0.005} & 0.560 & 0.017 & 0.743 & 0.022   \\
%         {\fmod{ITL}} & 0.843 & 0.904 & 0.776 & 0.017 & {0.696} & {0.005} & 0.550 & 0.024 & 0.711 & 0.006 \\
%         {\fmod{MTL}} & 0.845 & \fmax{0.907} & 0.850 & 0.045 & {0.700} & {0.003} & \fmax{0.566} & \fmax{0.013} & \fmax{0.755} & \fmax{0.016} \\
%         {\fmod{GLMTL}} & 0.832 & 0.894 &  0.490 & 0.264 & {0.695} & {0.007} & 0.366 & 0.027 & 0.596 & 0.033 \\
%         {\fmod{cvxGLMTL}} & \fmax{0.849} & 0.905 & \fmax{0.852} & \fmax{0.046} & \fmax{0.702} & \fmax{0.003} & \fmax{0.566} & \fmax{0.013} & 0.752 & 0.016 \\
%         \bottomrule
%         \end{tabular}}
% \end{table*}

\begin{table*}[t]
    \caption{In the left, test MAE  (top), and test R2 scores (bottom) in the regression problems. In the right, test  F1 score (top), and accuracy (bottom) in the classification problems.}
    \label{tab:error_models_full}
    \centering
    \scalebox{.65}{
    \begin{tabular}{l*{2}{S[table-format=1.3]}S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]
    |S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]}
    \toprule
    & \fhead{\fdata{maj.}} & \fhead{\fdata{ten.}} & \fheadmulti{2}{\fdata{boston}} & \fheadmulti{2}{\fdata{california}} &  \fheadmulti{2}{\fdata{abalone}} & \fheadmulti{2}{\fdata{crime}} &  \fheadmulti{2}{\fdata{landmine}} & \fheadmulti{2}{\fdata{binding}}\\
    \midrule
    &\fheadmulti{10}{MAE} & \fheadmulti{4}{F1} \\
    \midrule
    {\fmod{CTL}} & 5.265 &  5.786 & 2.254 & 0.035 & {41870.820} & {76.723} & 1.483 & 0.039 & 0.078 & 0.001  &  0.106 & 0.016 & 0.868 & 0.002 \\
    {\fmod{ITL}} & 5.119 & 5.341 & 2.779 & 0.134 & {37043.664} & {371.549} & 1.488 & 0.038 & 0.082 & 0.006  & 0.183 & 0.034 & 0.901 & 0.000 \\
    {\fmod{MTL}} & 5.077 & 5.351 &  \fmax{2.228} & \fmax{0.006} & {36848.971} & {242.052} & \fmax{1.466} & \fmax{0.028} & \fmax{0.074} & \fmax{0.003}   & 0.150 & 0.023 & 0.906 & 0.001 \\
    {\fmod{GLMTL}} & 5.291 & 5.840 & 3.070 & 0.391 & {37123.515} & {404.205} & 1.690 & 0.017 & 0.094 & 0.006   & \fmax{0.227} & \fmax{0.042} & 0.896 & 0.003 \\
    {\fmod{cvxGLMTL}} & \fmax{4.917} & \fmax{5.335} &  2.230 & 0.038 & \fmax{36720.854} & \fmax{225.335} & 1.467 & 0.026 & \fmax{0.074} & \fmax{0.003}   & 0.163 & 0.031 & \fmax{0.908} & \fmax{0.001} \\
    \midrule        
        &\fheadmulti{10}{R2} & \fheadmulti{4}{Accuracy}\\
        \midrule
        {\fmod{CTL}} & 0.831 &  0.902 & 0.843 & 0.044 & {0.638} & {0.005} & 0.560 & 0.017 & 0.743 & 0.022    &  0.942 & 0.004 & 0.791 & 0.003   \\
        {\fmod{ITL}} & 0.843 & 0.904 & 0.776 & 0.017 & {0.696} & {0.005} & 0.550 & 0.024 & 0.711 & 0.006  & 0.942 & 0.004 & 0.850 & 0.000 \\
        {\fmod{MTL}} & 0.845 & \fmax{0.907} & 0.850 & 0.045 & {0.700} & {0.003} & \fmax{0.566} & \fmax{0.013} & \fmax{0.755} & \fmax{0.016}  & 0.943 & 0.004 & 0.858 & 0.002 \\
        {\fmod{GLMTL}} & 0.832 & 0.894 &  0.490 & 0.264 & {0.695} & {0.007} & 0.366 & 0.027 & 0.596 & 0.033  & 0.935 & 0.002 & 0.844 & 0.005 \\
        {\fmod{cvxGLMTL}} & \fmax{0.849} & 0.905 & \fmax{0.852} & \fmax{0.046} & \fmax{0.702} & \fmax{0.003} & \fmax{0.566} & \fmax{0.013} & 0.752 & 0.016  & \fmax{0.944} & \fmax{0.004} & \fmax{0.862} & \fmax{0.002} \\
        \bottomrule
        \end{tabular}}
\end{table*}

% \begin{table*}[t]
%     \caption{Test  F1 score (top), and accuracy (bottom) in the classification problems.}
%     \label{tab:error_models}
%     \centering
%     \scalebox{.65}{
%     \begin{tabular}{l*{2}{S[table-format=1.3]@{$\pm$}S[table-format=1.3]}}
%     \toprule
%     &  \fheadmulti{2}{\fdata{landmine}} & \fheadmulti{2}{\fdata{binding}}\\
%     \midrule
%     & \fheadmulti{4}{F1} \\
%     \midrule
%     {\fmod{CTL}} &  0.106 & 0.016 & 0.868 & 0.002 \\
%     {\fmod{ITL}} & 0.183 & 0.034 & 0.901 & 0.000 \\
%     {\fmod{MTL}}  & 0.150 & 0.023 & 0.906 & 0.001 \\
%     {\fmod{GLMTL}} & \fmax{0.227} & \fmax{0.042} & 0.896 & 0.003 \\
%     {\fmod{cvxGLMTL}} & 0.163 & 0.031 & \fmax{0.908} & \fmax{0.001} \\
%     \midrule        
%     & \fheadmulti{4}{Accuracy}\\
%         \midrule
%         {\fmod{CTL}} &  0.942 & 0.004 & 0.791 & 0.003   \\
%         {\fmod{ITL}} & 0.942 & 0.004 & 0.850 & 0.000 \\
%         {\fmod{MTL}} & 0.943 & 0.004 & 0.858 & 0.002 \\
%         {\fmod{GLMTL}} & 0.935 & 0.002 & 0.844 & 0.005 \\
%         {\fmod{cvxGLMTL}} & \fmax{0.944} & \fmax{0.004} & \fmax{0.862} & \fmax{0.002} \\
%         \bottomrule
%         \end{tabular}}
% \end{table*}

% \begin{table*}[t]
%     \caption{Test  F1 score (left), and accuracy (right) in the classification problems.}
%     \label{tab:error_models_clas}
%     \centering
% \scalebox{.65}{
%     %\begin{tabular}{l*{2}{S[table-format=1.3]@{$\pm$}S[table-format=1.3]}}
%     \begin{tabular}{lrrrr}
%     \toprule
%     & \fheadmulti{2}{F1} & \fheadmulti{2}{Accuracy} \\
%     &  \fheadmulti{1}{\fdata{landmine}} & \fheadmulti{1}{\fdata{binding}}
%     &  \fheadmulti{1}{\fdata{landmine}} & \fheadmulti{1}{\fdata{binding}}\\
%     \midrule
%     {\fmod{CTL}} &  0.106 $\pm$ 0.016 & 0.868 $\pm$ 0.002                   &  0.942 $\pm$ 0.004 & 0.791 $\pm$ 0.003   \\
%     {\fmod{ITL}} & 0.183 $\pm$ 0.034 & 0.901 $\pm$ 0.000                    & 0.942 $\pm$ 0.004 & 0.850 $\pm$ 0.000 \\
%     {\fmod{MTL}}  & 0.150 $\pm$ 0.023 & 0.906 $\pm$ 0.001                & 0.943 $\pm$ 0.004 & 0.858 $\pm$ 0.002 \\
%     {\fmod{GLMTL}} & \fmax{0.227} $\pm$ \fmax{0.042} & 0.896 $\pm$ 0.003    & 0.935 $\pm$ 0.002 & 0.844 $\pm$ 0.005 \\
%     {\fmod{cvxGLMTL}} & 0.163 $\pm$ 0.031 & \fmax{0.908} $\pm$ \fmax{0.001} & \fmax{0.944} $\pm$ \fmax{0.004} & \fmax{0.862} $\pm$ \fmax{0.002} \\
%         \bottomrule
%         \end{tabular}
% }
% \end{table*}

% \\fmod[A-Za-z{}]+([a-z.0-9 (){}-]+&){3}
% ([.0-9 ()]+&){2}
\begin{table*}[t]
    \caption{Top: Wilcoxon $p$-values of absolute errors of a regression model and the one following it in the MAE ranking and similar F1 score $p$ values.
    Bottom: with the same scheme, $p$ values of quadratic errors and the R2 score ranking and accuracy scores.}
    % (bottom); $p$-value rankings shown in parenthesis. \comm{No son acc y f1 en classif?} \resp{S, no est bien la caption}}
    \label{tab:wilcoxon}
    \centering
    \scalebox{.65}{
    \begin{tabular}{l*{6}{S[table-format=1.4]@{ }l}|S[table-format=1.4]@{ }lS[table-format=1.4]@{ }l}
    \toprule
    & \fheadmulti{2}{\fdata{majorca}} & \fheadmulti{2}{\fdata{tenerife}}& \fheadmulti{2}{\fdata{boston}} & \fheadmulti{2}{\fdata{california}} &  \fheadmulti{2}{\fdata{abalone}} & \fheadmulti{2}{\fdata{crime}} & \fheadmulti{2}{\fdata{classif.}}  \\
    \midrule
    &\fheadmulti{12}{MAE} & \fheadmulti{2}{F1} \\
    \midrule
    \fmod{CTL} & 0.0000 & (3) & 0.0000 & (4)  & \fmaxn{0.2554} & \fmaxn{(1)} & 0.0000 & (4) & 0.0002 & (2) & 0.0000 & (2) & 0.0277 & {(3)}\\
    \fmod{ITL} & 0.8131 & (2) & 0.0035 & (2) & 0.0001 & (2) & 0.0318 & (3) & 0.2546 & (2) & 0.3995 & (2) &	\fmaxn{0.3454} & \fmaxn{(1)}\\
    \fmod{MTL} & 0.0000 & (2) & 0.0000 & (3) & {-} & \fmaxn{(1)} &  0.0000 & (2) &  {-} & \fmaxn{(1)} & {-} & \fmaxn{(1)} & 0.0277 & {(2)} \\
    \fmod{GLMTL} & 0.4183 & (3) & 0.5962 & (4) & 0.0621 & (2) &  0.5658 & (3) &  0.0000 & (3) & 0.0000 & (3) & {-} & \fmaxn{(1)} \\
    \fmod{cvxGLMTL} &  {-} & \fmaxn{(1)} & {-} & \fmaxn{(1)} & \fmaxn{0.4113} & \fmaxn{(1)} &  {-} & \fmaxn{(1)} & \fmaxn{0.0771} & \fmaxn{(1)} & \fmaxn{0.6093} & \fmaxn{(1)} & \fmaxn{0.3454} & \fmaxn{(1)}\\
    \midrule
    &\fheadmulti{12}{R2} & \fheadmulti{2}{Accuracy}\\
        \midrule
    \fmod{CTL} & 0.0032 & (3) & 0.0000 & (2)  & \fmaxn{0.1791} & \fmaxn{(1)} & 0.0000 & (4) & 0.0016 & (3) & 0.0001 & (2) & 0.3454 & (4) \\
        \fmod{ITL} & 0.6340 & (2) & \fmaxn{0.5999} & \fmaxn{(1)} & 0.0001 & (2)  & 0.0035 & (3) & 0.3096 & (3) & 0.3972 & (2) & 0.0277 & (3)\\
        \fmod{MTL} & 0.0000 & (2) & \fmaxn{0.0815} & \fmaxn{(1)} & {-} & \fmaxn{(1)} & 0.0000 & (2) &  {-} & \fmaxn{(1)} & {-} & \fmaxn{(1)} & 0.0431 & (2)\\
        \fmod{GLMTL} & 0.2040 & (3) & 0.7790 & (2) & 0.0384 & (3) &  0.6759 & (3) &  0.0000 & (4) & 0.0000 & (3) & 0.0277 & (4) \\
        \fmod{cvxGLMTL} &  {-} & \fmaxn{(1)} & {-} & \fmaxn{(1)} & \fmaxn{0.2606} & \fmaxn{(1)} &  {-} & \fmaxn{(1)} &  0.0181 & (2) & \fmaxn{0.7262} & \fmaxn{(1)} & 	{-} & \fmaxn{(1)} \\
        \bottomrule
    \end{tabular}}
\end{table*}

In Table~\ref{tab:error_models_full} we give the test scores for the regression problems; we consider the \acrshort{mae}, which is the most natural for \acrshort{svms}, and the R2 score which is a normalized \acrshort{mse}.

To show statistical significance we apply the procedure based on the Wilcoxon test, as described before. Recall that we first rank the models, either according to \acrshort{mae} or R2 score, and then the first model is assigned a ranking of $1$, and for the second model we use a Wilcoxon test to check if the difference with the first one is significant. If we reject the null hypothesis, we consider that both models are different and we give the second model a ranking of $2$, in other case we assign a ranking of $1$. We continue proceeding like this for each pair of consecutive models to get a ranking that is somehow statistically significant. We give this ranking, alongside the $p$-values of the corresponding pairwise Wilcoxon test in Table~\ref{tab:wilcoxon}.
%
%Recall that the Wilcoxon test checks if the difference between two paired samples is symmetrically distributed around zero.
 We 
 %use the list of errors in each instance by each model as paired samples and 
 reject the null hypothesis at the \SI{5}{\percent} significance level.
%

It can be observed in Table~\ref{tab:error_models_full} that, in terms of \acrshort{mae}, our proposed \fmod{cvxGLMTL} gets the best results in most regression problems, and even when this is not the case, we can see in Table~\ref{tab:wilcoxon} that the difference with the best model is not significant. Only in the case of~\fdata{abalone}, the \fmod{MTL} model gets significantly better results, and just in terms of R2 score.
%

In the case of classification problems, we also give the accuracy and F1 test scores in Table~\ref{tab:error_models_full}. We notice that in \fdata{landmine}, which is strongly unbalanced, although the accuracy scores are generally high, the F1 scores are low. On the other hand, in a balanced problem such as \fdata{binding}, both the accuracy and F1 scores are similar.
%

As it has been pointed out already, in the classification setting we cannot compute the accuracy or F1 score at every instance, so to apply the Wilcoxon test we can only use the score values computed for each of the outer folds in each problem, that is, a total of $6$ different values.
Given that this is a small sample, the validity of using the Wilcoxon test is not guaranteed. However, for illustration puroposes we provide the Wilcoxon $p$-values and rankings in the last column of ~\ref{tab:wilcoxon}. Observe that now we have a single ranking for all the problems, because we are combining the scores of all the problems, as described above, to apply the Wilcoxon test.


\begin{table*}[t]
    \caption{Train MAE in the regression problems (smallest values in bold face).}
    \label{tab:error_models_train}
    \centering
    \scalebox{.65}{
        \begin{tabular}{l*{2}{S[table-format=1.3]}S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]S[table-format=1.3]@{$\pm$}S[table-format=1.3]}
            \toprule
    & \fhead{\fdata{maj.}} & \fhead{\fdata{ten.}} & \fheadmulti{2}{\fdata{boston}} & \fheadmulti{2}{\fdata{california}} &  \fheadmulti{2}{\fdata{abalone}} & \fheadmulti{2}{\fdata{crime}} \\
    \midrule
    &\fheadmulti{10}{MAE} \\
    \midrule
        {\fmod{CTL}}              &       3.440 &        4.183 &   1.557 & 0.198 &  {40502.686} & {222.209} &  1.434 & 0.019 &   0.055 & 0.006 \\
        {\fmod{ITL}}              &       3.590 &        3.914 &   1.883 & 0.224 &   {34403.940} & {83.583} &  1.399 & 0.025 &   0.050 & 0.004 \\
        {\fmod{MTL}}       &       3.649 &        3.921 &   1.522 & 0.248 &  {35061.556} & {118.259} &  1.399 & 0.027 &   0.055 & 0.007 \\
        {\fmod{GLMTL}}     &       \fmaxn{2.630} &        \fmaxn{3.728} &   2.077 & 0.447 &  \fmaxn{33984.568} & \fmaxn{151.998} &  1.594 & 0.023 &   \fmaxn{0.038} & \fmaxn{0.002} \\
        {\fmod{cvxGLMTL}} &       3.344 &        4.141 &   \fmaxn{1.516} &\fmaxn {0.270} &  {34409.942} & {101.472} &  \fmaxn{1.406} &\fmaxn {0.023} &   0.057 & 0.007 \\
        % \midrule
        % &\fheadmulti{10}{R2} \\
        %     \midrule
        % {\fmod{CTL}}        & 0.892 &       0.940 &  0.922 & 0.015 &  0.656 & 0.001 &  0.581 & 0.010 &  0.829 & 0.017 \\
        % {\fmod{ITL}}        & 0.875 &       0.938 &  0.874 & 0.016 &  0.728 & 0.001 &  0.592 & 0.005 &  0.831 & 0.022 \\
        % {\fmod{MTL}}     &  0.873 &       0.940 &  0.928 & 0.018 &  0.721 & 0.001 &  0.595 & 0.009 &  0.829 & 0.012 \\
        % {\fmod{GLMTL}}      &  0.909 &       0.939 &  0.684 & 0.113 &  0.732 & 0.003 &  0.418 & 0.007 &  0.883 & 0.013 \\
        % {\fmod{cvxGLMTL}}   &  0.887 &       0.934 &  0.928 & 0.018 &  0.728 & 0.002 &  0.591 & 0.008 &  0.818 & 0.010 \\
        \bottomrule
        \end{tabular}

    }
\end{table*}

%
Finally, if we compare the two approaches using the \acrshort{gl} regularization, we can see that the \fm{GLMTL} performs quite well in the classification problems but less so in regression problems. As a possible explanation, recall that a pure \acrshort{gl} does not include individual regularizers for each $w_r$, so the models are more prone to overfitting. To support this theory, we give the training errors in Table~\ref{tab:error_models_train}, where \fmod{GLMTL} gets the best \acrshort{mae} scores in \fdata{majorca}, \fdata{tenerife}, \fdata{california} and \fdata{crime}, but these results are not transferred completely to the test sets, where \fmod{cvxGLMTL} gets better results.
%

























\section{Adaptive Graph Laplacian for Multi-Task Learning}\label{sec:adapconvexgl_experiments}

The convex \acrshort{mtl} or even the convex \acrshort{gl} approach assume that all tasks are connected or related to each other. However, there might be problems where there are some characteristics shared by all tasks, others that are present in a subgroup of tasks, and others that are task-specific.
%
To take into account this kind of dependences, we have proposed the convex adaptive \acrshort{gl} \acrshort{mtl} formulation in~\cite{RuizAD21_hais}, which we have described in Section~\ref{sec:adapconvexgl}.
%
In this section we present some experiments to test our proposal, using both synthetic and real data. 
%
To make this comparison we consider the \acrshort{ctl}, \acrshort{itl} and \acrshort{mtl} approaches. More specifically, using the nomenclature LX-\acrshort{svm} to refer for either L1, L2 or LS-\acrshort{svm}, we will compare the following:
\begin{itemize}
    \item \fmod{CTL-LX}: A \acrshort{ctl} model based on the LX-\acrshort{svm}.
    \item \fmod{ITL-LX}: An \acrshort{itl} model based on the LX-\acrshort{svm}.
    \item \fmod{MTL-LX}: A Convex \acrshort{mtl} model based on the LX-\acrshort{svm}, as explained in Section~\ref{sec:convexmlt_kernel}.
    \item \fmod{GLMTL-LX}: A Convex GL \acrshort{mtl} model based on the LX-\acrshort{svm}, as presented in Section~\ref{sec:convexgl}.
    \item \fmod{AdapGLMTL-LX}: An Adaptive Convex GL \acrshort{mtl} model based on the LX-\acrshort{svm}, as presented in Section~~\ref{sec:adapconvexgl}.
\end{itemize}
In all cases we use \acrshort{svms} with Gaussian kernels. We recall that in the adaptive convex \acrshort{gl} formulation two possible kernel spaces can be used simultaneously.
%

We conduct experiments with both synthetic and real data, each requiring a different experimental procedure because of their respective computational cost. We first describe the synthetic problems and then those with real data. In each case, we describe the characteristic of the problems, explain the procedure and discuss the corresponding results. 



\subsection{Synthetic Problems}
%
We use synthetic problems to generate data where the inter-task relationships are known, so we can check if our proposed model is able to detect this underlying task structure.
%
Also, we generate small training datasets so we can find all the hyperparameters using a grid-search procedure.

%\subsubsection*{Problems' Description.}


\begin{figure}[t!]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Chapter6/IGPL2022/regClusters__0.pdf}
        \caption{\fdata{regClusters0}.}
        \label{regClusters0}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Chapter6/IGPL2022/clasClusters__0.pdf}
        \caption{\fdata{clasClusters0}.}
        \label{clasClusters0}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Chapter6/IGPL2022/regClusters__1.pdf}
        \caption{\fdata{regClusters1}.}
        \label{regClusters1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Chapter6/IGPL2022/clasClusters__1.pdf}
        \caption{\fdata{clasClusters1}.}
        \label{clasClusters1}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Chapter6/IGPL2022/regClusters__2.pdf}
        \caption{\fdata{regClusters2}.}
        \label{regClusters2}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Chapter6/IGPL2022/clasClusters__2.pdf}
        \caption{\fdata{clasClusters2}.}
        \label{clasClusters2}
    \end{subfigure}
    \caption{Representation of the synthetic problems. We use a different color for each ``underlying'' task and a different marker for each ``virtual'' task. In the case of classification, we take two tones for each color: the darker one corresponds to the positive labels, while the lighter one corresponds to the negative labels.}
\end{figure}

Regarding the definition of the synthetic problems, we generate three pairs of related regression and classification problems, namely \fdata{regClusters0}, \fdata{regClusters1} and \fdata{regClusters2} for regression, and \fdata{clasClusters0}, \fdata{clasClusters1} and \fdata{clasClusters2} for classification.
The data in each pair, such as, for example, \fdata{regClusters0} and \fdata{clasClusters0}, is generated using essentially the same procedure, and the underlying functions in the regression problems are also the decision boundaries in the classification ones.
%
In each problem, we define a number of ``underlying'' tasks $\tau$, and for $r=1, \ldots, \tau$ we have a function $f_r$.
Then, for each $r$-th ``underlying'' task, with $r=1, \ldots, \tau$, we generate $T_r$ ``virtual'' tasks; although their data is sampled using basically the same function, models will see them with different task labels, although these models should be able to identify their similarities and somehow group them.
%
The total number of tasks in each problem is thus $\sum_{r=1}^{\tau} T_r$, and we denote them as $t_i^r$, where the superindex $r=1, \ldots, \tau$ correspond to the ``underlying'' task and the subindex $i=1, \ldots, T_r$ are the ``virtual'' tasks or task labels. Therefore, each model receives a total of $\sum_{r=1}^\tau T_r$ different task labels.
%
For each task label $t_i^r$, we sample $m_i^r$ points, so the total number of points for each problem is $\sum_{r=1}^\tau \sum_{i=1}^{T_r} m_i^r$.
%
More precisely, we proceed as follows:
\begin{itemize}
    \item In problems \fdata{regClusters0} and \fdata{clasClusters0}, we define $\tau=3$ ``underlying'' tasks, defined by the functions $f_1(x) = x^2$,  $f_2(x) = \sin(10x)$, $f_3(x) = x^3$. Moreover, we further subdivide them in $T_1 = 2, T_2 = 3$ and $T_3 = 2$ tasks, respectively. The resulting regression dataset is shown in Figure~\ref{regClusters0}, and the classification one in Figure~\ref{clasClusters0}. 
    \item In problems \fdata{regClusters1} and \fdata{clasClusters1} we define $\tau=2$ ``underlying'' tasks, defined by the functions $f_1(x) = x^2$,  $f_2(x) = \sin(10x)$, and we further subdivide them in
    $T_1 = 5$ and $T_2 = 2$ tasks, respectively. The resulting regression dataset is shown in Figure~\ref{regClusters1}, and the classification one in Figure~\ref{clasClusters1}. 
    \item Finally, in problems \fdata{regClusters2} and \fdata{clasClusters2} we define $\tau=2$ ``underlying'' tasks in terms of the functions $f_1(x) = \sin(10x)$, $f_2 = x^3$, and we further subdivide them in
    $T_1 = 4$ and $T_2 = 1$ tasks, respectively. The resulting regression dataset is shown in Figure~\ref{regClusters2}, and the classification one in Figure~\ref{clasClusters2}.
\end{itemize}
%
In the regression problems we sample $150$ values $x_i$ for each task label (``virtual'' task) and using the corresponding function we compute the corresponding target values as $t_i = f(x_i) + \epsilon_i$, where $\epsilon_i \sim \normal{0, 0.1}$.
For the classification problems we sample $500$ pairs $(x_{i,1}, x_{i,2})$ and get the class values in terms of the corresponding function as $c_i = \sign(x_{i,2} - f(x_{i,1}) + \epsilon_i)$, where now $\epsilon_i \sim \normal{0, 1}$.
%
Since we sample $150$ pairs for each task, in this problem $300$, $450$ and $300$ patterns come from the underlying tasks $1$, $2$ and $3$, respectively.
%
Therefore, in \fdata{regClusters0}, for example, we have a total of $7 \times 150 = \num{1050}$ pairs $(x_i, t_i)$. 

%\subsubsection*{Experimental Procedure}
The experimental procedure to test the performance of our proposal is the following one.
First, we keep \SI{10}{\percent} of the data for training and validation, while the remaining data is used as test set. Thus, in the regression problems we use $15$ patterns for train and validation, and in the classification problems we use $50$ examples.
%
We remark the small size of the training and validation sets; however this is done consciously; otherwise, if the one-dimensional problems we generate are not challenging enough, we would get perfect score with all the models, which is no useful. We use thus the scarcity of data to make the problems more difficult.
%

The optimal hyperparameters for each model in each problem are selected using a $5$-fold \acrshort{cv} grid search; as with the rest of the experiments, the corresponding grids are given Table~\ref{table:hyperpars_grid_full}.
%
Once these optimal hyperparameters are selected, we use the associated hyperparametrized models and refit them using the entire train and validation set; then we compute the test scores on the test set.
%
For the regression problems we use the \acrshort{mae} as the validation metric, while we use the F1 score for classification ones.
%
To get more stable results, the full procedure, i.e. the problem generation, hyperparameter selection and test scores computation for each model, is repeated $10$ times with every problem.
%

\begin{table}[t!]
    \caption{Hyperparameters, grids used to select them (when appropriate) and hyperparameter selection method for each model in the synthetic and real problems.
    The parameter $\epsilon$ is only suitable for regression with L1 and L2-\acrshort{svm}.
    }
    \label{table:hyperpars_grid_full}
    \centering
    \scalebox{.65}{
     \begin{tabular}{*{8}{c}}
     \toprule
     \fhead{} & \fhead{Grid} & \fhead{\fmod{CTL-LX}} & \fhead{\fmod{ITL-LX}} & \fhead{\fmod{MTL-LX}}  & \fhead{\fmod{GLMTL-LX}} & \fhead{\fmod{AdapGLMTL-LX}}   \\
     \midrule
      \fheadmulti{7}{Synthetic Problems} \\
     \midrule
      $C$ &  \scalebox{1}{$\set{10^k: 0 \leq k \leq 5}$} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark  \\ 
      $\epsilon$ & \scalebox{1}{$\set{\frac{1}{10^k}: 1 \leq k \leq 3}$} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
      $\gamma$ & \scalebox{1}{$\set{\frac{10^k}{d}: 0 \leq k \leq 3}$} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark  \\
      %$\gamma_s^r$ & \scalebox{1}{$\set{\frac{4^k}{d}: -2 \leq k \leq 3}$} & - & \checkmark & - & - & -\\
      $\lambda$ & \scalebox{1}{$\set{0.2 k : 0 \leq k \leq 5}$} & - & - & \checkmark & \checkmark & \checkmark \\
      $\nu$ & \scalebox{1}{$\set{10^k : -2 \leq k \leq 3}$} & - & - & - & \checkmark & \checkmark \\
      $\mu$ & \scalebox{1}{$\set{10^k : 0 \leq k \leq 5}$} & - & - & - & - & \checkmark \\
      \midrule
      \fheadmulti{7}{Real Problems} \\
      \midrule 
      $C$ &  \scalebox{1}{$\set{10^k: 0 \leq k \leq 4}$} & \checkmark & \checkmark & \checkmark & - & - \\ 
      $\epsilon$ & \scalebox{1}{$\set{\frac{1}{10^k}: 1 \leq k \leq 4}$} & \checkmark & \checkmark & \checkmark & - & - \\
      $\gamma$ & \scalebox{1}{$\set{\frac{10^k}{d}: -3 \leq k \leq 2}$} & \checkmark & \checkmark & \checkmark & - & - \\
      $\gamma_s$ & \scalebox{1}{$\set{\frac{10^k}{d}: -3 \leq k \leq 2}$} & - & - & \checkmark & - & - \\
      $\lambda$ & \scalebox{1}{$\set{0.1 k : 0 \leq k \leq 10}$} & - & - & \checkmark & - & - \\
      $\nu$ & \scalebox{1}{$\set{0} \cup \set{10^k : -4 \leq k \leq 3}$} & - & - & - & \checkmark & \checkmark \\
      $\mu$ & \scalebox{1}{$\set{0} \cup \set{10^k : -4 \leq k \leq 3}$} & - & - & - & - & \checkmark \\
      \bottomrule
     \end{tabular}
    }
\end{table}

%\subsubsection*{Results}
%
In Table~\ref{tab:full_synthetic} we give the test results for the regression problems where we consider the \acrshort{mae} as the metric to measure the performance of the models.
%
Here, we observe that our proposal, \fmod{AdapGLMTL}, gets the best test scores in all problems and for all the variants of the \acrshort{svm}.
To better understand these results we can look at the adjacency matrices learned by the \fmod{AdapGLMTL} models, which are depicted in Figure~\ref{fig:reg_adjmatrix_regClusters0} for problem \fdata{regClusters0}, in Figure~\ref{fig:reg_adjmatrix_regClusters1} for problem \fdata{regClusters1} and in Figure~\ref{fig:reg_adjmatrix_regClusters2} for problem \fdata{regClusters2}.
%
In general, it can be observed that our method detects the underlying task structure and exploits it.
See, for instance, the adjacency matrices learned for the problem \fdata{regCluster0}, where there are three distinct clusters, one for each of the three ``underlying'' tasks of such problem, corresponding to the task-defining functions $f_1(x) = x^2$,  $f_2(x) = \sin(10x)$ and $f_3(x) = x^3$.
%
A similar behavior can be found in all the regession problems with all the \acrshort{svm} variants, as shown in Figures~\ref{fig:reg_adjmatrix_regClusters1} and~\ref{fig:reg_adjmatrix_regClusters2}.
%
The improvement on the test scores can then be explained by the implicit data augmentation that takes place when the tasks, corresponding to the same ``underlying'' task, are grouped and learned together.
%
For example, in problem \fdata{regClusters1}, after the structure of the ``underlying'' tasks has been identified, our proposal can use $0.1 \times 5 \times 150 = 75$ examples, instead of the $15$ that would be considered when each task is to be learned separately.
%

%
In the classification problems, the results are not that clear-cut.
We give in Table~\ref{tab:full_synthetic} the F1 test scores for each model, and, in most cases, the proposed \fmod{AdapGLMTL} gets the best results.
However, there are cases where our proposal ties with other approaches, or even where other models obtains the largest F1 score.
%
In Figures~\ref{fig:clas_adjmatrix_clasClusters0}, ~\ref{fig:clas_adjmatrix_clasClusters1} and~\ref{fig:clas_adjmatrix_clasClusters2}, we give the adjacency matrix for problems \fdata{clasClusters0}, \fdata{clasClusters1} and \fdata{clasClusters2}, respectively.
%
These matrices, although they show that some information about the task structure is inferred from the problems, do not perfectly capture the task relationships, and, therefore, the learning process does not improve task identification that much.
This is specially true for the results of the LS-\acrshort{svm} variant, where the matrices learned are very close to the constant matrix, and the results are clearly inferior than those of the L1 or L2-\acrshort{svms}.
One possible reason can be found in the nature of the LS-\acrshort{svm} for classification, which builds a regression function for the positive class and another for the negative one, which usually leads to worse results than those of models designed directly for classification.

%

% Problems
% \begin{figure}[t!]
%     \centering
%     \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/IGPL2022/regClusters__0.pdf}
%         \caption{\fdata{regClusters0}.}
%         \label{regClusters0}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/IGPL2022/clasClusters__0.pdf}
%         \caption{\fdata{clasClusters0}.}
%         \label{clasClusters0}
%     \end{subfigure}
%     %\caption{Representation of problems \fdata{regClusters0} and \fdata{clasClusters0}. We use a different color for each ``underlying'' task and a different marker for each ``virtual'' task. In the case of classification, we take two tones for each color: the darker one corresponds to the positive labels, while the lighter one corresponds to the negative labels.}
% \end{figure}


% \begin{figure}[t!]
%     \centering
%     \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/IGPL2022/regClusters__1.pdf}
%         \caption{\fdata{regClusters1}.}
%         \label{regClusters1}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{Chapter6/IGPL2022/clasClusters__1.pdf}
%         \caption{\fdata{clasClusters1}.}
%         \label{clasClusters1}
%     \end{subfigure}
% %\caption{Representation of problems \fdata{regClusters1} and \fdata{clasClusters1}. . We use a different color for each ``underlying'' task and a different marker for each ``virtual'' task. In the case of classification, we take two tones for each color: the darker one corresponds to the positive labels, while the lighter one corresponds to the negative labels.}
% \end{figure}




% Tables

% \centering
% \begin{tabular}{lrrr}
%     \toprule
%     {} &  \fdata{regClusters0} &  \fdata{regClusters1} &  \fdata{regClusters2} \\
%     \midrule-
%     CTLL1               &           0.946 &           0.669 &           0.555 \\-
%     ITLL1               &           0.174 &           0.203 &           0.160 \\-
%     ConvexMTLL1         &           0.207 &           0.161 &           0.146 \\-
%     ConvexGLMTLL1       &           0.209 &           0.162 &           0.143 \\-
%     AdapConvexGLMTLL1   &           0.109 &           0.103 &           0.127 \\
%     \midrule
%     CTLL2SVM             &           1.033 &           0.692 &           0.781 \\
%     ITLL2SVM             &           0.173 &           0.188 &           0.144 \\
%     ConvexMTLL2SVM       &           0.197 &           0.164 &           0.137 \\
%     ConvexGLMTLL2SVM     &           0.189 &           0.170 &           0.138 \\
%     AdapConvexGLMTLL2SVM &           0.109 &           0.098 &           0.112 \\
%     \midrule
%     CTLLSSVM             &           1.032 &           0.691 &           0.778 \\
%     ITLLSSVM             &           0.172 &           0.187 &           0.143 \\
%     ConvexMTLLSSVM       &           0.178 &           0.162 &           0.136 \\
%     ConvexGLMTLLSSVM     &           0.194 &           0.168 &           0.141 \\
%     AdapConvexGLMTLLSSVM &           0.138 &           0.103 &           0.119 \\
%     \bottomrule
% \end{tabular}

% \centering
% \begin{tabular}{lrrr}
%     \toprule
%     {} &  \fdata{clasClusters0} &  \fdata{clasClusters1} &  \fdata{clasClusters2} \\
%     \midrule-
%     CTLL1               &            0.913 &            0.911 &            0.906 \\-
%     ITLL1               &            0.929 &            0.931 &            0.893 \\-
%     ConvexMTLL1         &            0.911 &            0.931 &            0.911 \\-
%     ConvexGLMTLL1       &            0.929 &            0.930 &            0.911 \\-
%     AdapConvexGLMTLL1   &            0.924 &            0.929 &            0.914 \\
%     \midrule
%     CTLL2SVM             &            0.910 &            0.914 &            0.904 \\
%     ITLL2SVM             &            0.934 &            0.933 &            0.914 \\
%     ConvexMTLL2SVM       &            0.923 &            0.929 &            0.901 \\
%     ConvexGLMTLL2SVM     &            0.925 &            0.933 &            0.901 \\
%     AdapConvexGLMTLL2SVM &            0.936 &            0.935 &            0.906 \\
%     \midrule
%     CTLLSSVM             &            0.899 &            0.903 &            0.876 \\
%     ITLLSSVM             &            0.929 &            0.919 &            0.866 \\
%     ConvexMTLLSSVM       &            0.929 &            0.922 &            0.905 \\
%     ConvexGLMTLLSSVM     &            0.929 &            0.924 &            0.905 \\
%     AdapConvexGLMTLLSSVM &            0.929 &            0.924 &            0.905 \\
%     \bottomrule
% \end{tabular}




\begin{table}
    \caption{\acrshort{mae} scores for synthetic regression problems and F1 scores for synthetic classification ones. In bold we highlight the best models of each group: L1, L2 or LS-\acrshort{svms}.}
    \label{tab:full_synthetic}
    \centering
    \scalebox{.65}{
    \begin{tabular}{lccc|ccc}
        \toprule
        {} &  \fhead{\fdata{regClusters0}} &  \fhead{\fdata{regClusters1}} &  \fhead{\fdata{regClusters2}} &  \fhead{\fdata{clasClusters0}} &  \fhead{\fdata{clasClusters1}} &  \fhead{\fdata{clasClusters2}} \\
        \midrule
        & \fheadmulti{3}{MAE} & \fheadmulti{3}{F1} \\
        \midrule
        \fmod{CTL-L1}               &            0.989 &            0.512 &            0.541                 &             0.901 &             0.912 &             0.904 \\
        \fmod{ITL-L1}               &            0.221 &            0.212 &            0.159                 &             0.922 &             0.923 &             0.910 \\
        \fmod{MTL-L1}         &            0.213 &            0.176 &            0.135           &             \fmaxn{0.924} &             0.925 &             0.914 \\
        \fmod{GLMTL-L1}       &            0.212 &            0.173 &            0.138         &             0.920 &             0.926 &             0.912 \\
        \fmod{AdapGLMTL-L1}   &            \fmaxn{0.152} &            \fmaxn{0.116} &            \fmaxn{0.107}     &             \fmaxn{0.924} &             \fmaxn{0.929} &             \fmaxn{0.916} \\
        \midrule
        \fmod{CTL-L2}             &            0.990 &            0.642 &            0.768               &             0.904 &             0.912 &             0.906 \\
        \fmod{ITL-L2}             &            0.213 &            0.201 &            0.154               &             \fmaxn{0.928} &             0.928 &             0.910 \\
        \fmod{MTL-L2}       &            0.209 &            0.168 &            0.131         &             0.925 &             0.927 &             0.913 \\
        \fmod{GLMTL-L2}     &            0.204 &            0.169 &            0.131       &             0.921 &             0.923 &             \fmaxn{0.915} \\
        \fmod{AdapGLMTL-L2} &            \fmaxn{0.141} &            \fmaxn{0.115} &            \fmaxn{0.103}   &             0.924 &             \fmaxn{0.929} &             \fmaxn{0.915} \\
        \midrule
        \fmod{CTL-LS}             &            0.989 &            0.642 &            0.766               &             0.895 &             0.908 &             0.894 \\
        \fmod{ITL-LS}             &            0.212 &            0.209 &            0.149               &             0.914 &             0.915 &             0.904 \\
        \fmod{MTL-LS}       &            0.206 &            0.167 &            0.131         &             0.917 &             0.917 &             \fmaxn{0.905} \\
        \fmod{GLMTL-LS}     &            0.207 &            0.169 &            0.132       &             0.919 &             \fmaxn{0.921} &             0.897 \\
        \fmod{AdapGLMTL-LS} &            \fmaxn{0.136} &            \fmaxn{0.115} &            \fmaxn{0.106}   &             \fmaxn{0.920} &             \fmaxn{0.921} &             0.901 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

% \begin{table}
%     \caption{Mean Absolute Error scores for synthetic regression problems. In bold we highlight the best models of each group: L1, L2 or LS-SVMs.}
%     \label{tab:regression_synthetic}
%     \centering
%     \scalebox{.65}{
%     \begin{tabular}{lrrr}
%         \toprule
%         {} &  \fhead{\fdata{regClusters0}} &  \fhead{\fdata{regClusters1}} &  \fhead{\fdata{regClusters2}} \\
%         \midrule
%         \fmod{CTL-L1}               &            0.989 &            0.512 &            0.541 \\
%         \fmod{ITL-L1}               &            0.221 &            0.212 &            0.159 \\
%         \fmod{MTL-L1}         &            0.213 &            0.176 &            0.135 \\
%         \fmod{GLMTL-L1}       &            0.212 &            0.173 &            0.138 \\
%         \fmod{AdapGLMTL-L1}   &            \fmaxn{0.152} &            \fmaxn{0.116} &            \fmaxn{0.107} \\
%         \midrule
%         \fmod{CTL-L2}             &            0.990 &            0.642 &            0.768 \\
%         \fmod{ITL-L2}             &            0.213 &            0.201 &            0.154 \\
%         \fmod{MTL-L2}       &            0.209 &            0.168 &            0.131 \\
%         \fmod{GLMTL-L2}     &            0.204 &            0.169 &            0.131 \\
%         \fmod{AdapGLMTL-L2} &            \fmaxn{0.141} &            \fmaxn{0.115} &            \fmaxn{0.103} \\
%         \midrule
%         \fmod{CTL-LS}             &            0.989 &            0.642 &            0.766 \\
%         \fmod{ITL-LS}             &            0.212 &            0.209 &            0.149 \\
%         \fmod{MTL-LS}       &            0.206 &            0.167 &            0.131 \\
%         \fmod{GLMTL-LS}     &            0.207 &            0.169 &            0.132 \\
%         \fmod{AdapGLMTL-LS} &            \fmaxn{0.136} &            \fmaxn{0.115} &            \fmaxn{0.106} \\
%         \bottomrule
%     \end{tabular}
%     }
% \end{table}

% \begin{table}
%     \caption{F1 scores for synthetic classification problems. In bold we highlight the best models of each group: L1, L2 or LS-SVMs.}
%     \label{tab:classification_synthetic}
%     \centering
%     \scalebox{.65}{
% \begin{tabular}{lrrr}
%     \toprule
%     {} &  \fhead{\fdata{clasClusters0}} &  \fhead{\fdata{clasClusters1}} &  \fhead{\fdata{clasClusters2}} \\
%     \midrule
%     \fmod{CTL-L1}               &             0.901 &             0.912 &             0.904 \\
%     \fmod{ITL-L1}               &             0.922 &             0.923 &             0.910 \\
%     \fmod{MTL-L1}         &             \fmaxn{0.924} &             0.925 &             0.914 \\
%     \fmod{GLMTL-L1}       &             0.920 &             0.926 &             0.912 \\
%     \fmod{AdapGLMTL-L1}   &             \fmaxn{0.924} &             \fmaxn{0.929} &             \fmaxn{0.916} \\
%     \midrule
%     \fmod{CTL-L2}             &             0.904 &             0.912 &             0.906 \\
%     \fmod{ITL-L2}             &             \fmaxn{0.928} &             0.928 &             0.910 \\
%     \fmod{MTL-L2}       &             0.925 &             0.927 &             0.913 \\
%     \fmod{GLMTL-L2}     &             0.921 &             0.923 &             \fmaxn{0.915} \\
%     \fmod{AdapGLMTL-L2} &             0.924 &             \fmaxn{0.929} &             \fmaxn{0.915} \\
%     \midrule
%     \fmod{CTL-LS}             &             0.895 &             0.908 &             0.894 \\
%     \fmod{ITL-LS}             &             0.914 &             0.915 &             0.904 \\
%     \fmod{MTL-LS}       &             0.917 &             0.917 &             \fmaxn{0.905} \\
%     \fmod{GLMTL-LS}     &             0.919 &             \fmaxn{0.921} &             0.897 \\
%     \fmod{AdapGLMTL-LS} &             \fmaxn{0.920} &             \fmaxn{0.921} &             0.901 \\
%     \bottomrule
% \end{tabular}
%     }
% \end{table}    
    

    


% Adjacency Matrices

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{Chapter6/IGPL2022/adjMatrix_all__regClusters_0.pdf}
    \caption{Adjacency matrices learned for Adaptive GL MTL L1, L2 and LS-SVRs in problem \fdata{regClusters0}.}
    \label{fig:reg_adjmatrix_regClusters0}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{Chapter6/IGPL2022/adjMatrix_all__regClusters_1.pdf}
    \caption{Adjacency matrices learned for Adaptive GL MTL L1, L2 and LS-SVRs in problem \fdata{regClusters1}.}
    \label{fig:reg_adjmatrix_regClusters1}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{Chapter6/IGPL2022/adjMatrix_all__regClusters_2.pdf}
    \caption{Adjacency matrices learned for Adaptive GL MTL L1, L2 and LS-SVRs in problem \fdata{regClusters2}.}
    \label{fig:reg_adjmatrix_regClusters2}
\end{figure}



\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{Chapter6/IGPL2022/adjMatrix_all__clasClusters_0.pdf}
    \caption{Adjacency matrices learned for Adaptive GL MTL L1, L2 and LS-SVCs in problem \fdata{clasClusters0}.}
    \label{fig:clas_adjmatrix_clasClusters0}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{Chapter6/IGPL2022/adjMatrix_all__clasClusters_1.pdf}
    \caption{Adjacency matrices learned for Adaptive GL MTL L1, L2 and LS-SVCs in problem \fdata{clasClusters1}.}
    \label{fig:clas_adjmatrix_clasClusters1}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\textwidth]{Chapter6/IGPL2022/adjMatrix_all__clasClusters_2.pdf}
    \caption{Adjacency matrices learned for Adaptive GL MTL L1, L2 and LS-SVCs in problem \fdata{clasClusters2}.}
    \label{fig:clas_adjmatrix_clasClusters2}
\end{figure}


\subsection{Real Problems}

%\subsubsection*{Problems' Description}

%

%

Apart from the synthetic problems, we also use real data to test our proposal. We consider two regression datasets, \fdata{computer} and \fdata{parkinson}, and a classification dataset, \fdata{landmine}, which has already been described.
%
The \fdata{computer} dataset~\citep{Lenk96}, which has been used in several works~\citep{ArgyriouEP08,AgarwalDG10,KumarD12,JeongJ18}, represents the likelihood of purchasing different computer models, as gathered from a survey of $190$ people, who consider $13$ binary attributes of each computer model. There are $20$ different models that the users have to evaluate; thus, we have $190$ tasks with $20$ examples each.
%
The \fdata{parkinson} dataset\footnote{Available at \url{https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring}.} has data of the voice of 42 people in early stage of Parkinson's disease. They represent each recording with 26 attributes and the target is the UPDRS score, a measurement of the movement, of the patient corresponding to each example. 
In total, there are \num{5875} examples, from $42$ different tasks.
%
% Recall that the \fdata{landmine} dataset contains $9$-dimensional vectors, whose features are extracted from radar images, from $29$ types of landmines. The goal is to decide if there is a landmine present in the image (positive class) or not. In total there are \num{14820} patterns from $29$ different tasks, with an imbalanced ratio of $15.4$ (negative class per positive class example).
%
%In Table~\ref{table:size_dim_tasks} we give the characteristics of these problems.
We point out that their size, particularly for \fdata{landmine}, make them computationally challenging, specially for kernel methods.


% \begin{table*}[t!]
%     \caption{Sample sizes, dimensions and number of tasks of the datasets used.}
%     \label{table:size_dim_tasks}
%     \centering
%     \scalebox{.65}{
%     \begin{tabular}{l*{6}{S[table-format=5]}}
%     \toprule
%     \fhead{Name} & \fhead{Size} & \fhead{No. feat.} & \fhead{No. tasks} & \fhead{Avg. task size} & \fhead{Min. task size} & \fhead{Max. task size}\\
%     \midrule
%     \fdata{computer} & 3800 & 13 & 190 & 20 & 20 & 20 \\ 
%     \fdata{parkinson} & 5875 & 18 & 42 & 140 & 101 & 168 \\
%     \fdata{landmine} & 14820 & 10 & 28 & 511 & 445 & 690 \\
%     \bottomrule
%    \end{tabular} 
%     }
% \end{table*}


%\subsubsection*{Experimental Procedure}
Due to the computational limitations, here we consider a different approach for the experimental procedure to the one used for synthetic problems and again we reutilize hyperparameters, as we have done in the others experiments with real data.
To compute different test scores for more stable results, we use $5$ external folds, where four folds are used for train and validation and the remaining one as test set.
That is, we get $5$ different test scores and average them for a better estimation of the performance of the models. 
%
For searching the optimal hyperparameters, with each outer train-validation set we perform a randomized search with an internal $5$-fold \acrshort{cv}. That is, we define a discrete grid for each hyperparameter and then a maximum of $50$ points over the entire combined grid are evaluated on the inner train-validation folds.
%
We select the hyperparameter combination with the best average validation score, and the corresponding model is refitted on the entire outer train-validation set, and then applied to the outer test fold to compute the test score. In Table~\ref{tab:results_real} we give the averages of the $5$ test scores that we obtain with this procedure.
%
We remark that the number of hyperparameters in the \fmod{GLMTL} and \fmod{AdapGLMTL} models, which include the \acrshort{gl} regularization, is $5$ and $6$, which define spaces too large to be covered with only $50$ points. To alleviate this, we first pre-select the hyperparameters $C, \epsilon, \gamma, \gamma_s$ with those values that are optimal for the \fmod{MTL} model. Recall that we are using two different kernel widths, as discussed on the \acrshort{gl} \acrshort{mtl} Section in Chapter~\ref{Chapter5}.
%
In Table~\ref{table:hyperpars_grid_full} we present the grids considered for the \acrshort{cv} search in these experiments, and we also indicate which parameters are included in this random search for each model.
Here, observe that we include the values $\mu=0$ and $\nu=0$, which ensures that the the \fmod{GLMTL} model contains the \fmod{MTL} one, with $\nu=0$, and also \fmod{AdapGLMTL} contains \fmod{GLMTL} with an identity matrix (minimal entropy rows) when $\mu=0$.
%

% \begin{table}[t!]
%     \caption{Hyperparameters, grids used to select them (when appropriate) and hyperparameter selection method for each model in the real problems.
%     The parameter $\epsilon$ is only suitable for regression with L1 and L2-\acrshort{svm}.
%     }
%     \label{table:hyperpars_grid_real}
%     \centering
%     \scalebox{.65}{
%      \begin{tabular}{*{8}{c}}
%      \toprule
%      \fhead{} & \fhead{Grid} & \fhead{\fmod{CTL-LX}} & \fhead{\fmod{ITL-LX}} & \fhead{\fmod{MTL-LX}}  & \fhead{\fmod{GLMTL-LX}} & \fhead{\fmod{AdapGLMTL-LX}}    \\
%      \midrule
%       $C$ &  \scalebox{1}{$\set{10^k: 0 \leq k \leq 4}$} & \checkmark & \checkmark & \checkmark & - & - \\ 
%       $\epsilon$ & \scalebox{1}{$\set{\frac{1}{10^k}: 1 \leq k \leq 4}$} & \checkmark & \checkmark & \checkmark & - & - \\
%       $\gamma$ & \scalebox{1}{$\set{\frac{10^k}{d}: -3 \leq k \leq 2}$} & \checkmark & \checkmark & \checkmark & - & - \\
%       $\gamma_s$ & \scalebox{1}{$\set{\frac{10^k}{d}: -3 \leq k \leq 2}$} & - & - & \checkmark & - & - \\
%       $\lambda$ & \scalebox{1}{$\set{0.1 k : 0 \leq k \leq 10}$} & - & - & \checkmark & - & - \\
%       $\nu$ & \scalebox{1}{$\set{0} \cup \set{10^k : -4 \leq k \leq 3}$} & - & - & - & \checkmark & \checkmark \\
%       $\mu$ & \scalebox{1}{$\set{0} \cup \set{10^k : -4 \leq k \leq 3}$} & - & - & - & - & \checkmark \\
%       \bottomrule
%      \end{tabular}
%     }
% \end{table}


%\subsubsection*{Results.}


In Table~\ref{tab:results_real} we show the test results for the real problems, where we report the \acrshort{mae} for the regression problems and the F1 score for \fdata{landmine}, the classification one.
%
In \fdata{computer}, our proposal, \fmod{AdapGLMTL} obtains different results depending on the \acrshort{svm} variant. For L2-\acrshort{svm}, it gets the best result; however, in the L1 and LS variants, it obtains third and second positions, respectively, while%although it has the best validation scores, this does not generalize well to the test set,
in these variants the non-adaptive \fmod{GLMTL} approach has the best results.
%
In summary, in \fdata{computer}, the proposed \fmod{AdapGLMTL} is best overall for the L2 variant, essentially ties with \fmod{MTL} for second place in the LS variant, and is third for the L1-\acrshort{svm}.
%
In the \fdata{parkinson} problem, our proposal is very close to the best models for the L1 and L2 variants, and gets the second best result in the L2-\acrshort{svm}.
%
Finally, in the \fdata{landmine}, the classification problem, \fmod{AdapGLMTL} is the best approach for L1, essentially ties with the non-adaptive version for the first place for LS, but it is fourth for the L2-\acrshort{svm}.
%
In any case, we can highlight some general patterns: the \acrshort{mt} models get the best results in all cases except in \fdata{landmine} for the L2 variant, the \acrshort{gl} approaches either tie or surpass the \fmod{MTL} approach in all problems, and \fmod{AdapGLMTL} have the best score in two occasions, while being competitive in almost all others.

Now, we also point out the difference in performance of the \fmod{AdapGLMTL} between the real and synthetic problems.
We can try to find an explanation for these different behaviors. Note that our adaptive proposal relies on pushing together tasks whose model parameters are close. In the synthetic problems, the clusters of tasks are well-defined and, thus, smart-grouping lead to better results. However, in the real problems this is not the case. The task structure is not clear-cut, and even more, the information that is inferred from the training set might not reflect the real underlying structure.
%
% In fact, when drawing the graph adjacency matrices (not shown for space considerations), they are essentially diagonal for the three real problems; in particular, no clustering between them appears and, therefore, \fmod{AdapGLMTL} cannot draw any advantage on these problems to improve the performance of either \fmod{MTL} or \fmod{GLMTL}.

\begin{table*}[t]
    \caption{Test results for real problems.
    We show the average and standard deviation of MAE scores for the regression problems: \fdata{computer} and \fdata{parkinson}; and average and standard deviation of F1 scores for the classification problem: \fdata{landmine}.
    In bold we highlight the best models of each group: L1, L2 or LS-SVMs.}
    \label{tab:results_real}
    \centering
    \scalebox{.65}{
    \begin{tabular}{l*{2}{S[table-format=1.3]@{$\pm$}S[table-format=1.3]}|S[table-format=1.3]@{$\pm$}S[table-format=1.3]}
    \toprule
    &  \fheadmulti{2}{\fdata{computer}} & \fheadmulti{2}{\fdata{parkinson}} & \fheadmulti{2}{\fdata{landmine}} \\
    \midrule
    \fmod{CTL-L1}    & 1.985 & 0.039  & 4.306 & 0.209 & 0.202 & 0.047 \\
     \fmod{ITL-L1}    & 1.623 & 0.028  & 1.949 & 0.021 & 0.243 & 0.014 \\
     \fmod{MTL-L1} & \fmaxn{1.526} & \fmaxn{0.052}  & \fmaxn{1.942} & \fmaxn{0.019} & 0.266 & 0.022 \\
     \fmod{GLMTL-L1}     & \fmaxn{1.526} & \fmaxn{0.052}  & 1.945 & 0.024 & 0.249 & 0.039 \\
     \fmod{AdapGLMTL-L1} & 1.545 & 0.083  & 1.945 & 0.024 & \fmaxn{0.272} & \fmaxn{0.033} \\
    \hline
    \fmod{CTL-L2}    & 2.001 & 0.028 & 4.211 & 0.093 & 0.235 & 0.045 \\
    \fmod{ITL-L2}    & 2.105 & 0.070 & 1.936 & 0.026 & \fmaxn{0.267} & \fmaxn{0.019} \\
    \fmod{MTL-L2} & 1.506 & 0.043 & 1.928 & 0.037 & 0.260 & 0.041 \\
    \fmod{GLMTL-L2}     & 1.507 & 0.045 & \fmaxn{1.927} & \fmaxn{0.037} & 0.251 & 0.048 \\
    \fmod{AdapGLMTL-L2} & \fmaxn{1.501} & \fmaxn{0.047} & 1.928 & 0.038 & 0.249 & 0.055 \\
   \hline
    \fmod{CTL-LS}    & 2.002 & 0.029 & 4.217 & 0.108 & 0.186 & 0.040 \\
    \fmod{ITL-LS}    & 1.609 & 0.015 & 1.928 & 0.017 & 0.182 & 0.007 \\
    \fmod{MTL-LS} & 1.507 & 0.042 & 1.929 & 0.026 & 0.186 & 0.041 \\
    \fmod{GLMTL-LS}     & \fmaxn{1.502} & \fmaxn{0.047} & \fmaxn{1.917} & \fmaxn{0.022} & \fmaxn{0.197} & \fmaxn{0.033} \\
    \fmod{AdapGLMTL-LS} & 1.506 & 0.046 & 1.924 & 0.033 & 0.196 & 0.031    \\
        \bottomrule
        \end{tabular}}
\end{table*}

% % Real Problems
% \begin{table*}[t!]
%     \caption{Test results for real problems.
%     We show the average and standard deviation of MAE scores for the regression problems: \fdata{computer} and \fdata{parkinson}; and average and standard deviation of F1 scores for the classification problem: \fdata{landmine}.
%     In bold we highlight the best models of each group: L1, L2 or LS-SVMs.}
%     \label{tab:results_real}
%     \centering
%     \scalebox{.65}{
% \begin{tabular}{lcc|c}
%     \hline
%                        & \fdata{computer}          & \fdata{parkinson}         & \fdata{landmine}          \\
%     \hline
%      \fmod{CTL-L1}    & 1.985 $\pm$ 0.039  & 4.306 $\pm$ 0.209 & 0.202 $\pm$ 0.047 \\
%      \fmod{ITL-L1}    & 1.623 $\pm$ 0.028  & 1.949 $\pm$ 0.021 & 0.243 $\pm$ 0.014 \\
%      \fmod{MTL-L1} & \fmaxn{1.526} $\pm$ \fmaxn{0.052}  & \fmaxn{1.942} $\pm$ \fmaxn{0.019} & 0.266 $\pm$ 0.022 \\
%      \fmod{GLMTL-L1}     & \fmaxn{1.526} $\pm$ \fmaxn{0.052}  & 1.945 $\pm$ 0.024 & 0.249 $\pm$ 0.039 \\
%      \fmod{AdapGLMTL-L1} & 1.545 $\pm$ 0.083  & 1.945 $\pm$ 0.024 & \fmaxn{0.272} $\pm$ \fmaxn{0.033} \\
%     \hline
%     \fmod{CTL-L2}    & 2.001 $\pm$ 0.028 & 4.211 $\pm$ 0.093 & 0.235 $\pm$ 0.045 \\
%     \fmod{ITL-L2}    & 2.105 $\pm$ 0.070 & 1.936 $\pm$ 0.026 & \fmaxn{0.267} $\pm$ \fmaxn{0.019} \\
%     \fmod{MTL-L2} & 1.506 $\pm$ 0.043 & 1.928 $\pm$ 0.037 & 0.260 $\pm$ 0.041 \\
%     \fmod{GLMTL-L2}     & 1.507 $\pm$ 0.045 & \fmaxn{1.927} $\pm$ \fmaxn{0.037} & 0.251 $\pm$ 0.048 \\
%     \fmod{AdapGLMTL-L2} & \fmaxn{1.501} $\pm$ \fmaxn{0.047} & 1.928 $\pm$ 0.038 & 0.249 $\pm$ 0.055 \\
%    \hline
%     \fmod{CTL-LS}    & 2.002 $\pm$ 0.029 & 4.217 $\pm$ 0.108 & 0.186 $\pm$ 0.040 \\
%     \fmod{ITL-LS}    & 1.609 $\pm$ 0.015 & 1.928 $\pm$ 0.017 & 0.182 $\pm$ 0.007 \\
%     \fmod{MTL-LS} & 1.507 $\pm$ 0.042 & 1.929 $\pm$ 0.026 & 0.186 $\pm$ 0.041 \\
%     \fmod{GLMTL-LS}     & \fmaxn{1.502} $\pm$ \fmaxn{0.047} & \fmaxn{1.917} $\pm$ \fmaxn{0.022} & \fmaxn{0.197} $\pm$ \fmaxn{0.033} \\
%     \fmod{AdapGLMTL-LS} & 1.506 $\pm$ 0.046 & 1.924 $\pm$ 0.033 & 0.196 $\pm$ 0.031    \\
% \hline
% \end{tabular}
%     }
% \end{table*}



















\section{Conclusions} \label{seq-conclusions}
% In this Chapter we have presented several experiments to test the proposals for \acrshort{mtl} that we have done in this work.
% In the first three sections we have observed that the convex \acrshort{mtl} formulation gets good results in a broad range of problems, and also when implemented with kernel methods or with \acrshort{nns}. In Section~\ref{sec:convexmtlsvm_exp}

In this chapter we have presented several experiments to test our \acrshort{mtl} proposals. We test the performance of the convex formulations and \acrshort{gl}-based strategies, presented in the previus chapters, on multiple classification and regression problems.

In Chapter~\ref{Chapter4} we have described the convex \acrshort{mtl} approach, where a common and task-specific parts are combined. Instead of adding the common and the corresponding task-specific part, which we call the additive formulation, we use a convex combination of the two parts.
In Section~\ref{sec:convexmtlsvm_exp}, using models based on the L1-\acrshort{svm}, we have shown empirically that the convex \acrshort{mtl} formulation is equivalent to the additive one. 
Next, in we also give numerical results, with multiple real datasets, that show the competitive performance of the convex \acrshort{mtl} formulation with L1, L2 and LS-\acrshort{svms}, which surpass their corresponding \acrshort{ctl} and \acrshort{itl} alternatives.
As a real application of this formulation, we present in Section~\ref{sec:convexmlt_renewable} experiments for solar and wind energy prediction. In the results we see again that the convex \acrshort{mtl} models outperform the considered competition in most cases, particularly with solar energy; however, in wind energy, where the task definitions are not that clear-cut, other approaches get sometimes better results.
% have extended this convex \acrshort{mtl} approach in two main ways. We have applied it to the three \acrshort{svm} varians, L1, L2 and LS-\acrshort{svm}, and we have also given numerical results, with multiple real datasets, that show that our proposed methods outperforms the corresponding \acrshort{ctl} and \acrshort{itl} strategies.

Although the convex \acrshort{mtl} formulation with kernel methods gives very competitive results, these models are not the most adequate for other type of data, such as images. To tackle the challenges that non-tabular data brings, the \acrshort{nns} are models that are better prepared. In Section~\ref{sec:convexmtl_nn_experiments} we provide experiments with four different image datasets to test the convex \acrshort{mtl} approach with \acrshort{nns}.
In these results we have observed that our proposal obtains better results than using a common \acrshort{nn} or considering task-specific ones. Also, in our experiments, the convex approach surpasses the models using a hard sharing strategy, with shared hidden layers and task-specific output ones, which is the most natural approximation for \acrshort{mtl} with \acrshort{nns}.

Furthermore, in Chapter~\ref{Chapter5} we have proposed an \acrshort{mtl} strategy based on the \acrshort{gl} formulation; we also combine it with the convex approach, which we call convex \acrshort{gl}.
Recall that the \acrshort{gl} formulation imposes a regularization that penalizes the pairwise distances between tasks, weighted by a given adjacency matrix.
In Section~\ref{sec:convexgl_experiments} we have compared the convex \acrshort{gl} with the baselines \acrshort{ctl} and \acrshort{itl} approaches, as well as with the convex models. We have observed that, with an appropiate selection of hyperparameters, the convex \acrshort{gl} methods with a fixed adjacency matrix can get good results, and outperform in many cases the convex ones.
%
We remark that the \acrshort{gl} approach can obtain the maximum leverage when an appropiate adjacency matrix is taken. In Chapter~\ref{Chapter5} we have provided a procedure to automatically learn this matrix from the data, this is the adaptive \acrshort{gl} algorithm. To test this algorithm we have provided in Section~\ref{sec:adapconvexgl_experiments} several synthetic problems, both in a regression and classification setting, to grasp a better understanding of such algorithm. We have observed that in the synthetic problems, where the task relations are well defined, the adaptive \acrshort{gl} methods are superior to non-adaptive ones. 
%
Here, the adjacency matrices learned by our proposals usually reflect the real underlying relations between tasks, and they provide an insightful information about the task structure.
%
Moreover, we see that our proposal is also useful with real problems, where the results are competitive even when the task relations are not that clear-cut.

% %
% In summary, our proposals, based on the convex combination of common and task-specific parts, and the application of the \acrshort{gl} regularization, yield good results over several datasets. We can observe that the convex formulation is quite general, and with it we can define a broad range of models, from kernel methods such as multiple \acrshort{svm} variants to \acrshort{nns}. Therefore, we can select the model that is better suited for our problem at hand and apply a convex \acrshort{mtl} strategy.
% %
% The \acrshort{gl} regularizer has been developed in this work for kernel models, and, when a fixed adjacency matrix is considered, it can be interpreted as a complement to our convex \acrshort{mtl} formulation. The convex approximation and the convex \acrshort{gl} one can be equivalent under an adequate selection of hyperparameters and some restrictions; we need to restrict the independent models to a common space, which results in less expressive models but also in less hyperparameters to select. 
% %
% We have observed that the interesting part of the \acrshort{gl} regularization is that we can learn the task relationship and exploit this information to get better results.
% %
% There is, thus, a tradeoff between the convex and convex \acrshort{gl} approaches; in the first one we need to make a computational effort to select the most adequate hyperparameters and task-specific spaces (especially with kernel methods), and in the second one this effort must be made to learn the task relations.
% Therefore, depending on the problem, we should select one or the other: if we believe that the tasks are very different we can use the full convex approach with all its hyperparameters, and, if we believe that the tasks are closely related but not in a trivial way (all share a common part), we should use the convex \acrshort{gl} models to control the task dependencies.
